(window.webpackJsonp=window.webpackJsonp||[]).push([[0],{157:function(s,n,e){"use strict";n.a=[{slug:"12.hashwick-v8-vulnerability",title:"HashWick V8 Vulnerability",date:"2018-08-22T00:00:00.000Z",html:'<p><img src="/images/hash-wick-small.png" alt="Hash Wick"></p>\n<p>About one year ago, I\'ve discovered a way to do a Denial-of-Service (DoS) attack\non a local Node.js instance. The process involved sending huge amounts of data\nto the HTTP server running on the same machine as the attacker, and measuring\nthe timing differences between various payloads. Given that the scope of attack\nwas limited to the same machine, it was decided by V8 team and myself that the\nissue wasn\'t worth looking in yet. Nevertheless, a <a href="https://darksi.de/f.v8-hash-seed-timing-attack/">blog post</a> was published.</p>\n<p>This year, I had a chance to revisit the Hash Seed guessing game with restored\nenthusiasm and new ideas. The results of this experiment are murky, and no fix\nis available yet in V8. Thus <strong>all V8 release lines are vulnerable to the\nHashWick attack</strong>.</p>\n<p><em>(Disclaimer: the issue was disclosed responsibly. This blog post is published\nafter more than 90 days since the initial report)</em></p>\n<h2>What is a Hash Seed?</h2>\n<p>The Hash Seed is a random number that is used as an initial value for the\n(non-cryptographic) hash functions inside of V8 instances. Such numbers are used\nnot only in V8 or other VMs, they\'re used in <a href="https://lwn.net/Articles/711167/">kernels</a>, <a href="https://github.com/antirez/redis/blob/cefe21d28a75f4fdbf24823ce42e777c2b9d5c6f/src/dict.c#L74">databases</a>, and\nmany different kinds of software.</p>\n<p>The reason to have seeded hash functions is to prevent collision attacks on\nhash maps (e.g. JavaScript objects/dictionaries). In ideal scenario, use of\nrandom seed should make guessing the hash value of a string/number an impossible\nendeavor.</p>\n<p>Whenever a Node.js instance parses HTTP headers or JSON object, V8 has to create\na hash map for it. Each hash map is backed by a list (storage) of length\n<code>2 * N</code>. The keys are inserted at even positions, the values are inserted at odd\n(right after the key). The position index is determined by the hash of the key\nmodulo the storage size. Two equal keys will have two equal hashes, and will\npoint to the same cell in the list.</p>\n<p>In ideal scenario the indices for two different keys are always different. It\nis easy to see that it isn\'t possible due to the limited list size. The more\nkey/value pairs we insert into the object, the more likely the &quot;collision&quot; to\nhappen. When the hash values are the same, but the keys are different, V8\nhas to place the key in the next cell... or in the cell after the next, if the\nnext is filled already.</p>\n<p>All in all, this provides quite optimal insertion/lookup performance at\nrelatively low memory costs.</p>\n<h2>What if attacker knows Hash Seed?</h2>\n<p>Every publicly exposed system is subject for external attacks. In the worst\ncase, an attacker gains access to the system or data in it. In less worse cases\nthe attacker might be able to overload the resources of the system by repeatedly\nhitting the &quot;slow&quot; paths in the system\'s code. Such attacks are called &quot;Denial\nof Service&quot; attacks or simply DoS.</p>\n<p>For the hash maps in V8, the hash collisions are exactly the slow path. Being\nable to generate a lot of (or precompute) keys with similar hash values (for\nvarious hash map storage capacities) without using many resources is a guarantee\nof success for such an attack. The worst case scenario is that a small JSON\nobject (or HTTP headers) could take seconds to parse. Sending thousands of such\nobjects would render any server unresponsive.</p>\n<p>What stands in a way of generating the collisions is a random Hash Seed number.\nGiven sufficient size of that number and a strong hash function, the indices of\nthe different keys would look absolutely random. Guessing the Hash Seed becomes\nimpractical both time-wise and information-wise.</p>\n<p>Unfortunately for V8, the hash function isn\'t strong enough and the hash seed\nis a small number.</p>\n<h2>How to find V8\'s Hash Seed?</h2>\n<p>Imagine the following scenario: a Node.js HTTP server is available publicly and\naccepts JSON bodies for POST requests. It\'d be reasonable to say that many\npublic Node.js servers are of this kind. It\'s important to note that this is\nalso applicable if Node.js is not directly exposed to a public internet port,\nsuch as the case of being proxy-passed via Nginx.</p>\n<p>How can an attacker find the value of V8\'s Hash Seed in such case?</p>\n<p>This was a subject of my research this and last year. Assuming absence of access\nto the server itself, the only way seems to be through the timing differences\nbetween processing different crafted HTTP requests.</p>\n<p>Hitting the slow path in hash map key insertion that we discussed above should\ngive a slightly slower response time. Knowing a lot of key combinations that\ncause the slowdown (and as many combinations that doesn\'t cause one) is enough\nfor reconstructing the seed value. The problem is, the difference between slow\nand fast path is in the order of microseconds, while the network latency is\noften at least a couple of milliseconds. The network jitter overwrites any minor\ntiming differences without leaving us a chance to measure them.</p>\n<p>What is needed for successful attack is an <strong>&quot;amplification&quot;</strong>. The request has\nto be crafted in such way that the key insertion is triggered many times in a\nsequence for the same key and same hash map contents. Each insertion would take\njust a couple of microseconds, but a thousand of them would add up to a\nmillisecond!</p>\n<p>Without giving away the complete tools for crafting such an attack, I can say\nthat the JSON body might look like this:</p>\n<p><code>{&quot;100000&quot;:0,&quot;101&quot;:1,&quot;101&quot;:1,...repeat many times...}</code></p>\n<p>It exploits several implementation details in V8 and a few quirks of JavaScript.\nIn particular, a JavaScript number lookup <code>obj[100000]</code> is equivalent to\nlooking up the &quot;stringified&quot; value of the same number <code>obj[&quot;100000&quot;]</code>.</p>\n<p>The next quirk is that JSON objects might contain duplicate keys. Each key will\nbe parsed and looked up in the object, regardless of how many times it is\nrepeated in the JSON. <em>Each lookup triggers either slow or fast path in the\ninsertion code</em>.</p>\n<p>The object above essentially becomes a sparse <code>Array</code> backed by a hash map with\nvery shallow storage capacity (just <code>4</code> values). Here\'s how V8 inserts key into\nit:</p>\n<ol>\n<li>Initially <code>storage</code> is <code>[ null, null, null, null ]</code></li>\n<li>The index of the first key (<code>100000</code>) is computed using the hash function and\nthe hash seed: <code>index = hash(100000, seed) % 4</code></li>\n<li>The value <code>0</code> is inserted into that slot of storage (e.g. <code>index = 1</code>):\n<code>[ null, 0, null, null ]</code></li>\n<li>The index of the second key is computed\n<code>index_2 = hash(random_key, seed) % 4</code></li>\n<li><code>while (storage[index_2] != null) index_2++</code></li>\n<li>The value is stored in <code>index_2</code> slot</li>\n</ol>\n<p>Step 5 is crucial for my attack. The extra check takes extra time, and this time\ndifference could be measured to get information about the hash seed.</p>\n<p>Thus fixing the first key to <code>100000</code>, and trying out different keys\n(probes) will give us the list of timings per each random key. Quarter of the\nprobes will have the same index as <code>100000</code> and will hit the slow path due to\ncollision. The rest will go through the fast path. The processing script would\nlater go through the list of timings and separate it by <code>75%</code> percentile of\nlatency. Most probes would be correctly classified as fast/slow. Misclassified\nprobes would increase Hash Seed search time.</p>\n<p>The result of processing is a list of probe keys, each with an assigned class:\n&quot;same index as 100000&quot; or &quot;different index&quot;. Each entry of this list is a\nconstraint on the Hash Seed value. An OpenCL script goes through all possible\n32-bit Hash Seed values (<code>0 - 0x3fffffff</code>), and finds the one that satisfies\nthe majority of the constraints. That value is the most likely Hash Seed of the\nattacked V8 instance. The OpenCL computation could take place on either CPU or\nGPU, and completes the search in about one minute on my MacBook Pro.</p>\n<p>My unoptimized PoC sends about 2 gb of JSON data to the server, collects the\ntiming information, and computes the Hash Seed in a <em>couple of minutes</em> (this\nincludes OpenCL brute-force time).</p>\n<h2>Prevention</h2>\n<p>This sounds dreary, but the fixes can be made. First of all, the hash seed size\nhas to be increased from 32 bits to 64 bits (this is already done in V8). Next,\nthe hash function has to be changed to <a href="https://en.wikipedia.org/wiki/SipHash">SipHash</a> or other hash function with\nPRF (Pseudo-Random Function) properties.</p>\n<p>Google has an amazing team working on V8. I\'m really hopeful that the remaining\nfixes will be completed soon.</p>\n<h2>Prior-Art</h2>\n<p>The hash collision attacks have <a href="https://lwn.net/Articles/474912/">a long history</a>, and most of the software\nprojects has moved to <a href="https://en.wikipedia.org/wiki/SipHash">SipHash</a> and at least 64-bit Hash Seed since then.</p>\n<hr>\n<h4>Credits</h4>\n<p>Huge thanks to <a href="https://github.com/aheckmann">Aaron Heckmann</a>, <a href="https://github.com/snowinferno">Greg Wilburn</a>, <a href="https://github.com/rauchg">Guillermo Rauch</a>, and\n<a href="https://github.com/shaunwarman">Shaun Warman</a> for providing feedback on this article.</p>\n'},{slug:"11.hyperbloom",title:"HyperBloom",date:"2017-04-26T00:00:00.000Z",html:'<p>Over this weekend I got not so original (but definitely a fun one) idea to build\nfully distributed and decentralized Twitter. At the time it was inspired by the\n<a href="https://datproject.org/">DAT Project</a> and <a href="https://github.com/mafintosh/hypercore">Hypercore</a>, neither of which could support public\nreplies to user feeds.</p>\n<p>Hence, the most natural thing was to <a href="https://xkcd.com/927/">write a new protocol</a>! Say hello to\n<a href="https://github.com/hyperbloom/hyperbloom">HyperBloom</a>!</p>\n<h2>Protocol</h2>\n<p>It is crucial to understand the needs for the protocol before discussing the\nprotocol itself. Let me list few requirements for it:</p>\n<ul>\n<li>Decentralized and distributed</li>\n<li>Viral. Everyone can reply to anyone\'s tweet without exchanging any public\nkeys or information ahead of time</li>\n<li>Secure</li>\n</ul>\n<p>How could it combine all these three qualities into one protocol? By combining\nexisting solutions, of course:</p>\n<ul>\n<li><a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type#State-based_grow-only_set">State-based grow-only set</a> with <a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom Filters</a> for diffs</li>\n<li>Distributed <a href="https://en.wikipedia.org/wiki/Public_key_infrastructure">Public Key Infrastructure</a> (PKI) for append permissions</li>\n</ul>\n<h3>Trust Network</h3>\n<p>Having grow-only set that is writable by anyone on the web is the best way to\nintroduce enormous amount of spam into social network. This can be tackled by\naccepting writes only from your friends. However, this kills the virality of the\nplatform.</p>\n<p>Perhaps friends-of-friends should be allowed to append to that Set? Better!</p>\n<p>The way <a href="https://github.com/hyperbloom/hyperbloom">HyperBloom</a> addresses this is by letting author\'s issue so called\n<a href="https://github.com/hyperbloom/hyperbloom-protocol/blob/master/spec.md#signature-chain"><em>Trust Links</em></a>. Each <em>Trust Link</em> acts like an edge in the Graph: <code>A -&gt; B</code>\nor <em>A</em> trusts <em>B</em>. When two peers connect to synchronize the values in a Set,\nthey each present a collection of links from the author of the Set to the peers\nthemselves. Each successive link in such collection is a continuation of the\nprevious link: <code>A -&gt; B, B -&gt; C, C -&gt; D</code>. With a total limit of <strong>5</strong> links in\none collection (chain).</p>\n<p>The limit is imposed to save the bandwidth. To further save it peers help each\nother by automatically issuing links that create shorter path to the author.</p>\n<p>Example:</p>\n<ol>\n<li>Peer B has following chain: <code>A -&gt; B</code></li>\n<li>Peer C has following chain: <code>A -&gt; D, D -&gt; E, E -&gt; C</code></li>\n<li>Peer B sends <code>B -&gt; C</code> to C to minimize the route</li>\n<li>Peer C uses <code>A -&gt; B, B -&gt; C</code> later on</li>\n</ol>\n<p>Each link has an expiration time, and such automatic link as in the example will\nhave the expiration time set to: <code>minimum(A -&gt; D, D -&gt; E, E -&gt; C)</code>. Essentially,\n<code>A</code> always controls how often it wants to refresh its peers\' trust.</p>\n<h3>Set</h3>\n<p>Set is not particularly interesting. It borrows some design decisions from\n<a href="https://bitcoin.org/en/glossary/simplified-payment-verification">Bitcoin SPV client</a>. In particular the use of Bloom filters to optimally\ncompute the difference between the peers and set the missing values.</p>\n<h2>Usage</h2>\n<p>I\'m combining both Hypercore and HyperBloom into a project called (for no\nparticular reason. May be Hyper-uni-corn?) <a href="https://github.com/indutny/hypercorn">HyperCorn</a>. HyperCorn uses\nHyperCore logs for JSON message fields, and HyperBloom for notifying authors\nabout replies to their feeds.</p>\n<p>HyperBloom Trust Links are stored and distributed through HyperCore. So far it\nappears to be working, but it has pretty long way to go still. Mainly it needs\nan UI. Contact me, if you are interested!</p>\n<h2>Open Questions</h2>\n<ul>\n<li>Is virality a good thing?</li>\n<li>Should auto-links be issued?</li>\n<li>Is 5 links enough?</li>\n</ul>\n<p>I\'d love to hear your opinion.</p>\n<p>(You can reply on <a href="https://twitter.com/indutny/status/857136827639189504">twitter</a>)</p>\n<p>Thanks for reading.</p>\n'},{slug:"10.bitcoin-to-the-moon",title:"Bitcoin to the Moon",date:"2017-04-06T00:00:00.000Z",html:'<p>Behold, this is rather unusual post for this blog. Instead of exploring\nvastness of technical wonders, this post will concentrate on discussion and\nexplanation of recent events in Bitcoin community.</p>\n<h2>Prerequisites</h2>\n<ul>\n<li><a href="https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-April/013996.html">Greg Maxwell\'s email</a></li>\n<li><a href="https://github.com/tothemoon-org/extension-blocks">To the Moon proposal</a></li>\n</ul>\n<h2>Statement</h2>\n<p>Recently I got involved in the <a href="https://github.com/tothemoon-org/extension-blocks">initiative</a> related to my past interest in\nBitcoin technology. This effort is lead by <a href="https://github.com/chjj">Christopher Jeffrey (JJ)</a> from\n<a href="https://purse.io/">purse.io</a>, <a href="https://twitter.com/jcp?lang=en">Joseph Poon</a> from <a href="http://lightning.network/">Lightning Network</a>, <a href="https://twitter.com/spair">Stephen Pair</a>\nfrom <a href="https://bitpay.com/">bitpay.com</a>. To make it clear from the start, my contribution to this\nproject was rather small and limited to providing superficial technical review.</p>\n<p>The <a href="https://github.com/tothemoon-org/extension-blocks">initiative</a> is based off the <a href="https://bitcointalk.org/index.php?topic=283746.0">Auxillary Block proposal</a> that is\nslightly older than the <a href="https://github.com/bcoin-org/bcoin">bcoin</a> project. It was modified to\naccommodate the use of Lightning, and (although, it is incompatible with\n<a href="https://github.com/bitcoin/bips/blob/master/bip-0141.mediawiki">BIP 141</a>) Segregated Witness (<em>SEGWIT</em>).</p>\n<p>The main advantage over Segregated witness is that the block size is no longer\ntied to the number of transactions in it. Many transactions could be stored\noutside of the canonical blocks in so called Extension blocks. There are pros\nand cons to this approach that better be discussed on <a href="https://github.com/tothemoon-org/extension-blocks">github</a>.</p>\n<p>The most important thing is that it attempts to solve the contention between\nminers and bitcoin core. It has been known for some time that many miners were\nwilling to switch to <a href="https://www.bitcoinunlimited.info/">Bitcoin Unlimited</a> (<em>BU</em>) (or in other words do a\nhard-fork) because of the block size limitation. Not only <em>BU</em> is a hard fork,\nbut it also prone to <a href="http://www.coindesk.com/code-bug-exploit-bitcoin-unlimited-nodes/">bugs</a> that already brought it down once. Obviously,\ngiven this information one has to be very careful when considering it.\n<a href="https://github.com/bitcoin/bips/blob/master/bip-0141.mediawiki">SEGWIT</a>, on other hand, is a fantastic effort and a soft-fork alternative to\n<em>BU</em>. However it still caps the block size, and thus is not acceptable for\nminers for the very same reason as the current version of Bitcoin.</p>\n<p>Given this context, <a href="https://github.com/tothemoon-org/extension-blocks">a proposal</a> has been created to address this once and\nfor all. Purse.io has <a href="https://medium.com/purse-essays/extension-block-story-619a46b58c24">reached out</a> to the companies involved in Bitcoin to\ncollect their feedback and feature requests. All in all, it appears to me that\n&quot;To the Moon&quot; proposal should address the needs of everyone without much\ncompromise of our ideals and Bitcoin ideology.</p>\n<h2>ASICBOOST</h2>\n<p>Almost at the same time as &quot;To the Moon&quot; proposal was published, Greg Maxwell\nhas sent an <a href="https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-April/013996.html">email</a> about <a href="https://www.asicboost.com/">ASICBOOST</a> and his findings about usage of\nthis optimization in &quot;particular mining chip&quot; (quoting Greg).</p>\n<p>Given the timing this email has sprawled the discussion of miner\'s reasons to\n&quot;love&quot; <a href="https://github.com/tothemoon-org/extension-blocks">&quot;To the Moon&quot;</a> and &quot;hate&quot; <a href="https://github.com/bitcoin/bips/blob/master/bip-0141.mediawiki">BIP 141</a>. It turned out that\n&quot;To the Moon&quot; was compatible with ASICBOOST\'s optimization, while <em>SEGWIT</em> is\nnot.</p>\n<p>I can\'t resist diving into the technical details of this optimization, but\nbefore I\'ll walk this road with you let me quickly reassure you. As of\n<a href="https://github.com/tothemoon-org/extension-blocks/commit/5331eeed1880ecc43a250313415e0d0b02c56bab">this commit</a> &quot;To the Moon&quot; is no longer compatible with ASICBOOST, and,\nalthough it is an open question whether this kind of optimization is\npermissible or not, this proposal is on the same grounds with <em>SEGWIT</em> now.</p>\n<p><strong>This means that reasons for conspiracy about relationship between\n&quot;To the Moon&quot; and miners no longer holds.</strong></p>\n<p>If you have any additional prevention measures in mind - please do not hesitate\nto open an issue on <a href="https://github.com/tothemoon-org/extension-blocks">github</a>.</p>\n<h2>Technical details!</h2>\n<p>Finally :)</p>\n<p>The most of the content below relies on some understanding of\n<a href="https://arxiv.org/pdf/1604.00575.pdf">this ASICBOOST paper</a>. This paper is not to hard to follow, so please take\na look.</p>\n<p>It is a normal practice in Bitcoin mining to pre-compute as much as possible to\nmake mining possible. ASIC\'s mostly do double SHA256 hashes, thus this\npre-computation relies heavily on splitting SHA256 into phases and sharing data\nfor inputs that do not change.</p>\n<p>The way Bitcoin is mined is by brute-forcing the 32-bit nonce in the block\nheader until the hash of the header will match current complexity of the\nBlockchain (read, number of leading zeroes in the hash). Trying all 32 bits is\nof course not enough to generate such fancy looking block hashes, and almost in\nevery case some additional modifications to the block header are needed.</p>\n<p>Given the structure of the block header:</p>\n<pre><code>02000000 ........................... Block version: 2\n\nb6ff0b1b1680a2862a30ca44d346d9e8\n910d334beb48ca0c0000000000000000 ... Hash of previous block\'s header\n9d10aa52ee949386ca9385695f04ede2\n70dda20810decd12bc9b048aaab31471 ... Merkle root\n\n24d95a54 ........................... Unix time: 1415239972\n30c31b18 ........................... Target: 0x1bc330 * 256**(0x18-3)\nfe9f0864 ........................... Nonce\n</code></pre>\n<p>(<a href="https://bitcoin.org/en/developer-reference#block-headers">Source of the data</a>)</p>\n<p>The only field that miners has control of (other than timestamp, which can\'t\nbe changed too much for obvious reasons) is root of the <a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle tree</a> with\nblock\'s transactions (<em>TX</em>) as leafs. This is usually approached by modifying\nthe first <em>TX</em> (coinbase) in the block.</p>\n<p>Now as the Merkle root changes - it will practically invalidate any SHA256\npre-computation that could have been made, since the changes will span both of\nthe two 64-byte chunks (including padding) forming the 80-byte block header.\n(SHA256 operates on 64-byte chunks).</p>\n<p>What can one do about it? Second 64-byte chunk starts from the last 4 bytes of\nthe merkle root... Does it ring the bell yet?</p>\n<p>The answer is: collisions!</p>\n<p>The pre-computation is still partially possible if the second 64-byte chunk is\nthe same during mining. One doesn\'t have to keep it always the same, generating\nfew of such colliding chunks is enough to get the benefits of the optimization.</p>\n<p>Now how this collision may be generated? The answer is <a href="https://en.wikipedia.org/wiki/Brute-force_attack">brute-force</a>.</p>\n<p>(The rest of the post is basically elaboration upon <a href="https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-April/013996.html">Greg\'s email</a> which I\nhope you already checked).</p>\n<p>How many brute-force attempts has to be done? Applying <a href="https://en.wikipedia.org/wiki/Birthday_problem">Birthday Paradox</a>\ngives the number of tries around <code>2^16</code> (size of whole problem space is <code>2^32</code>,\nsince we need to collide just 4 bytes) for two colliding block headers. Four of\nthem will take approximately <code>2^24</code> tries. Quite a lot, but not too much if you\ncan optimize it. Let\'s now consider how this brute-force could work.</p>\n<p>The most straightforward way of doing it would be changing the coinbase, but\nthis is rather expensive for regular blocks. If block has around <code>1500</code> TXs this\nmeans re-computing the Merkle tree branch of length <code>10</code>. Thus <code>10</code>\ndouble-SHA256 per brute-force attempt. Very inefficient!</p>\n<p>Can we do less? Yes - we can!</p>\n<p>Transactions can be re-arranged in the block to change the Merkle root, each\ndifferent permutation will yield a different hash and thus will count as a try.\nPermuting 7 branches to the right of the Merkle root yields <code>5040</code> combinations\nwith <code>7</code> double-SHA526 hashes per try. Changing the coinbase to the left of the\nroot can produce <code>4096</code> more combinations. Combining these two together gives\nus just <code>2^24</code> tries that we was looking for! Now since we pre-cached various\nchoices for both left and right branches the only thing that is left is compute\ndouble-SHA256 of both of them for every combination. To conclude: just <code>1</code>\ndouble-SHA256 per try! Now this sounds quite good.</p>\n<h2>SEGWIT and &quot;To the Moon&quot;</h2>\n<p>This optimization is possible with &quot;classical&quot; Bitcoin, but is not feasible with\nSEGWIT for a very simple reason. Coinbase in SEGWIT includes the Merkle root\nover the rest of transactions (ignoring technical details), which means that\nit is not possible to combine left and right branches without changing the\ncoinbase which brings us back to <code>10</code> double-SHA256 per try.</p>\n<p>Initial version of &quot;To the Moon&quot; has a Merkle tree in coinbase too, but it\nhad to be computed only over transactions that are not present in\nclassical/canonical block. Meaning that it is easier to do ASICBOOST\noptimization on &quot;To the Moon&quot; than on SEGWIT.</p>\n<p>Given this description, it is easy to see that <a href="https://github.com/tothemoon-org/extension-blocks/commit/5331eeed1880ecc43a250313415e0d0b02c56bab">the recent change</a> in\n&quot;To the Moon&quot; spec makes it non-susceptible to ASICBOOST optimization.</p>\n<p>I hope this answers all or at least some of your questions about it.</p>\n<p>Thank you for reading!</p>\n<h3>Credits</h3>\n<p>I\'d like to thank:</p>\n<ul>\n<li>Greg Maxwell for doing a quick review of the change to &quot;To the Moon&quot; proposal,\nand for helping me understand the details of his discovery</li>\n<li>Christopher Jeffrey (JJ) for inviting me to the initiative</li>\n<li>Guillermo Rauch for reviewing/proof-reading this post.</li>\n</ul>\n'},{slug:"f.v8-hash-seed-timing-attack",title:"V8 hash seed timing attack",date:"2017-01-19T00:00:00.000Z",html:'<h2>Moment of History</h2>\n<p>There is a mostly forgotten <a href="https://github.com/nodejs/node-v0.x-archive/issues/2431">security issue</a> that was fixed in\nNode.js back in 2012. It was originally announced on the\n<a href="https://www.youtube.com/watch?v=R2Cq3CLI6H8">28c3 conference</a> December, 2011 and the final fix landed in\n<a href="https://github.com/nodejs/node/commit/16953329413831b32f4c3b2255aeacec874ed69d">January, 2012</a>.</p>\n<p>In few words, the most of dynamic languages use either bucket lists or\n<a href="https://en.wikipedia.org/wiki/Hash_table#Open_addressing">open addressing</a> variants of hash tables. V8 uses the latter one, and in\nsuch case when VM is asked to insert a property into an object it does\nthe following sequence of actions:</p>\n<ol>\n<li>Compute the hash of the key (quite often with a <a href="https://en.wikipedia.org/wiki/Jenkins_hash_function">Jenkins hash</a>)</li>\n<li>Clear the high bits of the hash value</li>\n<li>Use it as an index in the internal array</li>\n<li>Find unused slot in that array</li>\n<li>Insert the key/value pair at that slot.</li>\n</ol>\n<p>This sounds pretty much OK, except for the step 4. One may ask: What if the\ntarget slot is way too far from the index in the step 3? The answer is: it will\ntake more time to do such insertion.</p>\n<p>Do you see where it is going?</p>\n<h2>Collision attacks</h2>\n<p>If the attacker can insert many keys like these into the hash table - the whole\nprocedure is going be much slower than usual (20x slower in some cases). During\nthis time Node.js will be blocked, and performing such insertions one after\nanother leads directly to Denial of Service attack. To put it in concrete\ncontext: <code>req.headers</code> in <code>http.Server</code> is populated with user data, and is thus\nsusceptible to this kind of attack.</p>\n<p>How does one generate such keys? Trivial and fast brute-force could generate as\nmany keys as needed to give desired &quot;collisions&quot; given that attacker knows what\nhash function is used by VM.</p>\n<p>What was done to fix it in V8/Node.js? Together with V8 team we added seeds to\nall hash tables used in V8, and made sure that they are randomized on the\nprocess start.</p>\n<h2>Inspiration for an Experiment</h2>\n<p>After reading this <a href="http://perl11.org/blog/seed.html">Perl blog post</a> I thought that it would be funny to\ncarry out an actual hash seed extraction out of the live node.js process:\nfirst - locally within the process itself, second - from http server on the same\nmachine, third - remotely (no luck so far). Knowing the seed means being able\nto craft the collisions, and this gets us back to DoS problem.</p>\n<p>Numerous code paths in V8 have been tried, until I stumbled upon a\n<a href="https://github.com/v8/v8/blob/140d4df7954259e60a555efc0b2d00a9c924564c/src/objects-inl.h#L3140-L3157">particular function</a>. There V8 puts a new property into an internal list\ncalled <code>DescriptorArray</code>. For performance reasons properties in that array\nmust be sorted, and since V8 extends the array - it has to shift all bigger\nproperties to the right to make space for the new one.</p>\n<p>By measuring timing of such insertions, attacker could figure out approximate\nposition of the inserted key. <code>DescriptorArray</code> holds no more than 18 keys, so\nit could be attempted to insert the same 17 keys and one random one many times,\nand infer the difference in timing to find the random keys that were placed\neither at the very end or at the start of the array.</p>\n<p>It\'s easier said than done, though. V8 has many layers of caching (which is one\nof the reasons why your JavaScript code is so fast!). In order to get\nthrough to that <code>DescriptorArray::Append</code> function, I had to outflank all of\nthem. In the end, the resulting program does everything in reverse - the random\nkey is inserted first, and then 17 predefined keys are inserted right after it.\nThe difference is non-obvious, but that\'s the part of the solution to skip all\nof the caches.</p>\n<p>This is how it looks:</p>\n<pre><code class="language-javascript"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">test</span>(<span class="hljs-params">pre, list</span>) </span>{\n  <span class="hljs-keyword">const</span> o = {};\n  o[pre] = <span class="hljs-literal">null</span>;\n  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">let</span> i = <span class="hljs-number">0</span>; i &lt; list.length; i++)\n    o[list[i]] = <span class="hljs-literal">null</span>;\n  <span class="hljs-keyword">return</span> o;\n}\n</code></pre>\n<p>Now this script has to create a <code>list</code> of keys, and a large number of probes\n(2093 strings that are passed one after another as <code>pre</code>). It can try each probe\nwith the same <code>list</code>, and measure the timing with <code>process.hrtime()</code> with\nnanosecond precision. Largertime difference means that the probe was inserted\nat the start of the <code>DescriptorArray</code>, and thus its hash value (32 bit number)\nis less than all hashes of the keys in the <code>list</code>. When the time delta is least</p>\n<ul>\n<li>probe was appended to the end of the <code>DescriptorArray</code>, meaning that its hash\nis the biggest in it.</li>\n</ul>\n<p>It may sound like not too much to stick to, but if one can collect enough such\n&quot;relations&quot; between the probe and keys - one can brute force all 32-bit seed\nvalues to find the one that gives the best approximation to this relation!\nIn fact, it takes just about 15 minutes on 20 core machine to do it, and this\ntime can be improved by using GPU (I dare you!).</p>\n<p>The most important part of brute forcing function is <code>check</code>:</p>\n<pre><code class="language-c"><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> <span class="hljs-title">check</span><span class="hljs-params">(<span class="hljs-keyword">uint32_t</span> seed)</span> </span>{\n  <span class="hljs-keyword">int</span> score;\n  <span class="hljs-keyword">uint32_t</span> key_hashes[ARRAY_SIZE(keys)];\n\n  score = <span class="hljs-number">0</span>;\n\n  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> i = <span class="hljs-number">0</span>; i &lt; ARRAY_SIZE(keys); i++) {\n    key_hashes[i] = jenkins(keys[i], seed);\n  }\n\n  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> i = <span class="hljs-number">0</span>; i &lt; ARRAY_SIZE(probes); i += <span class="hljs-number">2</span>) {\n    <span class="hljs-keyword">uint32_t</span> l;\n    <span class="hljs-keyword">uint32_t</span> r;\n\n    l = jenkins(probes[i], seed);\n    r = jenkins(probes[i + <span class="hljs-number">1</span>], seed);\n\n    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> j = <span class="hljs-number">0</span>; j &lt; ARRAY_SIZE(keys); j++) {\n      <span class="hljs-keyword">if</span> (l &lt; key_hashes[j])\n        score++;\n      <span class="hljs-keyword">if</span> (key_hashes[j] &lt;= r)\n        score++;\n    }\n  }\n\n  <span class="hljs-keyword">return</span> score;\n}\n</code></pre>\n<p><code>l</code> is a probe that supposedly has the lowest hash value in <code>DescriptorArray</code>,\n<code>r</code> is a probe that has the highest. So all in all, <code>brute.c</code> just searches for\nthe seed value that maximizes the result of <code>check</code>. Simple!</p>\n<h2>Conclusions and code</h2>\n<p>This works locally as a charm, and works with a <code>http.Server</code> on the same\nmachine to some extent. Unfortunately (or fortunately?) this attack doesn\'t work\nwith remote servers (or I wasn\'t able to execute it), even when the ping is\naround 1ms. The timing difference that we are looking for is about several\nmicroseconds, and it looks like it is smudged out in the network delay\ndistribution.</p>\n<p>V8 team is aware of this effort, and the decision is that this is not a security\ndefect - hence it is published here.</p>\n<p>All code is available on <a href="https://github.com/indutny/hash-cracker">github</a>. Please enjoy with care!</p>\n'},{slug:"e.uv-link-t",title:"uv_link_t - libuv pipeline",date:"2016-08-15T00:00:00.000Z",html:'<h2>Preface</h2>\n<p>Writing servers/clients in C could be non-trivial. Even with the help of such\npowerful (and awesome dinosaur) libraries as <a href="https://github.com/libuv/libuv">libuv</a>, it still takes lots of\neffort and boilerplate code to create real world applications.</p>\n<p>Some of this boilerplate code comes from the use of the widespread protocols\nlike TLS (SSL) and HTTP. While there are popular implementations available\nas an Open Source libraries (<a href="https://github.com/openssl/openssl">OpenSSL</a>, <a href="https://github.com/nodejs/http-parser">http-parser</a>), they still either\nprovide very abstract interface (like <a href="https://github.com/nodejs/http-parser">http-parser</a>), or an API to transfer\nthe responsibility of the networking to the library itself (like <code>SSL_set_fd()</code>\nin <a href="https://github.com/openssl/openssl">OpenSSL</a> and Amazon\'s <a href="https://github.com/awslabs/s2n">s2n</a>). Such abstract nature makes them easier\nto embed, but the adaptor code inevitably tend to appear in the particular\napplications.</p>\n<h2>Precursor - StreamBase</h2>\n<p><a href="https://github.com/libuv/libuv">libuv</a> is hardly an exception, and <a href="https://github.com/nodejs/node/blob/master/src/tls_wrap.cc">node.js</a> and <a href="https://github.com/indutny/bud/blob/master/src/client.c">bud</a>\'s TLS\nimplementation is a vivid evidence of this. However, in a contrast to <a href="https://github.com/indutny/bud/blob/master/src/client.c">bud</a>,\n<a href="https://github.com/nodejs/node/blob/master/src/tls_wrap.cc">node.js</a> TLS code lives off on an abstraction called <a href="https://github.com/nodejs/node/blob/master/src/stream_base.h">StreamBase</a>. By\nseparating <a href="https://github.com/libuv/libuv">libuv</a>-specific adaptor code into a generic C++ class, we have\ncreated a foundation for a simpler and reusable implementation of any other\nprotocol! See, for example, recent <a href="https://github.com/nodejs/node/blob/29228c4089431d0e65749421f43aafd05694f376/src/node_http_parser.cc#L472-L486">node_http_parser.cc</a> which uses only\na minor amount of power available through the means of <a href="https://github.com/nodejs/node/blob/master/src/stream_base.h">StreamBase</a>, but\nnevertheless provides <a href="https://github.com/nodejs/node/pull/2355">10-20%</a> performance improvement since its inception.</p>\n<p>This implementation has some major drawbacks, preventing its wider adoption\noutside of the node.js core:</p>\n<ul>\n<li>C++ headers: lots of virtual classes, complex API, non-trivial inheritance\nscheme</li>\n<li>High internal dependence on the node.js core itself</li>\n</ul>\n<p>Because of these issues (and my own limitations) <a href="https://github.com/nodejs/node/blob/master/src/stream_base.h">StreamBase</a> has defied all\nattempts to make it public.</p>\n<h2>uv_link_t</h2>\n<p>Heavily inspired by the success of <a href="https://github.com/nodejs/node/blob/master/src/stream_base.h">StreamBase</a> in the node.js core, a\n<a href="https://github.com/indutny/uv_link_t">uv_link_t</a> library was created. It has lots of similarities with the\n<a href="https://github.com/nodejs/node/blob/master/src/stream_base.h">StreamBase</a>, but it is:</p>\n<ul>\n<li>Implemented in C: self-documented structures, C-cast based inheritance, etc</li>\n<li>Standalone library</li>\n</ul>\n<p>The API is based on the <a href="http://docs.libuv.org/en/v1.x/stream.html">uv_stream_t</a> and shouldn\'t come as a big surprise\nto the users, since <a href="https://github.com/indutny/uv_link_t">uv_link_t</a> is intended to be used together with\n<a href="https://github.com/libuv/libuv">libuv</a>.</p>\n<p>Here is a visual explanation of how <a href="https://github.com/libuv/libuv">uv_link_t</a> works:</p>\n<p><img src="/images/uv_link_source_t.svg" alt="uv_link_source_t"></p>\n<h2>Examples</h2>\n<p>Before we take a peek at the APIs, let\'s discuss what can be done with\n<a href="https://github.com/indutny/uv_link_t">uv_link_t</a>. Technically, any stream-based (i.e. anything that uses\n<code>uv_stream-t</code>) protocol can be implemented on top of it. Multiple protocols can\nbe chained together (that\'s why it is called <code>uv_</code><strong>link</strong><code>_t</code>!), provided that\nthere is an implementation:</p>\n<p><code>TCP &lt;-&gt; TLS &lt;-&gt; HTTP &lt;-&gt; WebSocket</code>.</p>\n<p>This chaining works in a pretty transparent way, and every segment of it can be\nobserved without disturbing the data flow and operation of the other links.</p>\n<p>Existing protocols:</p>\n<ul>\n<li><a href="https://github.com/indutny/uv_ssl_t">uv_ssl_t</a> - TLS, based on OpenSSL\'s API</li>\n<li><a href="https://github.com/indutny/uv_http_t">uv_http_t</a> - low-level HTTP/1.1 implementation, possibly incomplete</li>\n</ul>\n<p>Small demo-project:</p>\n<ul>\n<li><a href="https://github.com/indutny/file-shooter">file-shooter</a> - dumb-simple HTTPS server based on both <a href="https://github.com/indutny/uv_ssl_t">uv_ssl_t</a> and\n<a href="https://github.com/indutny/uv_http_t">uv_http_t</a></li>\n</ul>\n<p>Note that all these projects, including <a href="https://github.com/indutny/uv_link_t">uv_link_t</a> itself are supposed to\nbe built with a <a href="https://github.com/gypkg/gypkg">gypkg</a>, which is a subject for a future blog post.</p>\n<h2>API</h2>\n<p>The backbone of the API is a <code>uv_link_t</code> structure:</p>\n<pre><code class="language-c"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">"uv_link_t.h"</span></span>\n\n<span class="hljs-keyword">static</span> <span class="hljs-keyword">uv_link_methods_t</span> methods = {\n  <span class="hljs-comment">/* To be discussed below */</span>\n};\n\n<span class="hljs-keyword">void</span> _() {\n  <span class="hljs-keyword">uv_link_t</span> link;\n\n  uv_link_init(&amp;link, &amp;methods);\n\n  <span class="hljs-comment">/* ... some operations */</span>\n  uv_link_close(&amp;link, close_cb);\n}\n</code></pre>\n<p>In the most of the cases a first link should be an <code>uv_link_source_t</code>. It\nconsumes an instance of <code>uv_stream_t</code>, and propagates reads and writes from\nthe whole chain of links connected to it.</p>\n<pre><code class="language-c"><span class="hljs-keyword">uv_link_source_t</span> source;\n\n<span class="hljs-keyword">uv_stream_t</span>* to_be_consumed;\nuv_link_source_init(&amp;source, to_be_consumed);\n</code></pre>\n<p>As mentioned before, links can be chained together:</p>\n<pre><code class="language-c"><span class="hljs-keyword">uv_link_t</span> a;\n<span class="hljs-keyword">uv_link_t</span> b;\n\n<span class="hljs-comment">/* Initialize `a` and `b` */</span>\nuv_link_chain(<span class="hljs-comment">/* from */</span> a, <span class="hljs-comment">/* to */</span> b);\n</code></pre>\n<p>This <code>uv_link_chain</code> call means that the data emitted by <code>a</code> will be passed as\nan input to <code>b</code>, and the output of <code>b</code> will written to <code>a</code>.</p>\n<p>Speaking of input/output, the API is pretty similar to <a href="https://github.com/libuv/libuv">libuv</a>\'s:</p>\n<pre><code class="language-c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">uv_link_write</span><span class="hljs-params">(<span class="hljs-keyword">uv_link_t</span>* link, <span class="hljs-keyword">const</span> <span class="hljs-keyword">uv_buf_t</span> bufs[],\n                  <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">int</span> nbufs, <span class="hljs-keyword">uv_stream_t</span>* send_handle,\n                  uv_link_write_cb cb, <span class="hljs-keyword">void</span>* arg)</span></span>;\n\n<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">uv_link_read_start</span><span class="hljs-params">(<span class="hljs-keyword">uv_link_t</span>* link)</span></span>;\n<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">uv_link_read_stop</span><span class="hljs-params">(<span class="hljs-keyword">uv_link_t</span>* link)</span></span>;\n\n<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">fn</span><span class="hljs-params">()</span> </span>{\n  link-&gt;alloc_cb = <span class="hljs-comment">/* something */</span>;\n  link-&gt;read_cb = <span class="hljs-comment">/* something */</span>;\n}\n</code></pre>\n<p>Please check the <a href="https://github.com/indutny/uv_link_t/blob/master/docs/api.md">API docs</a> for further information on particular methods\nand structures (likes <code>uv_link_source_t</code> and <code>uv_link_observer_t</code>).</p>\n<p>There is also an <a href="https://github.com/indutny/uv_link_t/blob/master/docs/implementation-guide.md">Implementation guide</a> for implementing custom types of\n<code>uv_link_t</code>.</p>\n<h2>Error reporting</h2>\n<p>Having multiple independent implementations of <code>uv_link_t</code> interface, it is a\nnatural question to ask: how does <code>uv_link_t</code> handle error code conflict?</p>\n<p>The answer is that all error codes returned by <code>uv_link_...</code> methods are\nactually prefixed with the index of the particular link in a chain. Thus, even\nif there are several similar links in a chain, it is possible to get the pointer\nto the <code>uv_link_t</code> instance that have emitted it:</p>\n<pre><code class="language-c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">uv_link_errno</span><span class="hljs-params">(<span class="hljs-keyword">uv_link_t</span>** link, <span class="hljs-keyword">int</span> err)</span></span>;\n<span class="hljs-function"><span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* <span class="hljs-title">uv_link_strerror</span><span class="hljs-params">(<span class="hljs-keyword">uv_link_t</span>* link, <span class="hljs-keyword">int</span> err)</span></span>;\n</code></pre>\n<h2>Foreword: gypkg</h2>\n<p><a href="https://github.com/gypkg/gypkg">gypkg</a> is recommended to be used when embedding <code>uv_link_t</code> in the C\nproject. There are not too many source files to put into a <code>Makefile</code> or some\nother build file, but the convenience that <a href="https://github.com/gypkg/gypkg">gypkg</a> provides, pays off very\nquickly!</p>\n<h3>Installation (node.js v6 is required):</h3>\n<pre><code class="language-sh">npm install -g gypkg\n</code></pre>\n<h3>Init</h3>\n<pre><code class="language-sh">mkdir project\n<span class="hljs-built_in">cd</span> project\ngypkg init\n</code></pre>\n<h3>Adding <code>uv_link_t</code> as a dependency</h3>\n<pre><code class="language-sh">vim project.gyp\n</code></pre>\n<pre><code class="language-python">{\n  <span class="hljs-string">"variables"</span>: {\n    <span class="hljs-string">"gypkg_deps"</span>: [\n      <span class="hljs-string">"git://github.com/libuv/libuv.git@^1.9.0 =&gt; uv.gyp:libuv"</span>,\n      <span class="hljs-string">"git://github.com/indutny/uv_link_t@^1.0.0 [gpg] =&gt; uv_link_t.gyp:uv_link_t"</span>,\n    },\n  },\n\n  <span class="hljs-comment"># Some other GYP things</span>\n}\n</code></pre>\n<h3>Building</h3>\n<pre><code class="language-sh">gypkg build\nls -la out/Release\n</code></pre>\n'},{slug:"d.sea-of-nodes",title:"Sea of Nodes",date:"2015-10-08T00:00:00.000Z",html:'<h2>Brief intro</h2>\n<p>This post is going to be about the sea-of-nodes compiler concept that I have\nrecently learned.</p>\n<p>While it is not completely necessary, it may be useful to take a peek at the\nsome of my previous posts on JIT-compilers before reading this:</p>\n<ul>\n<li><a href="/4.how-to-start-jitting">How to start JIT-ting</a></li>\n<li><a href="/5.allocating-numbers">Allocating numbers</a></li>\n<li><a href="/6.smis-and-doubles">SMIs and Doubles</a></li>\n<li><a href="/a.deoptimize-me-not">Deoptimize me not, v8</a></li>\n</ul>\n<h2>Compilers = translators</h2>\n<p>Compilers are something that every Software Engineer uses several times a day.\nSurprisingly even people who consider themselves to be far from writing the\ncode, still use a compiler quite heavily throughout their day. This is\nbecause most of the web depends on client-side code execution, and many of such\nclient-side programs are passed to the browser in a form of the source code.</p>\n<p>Here we come to an important thing: while source code is (usually)\nhuman-readable, it looks like complete garbage to your\nlaptop/computer/phone/...\'s CPU. On other hand, machine code, that computers\n<strong>can</strong> read, is (almost always) not human-readable. Something should be done\nabout it, and the solution to this problem is provided by the process called\n<strong>translation</strong>.</p>\n<p>Trivial compilers perform a single pass of <em>translation</em>: from the source code\nto the machine code. However, in practice most compilers do at least two passes:\nfrom the source code to <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract Syntax Tree</a> (AST), and from <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">AST</a> to\nmachine code. <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">AST</a> in this case acts like an <em>Intermediate Representation</em>\n(IR), and as the name suggests, <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">AST</a> is just another form of the same source\ncode. These intermediate representations chain together and essentially are\nnothing else but the abstraction layers.</p>\n<p>There is no limit on the layer count. Each new layer brings the source program\ncloser to how it will look like in machine code.</p>\n<h2>Optimization layers</h2>\n<p>However, not all layers are used solely for translation. Many compilers also\nadditionally attempt to optimize the human-written code. (Which is usually\nwritten to have a balance between code elegance and code performance).</p>\n<p>Take the following JavaScript code, for example:</p>\n<pre><code class="language-javascript"><span class="hljs-keyword">for</span> (<span class="hljs-keyword">var</span> i = <span class="hljs-number">0</span>, acc = <span class="hljs-number">0</span>; i &lt; arr.length; i++)\n  acc += arr[i];\n</code></pre>\n<p>If the compiler would translate it to the machine code straight out of <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">AST</a>,\nit may resemble (in very abstract and detached from reality instruction set):</p>\n<pre><code>acc = 0;\ni = 0;\nloop {\n  // Load `.length` field of arr\n  tmp = loadArrayLength(arr);\n  if (i &gt;= tmp)\n    break;\n\n  // Check that `i` is between 0 and `arr.length`\n  // (NOTE: This is necessary for fast loads and\n  // stores).\n  checkIndex(arr, i);\n\n  // Load value\n  acc += load(arr, i);\n\n  // Increment index\n  i += 1;\n}\n</code></pre>\n<p>It may not be obvious, but this code is far from optimal. Array length does not\nreally change inside of the loop, and the range checks are not necessary at all.\nIdeally, it should look like this:</p>\n<pre><code>acc = 0;\ni = 0;\nlen = loadArrayLength(arr);\nloop {\n  if (i &gt;= tmp)\n    break;\n\n  acc += load(arr, i);\n  i += 1;\n}\n</code></pre>\n<p>Let\'s try to imagine how we could do this.</p>\n<p>Suppose we have an <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">AST</a> at hand, and we try to generate the machine code\nstraight out of it:</p>\n<p><em>(NOTE: Generated with <a href="https://github.com/jquery/esprima">esprima</a>)</em></p>\n<pre><code class="language-javascript">{ <span class="hljs-attr">type</span>: <span class="hljs-string">\'ForStatement\'</span>,\n\n  <span class="hljs-comment">//</span>\n  <span class="hljs-comment">// This is `var i = 0;`</span>\n  <span class="hljs-comment">//</span>\n  init:\n   { <span class="hljs-attr">type</span>: <span class="hljs-string">\'VariableDeclaration\'</span>,\n     <span class="hljs-attr">declarations</span>:\n      [ { <span class="hljs-attr">type</span>: <span class="hljs-string">\'VariableDeclarator\'</span>,\n          <span class="hljs-attr">id</span>: { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Identifier\'</span>, <span class="hljs-attr">name</span>: <span class="hljs-string">\'i\'</span> },\n          <span class="hljs-attr">init</span>: { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Literal\'</span>, <span class="hljs-attr">value</span>: <span class="hljs-number">0</span>, <span class="hljs-attr">raw</span>: <span class="hljs-string">\'0\'</span> } },\n        { <span class="hljs-attr">type</span>: <span class="hljs-string">\'VariableDeclarator\'</span>,\n          <span class="hljs-attr">id</span>: { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Identifier\'</span>, <span class="hljs-attr">name</span>: <span class="hljs-string">\'acc\'</span> },\n          <span class="hljs-attr">init</span>: { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Literal\'</span>, <span class="hljs-attr">value</span>: <span class="hljs-number">0</span>, <span class="hljs-attr">raw</span>: <span class="hljs-string">\'0\'</span> } }],\n     <span class="hljs-attr">kind</span>: <span class="hljs-string">\'var\'</span> },\n\n  <span class="hljs-comment">//</span>\n  <span class="hljs-comment">// `i &lt; arr.length`</span>\n  <span class="hljs-comment">//</span>\n  test:\n   { <span class="hljs-attr">type</span>: <span class="hljs-string">\'BinaryExpression\'</span>,\n     <span class="hljs-attr">operator</span>: <span class="hljs-string">\'&lt;\'</span>,\n     <span class="hljs-attr">left</span>: { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Identifier\'</span>, <span class="hljs-attr">name</span>: <span class="hljs-string">\'i\'</span> },\n     <span class="hljs-attr">right</span>:\n      { <span class="hljs-attr">type</span>: <span class="hljs-string">\'MemberExpression\'</span>,\n        <span class="hljs-attr">computed</span>: <span class="hljs-literal">false</span>,\n        <span class="hljs-attr">object</span>: { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Identifier\'</span>, <span class="hljs-attr">name</span>: <span class="hljs-string">\'arr\'</span> },\n        <span class="hljs-attr">property</span>: { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Identifier\'</span>, <span class="hljs-attr">name</span>: <span class="hljs-string">\'length\'</span> } } },\n\n  <span class="hljs-comment">//</span>\n  <span class="hljs-comment">// `i++`</span>\n  <span class="hljs-comment">//</span>\n  update:\n   { <span class="hljs-attr">type</span>: <span class="hljs-string">\'UpdateExpression\'</span>,\n     <span class="hljs-attr">operator</span>: <span class="hljs-string">\'++\'</span>,\n     <span class="hljs-attr">argument</span>: { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Identifier\'</span>, <span class="hljs-attr">name</span>: <span class="hljs-string">\'i\'</span> },\n     <span class="hljs-attr">prefix</span>: <span class="hljs-literal">false</span> },\n\n  <span class="hljs-comment">//</span>\n  <span class="hljs-comment">// `arr[i] += 1;`</span>\n  <span class="hljs-comment">//</span>\n  body:\n   { <span class="hljs-attr">type</span>: <span class="hljs-string">\'ExpressionStatement\'</span>,\n     <span class="hljs-attr">expression</span>:\n      { <span class="hljs-attr">type</span>: <span class="hljs-string">\'AssignmentExpression\'</span>,\n        <span class="hljs-attr">operator</span>: <span class="hljs-string">\'+=\'</span>,\n        <span class="hljs-attr">left</span>: { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Identifier\'</span>, <span class="hljs-attr">name</span>: <span class="hljs-string">\'acc\'</span> },\n        <span class="hljs-attr">right</span>:\n         { <span class="hljs-attr">type</span>: <span class="hljs-string">\'MemberExpression\'</span>,\n           <span class="hljs-attr">computed</span>: <span class="hljs-literal">true</span>,\n           <span class="hljs-attr">object</span>: { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Identifier\'</span>, <span class="hljs-attr">name</span>: <span class="hljs-string">\'arr\'</span> },\n           <span class="hljs-attr">property</span>: { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Identifier\'</span>, <span class="hljs-attr">name</span>: <span class="hljs-string">\'i\'</span> } } } }\n</code></pre>\n<p>This JSON could also be visualized:\n<img src="/images/ast.svg" alt="AST"></p>\n<p>This is a tree, so it is very natural to traverse it from the top to the bottom,\ngenerating the machine code as we visit the AST nodes. The problem with this\napproach is that the information about variables is very sparse, and is spread\nthrough the different tree nodes.</p>\n<p>Again, to safely move the length lookup out of the loop we need to know that the\narray length does not change between the loop\'s iterations. Humans can do it\neasily just by looking at the source code, but the compiler needs to do quite a\nlot of work to confidently extract those facts directly from the AST.</p>\n<p>Like many other compiler problems, this is often solved by lifting the data into\na more appropriate abstraction layer, i.e. intermediate representation. In this\nparticular case that choice of IR is known as a data-flow graph (DFG). Instead\nof talking about syntax-entities (like <code>for loop</code>s, <code>expressions</code>, ...), we\nshould talk about the data itself (read, variables values), and how it changes\nthrough the program.</p>\n<h2>Data-flow Graph</h2>\n<p>In our particular example, the data we are interested in is the value of\nvariable <code>arr</code>. We want to be able to easily observe all uses of it to verify\nthat there are no out-of-bounds accesses or any other change that would modify\nthe length of the array.</p>\n<p>This is accomplished by introducing &quot;def-use&quot; (definition and uses) relationship\nbetween the different data values. Concretely, it means that the value has been\ndeclared once (<em>node</em>), and that it has been used somewhere to create new values\n(<em>edge</em> for every use). Obviously, connecting different values together will\nform a <strong>data-flow graph</strong> like this:</p>\n<p><img src="/images/data-flow.svg" alt="Data-flow Graph"></p>\n<p>Note the red <code>array</code> box in this vast graph. The solid arrows going out of it\nrepresent uses of this value. By iterating over those edges, the compiler can\nderive that the value of <code>array</code> is used at:</p>\n<ul>\n<li><code>loadArrayLength</code></li>\n<li><code>checkIndex</code></li>\n<li><code>load</code></li>\n</ul>\n<p>Such graphs are constructed in the way that explicitly &quot;clones&quot; the array node,\nif its value was accessed in a destructive manner (i.e. stores, length sizes).\nWhenever we see <code>array</code> node and observe its uses - we are always certain that\nits value does not change.</p>\n<p>It may sound complicated, but this property of the graph is quite easy to\nachieve. The graph should follow <a href="https://en.wikipedia.org/wiki/Static_single_assignment_form">Single Static Assignment</a> (SSA) rules.\nIn short, to convert any program to <a href="https://en.wikipedia.org/wiki/Static_single_assignment_form">SSA</a> the compiler needs to rename all\nassignments and later uses of the variables, to make sure that each variable is\nassigned only once.</p>\n<p>Example, before SSA:</p>\n<pre><code class="language-javascript"><span class="hljs-keyword">var</span> a = <span class="hljs-number">1</span>;\n<span class="hljs-built_in">console</span>.log(a);\na = <span class="hljs-number">2</span>;\n<span class="hljs-built_in">console</span>.log(a);\n</code></pre>\n<p>After SSA:</p>\n<pre><code class="language-javascript"><span class="hljs-keyword">var</span> a0 = <span class="hljs-number">1</span>;\n<span class="hljs-built_in">console</span>.log(a0);\n<span class="hljs-keyword">var</span> a1 = <span class="hljs-number">2</span>;\n<span class="hljs-built_in">console</span>.log(a1);\n</code></pre>\n<p>This way, we can be sure that when we are talking about <code>a0</code> - we are actually\ntalking about a single assignment to it. This is really close to how people do\nthings in the functional languages!</p>\n<p>Seeing that <code>loadArrayLength</code> has no control dependency (i.e. no dashed lines;\nwe will talk about them in a bit), compiler may conclude that this node is free\nto move anywhere it wants to be and can be placed outside of the loop.\nBy going through the graph further, we may observe that the value of <code>ssa:phi</code>\nnode is always between <code>0</code> and <code>arr.length</code>, so the <code>checkIndex</code> may be removed\naltogether.</p>\n<p>Pretty neat, isn\'t it?</p>\n<h2>Control Flow Graph</h2>\n<p>We just used some form of <a href="https://en.wikipedia.org/wiki/Data-flow_analysis">data-flow analysis</a> to extract information from\nthe program. This allows us to make safe assumptions about how it could be\noptimized.</p>\n<p>This <em>data-flow representation</em> is very useful in many other cases too. The only\nproblem is that by turning our code into this kind of graph, we made a step\nbackwards in our representation chain (from the source code to the machine\ncode). This intermediate representation is less suitable for generating machine\ncode than even the AST.</p>\n<p>The reason is that the machine is just a sequential list of instructions, which\nthe CPU executes one-after-another. Our resulting graph doesn\'t appear to\nconvey that. In fact, there is no enforced ordering in it at all.</p>\n<p>Usually, this is solved by grouping the graph nodes into blocks. This\nrepresentation is known as a <a href="https://en.wikipedia.org/wiki/Control_flow_graph">Control Flow Graph</a> (CFG). Example:</p>\n<pre><code>b0 {\n  i0 = literal 0\n  i1 = literal 0\n\n  i3 = array\n  i4 = jump ^b0\n}\nb0 -&gt; b1\n\nb1 {\n  i5 = ssa:phi ^b1 i0, i12\n  i6 = ssa:phi ^i5, i1, i14\n\n  i7 = loadArrayLength i3\n  i8 = cmp &quot;&lt;&quot;, i6, i7\n  i9 = if ^i6, i8\n}\nb1 -&gt; b2, b3\nb2 {\n  i10 = checkIndex ^b2, i3, i6\n  i11 = load ^i10, i3, i6\n  i12 = add i5, i11\n  i13 = literal 1\n  i14 = add i6, i13\n  i15 = jump ^b2\n}\nb2 -&gt; b1\n\nb3 {\n  i16 = exit ^b3\n}\n</code></pre>\n<p>It is called a graph not without the reason. For example, the <code>bXX</code> blocks\nrepresent nodes, and the <code>bXX -&gt; bYY</code> arrows represent edges. Let\'s visualize\nit:</p>\n<p><img src="/images/cfg.svg" alt="CFG"></p>\n<p>As you can see, there is code before the loop in block <code>b0</code>, loop header in\n<code>b1</code>, loop test in <code>b2</code>, loop body in <code>b3</code>, and exit node in <code>b4</code>.</p>\n<p>Translation to machine code is very easy from this form. We just replace <code>iXX</code>\nidentifiers with CPU register names (in some sense, CPU registers are sort of\nvariables, the CPU has a limited amount of registers, so we need to be careful\nto not run out of them), and generating machine code for each instruction,\nline-by-line.</p>\n<p>To recap, <a href="https://en.wikipedia.org/wiki/Control_flow_graph">CFG</a> has data-flow relations and also ordering. This allows us to\nutilize it for both data-flow analysis and machine code generation. However,\nattempting to optimize the CFG, by manipulating the blocks and their contents\ncontained within it, can quickly become complex and error-prone.</p>\n<p>Instead, Clifford Click and Keith D. Cooper proposed to use an approach\ncalled <a href="http://www.researchgate.net/profile/Cliff_Click/publication/2394127_Combining_Analyses_Combining_Optimizations/links/0a85e537233956f6dd000000.pdf"><strong>sea-of-nodes</strong></a>, the very topic of this blog post!</p>\n<h2>Sea-of-Nodes</h2>\n<p>Remember our fancy data-flow graph with dashed lines? Those dashed-lines are\nactually what make that graph a <strong>sea-of-nodes</strong> graph.</p>\n<p>Instead of grouping nodes in blocks and ordering them, we choose to declare the\ncontrol dependencies as the dashed edges in a graph. If we will take that graph,\nremove everything <strong>non-dashed</strong>, and group things a bit we will get:</p>\n<p><img src="/images/control-flow-sea.svg" alt="Control-flow part of Sea-of-Nodes"></p>\n<p>With a bit of imagination and node reordering, we can see that this graph is the\nsame as the simplified CFG graphs that we have just seen above:</p>\n<p><img src="/images/cfg.svg" alt="CFG"></p>\n<p>Let\'s take another look at the <strong>sea-of-nodes</strong> representation:</p>\n<p><img src="/images/data-flow.svg" alt="Sea-of-Nodes"></p>\n<p>The striking difference between this graph and CFG is that there is no ordering\nof the nodes, except the ones that have control dependencies (in other words,\nthe nodes participating in the control flow).</p>\n<p>This representation is very powerful way to look at the code. It has all\ninsights of the general data-flow graph, and could be changed easily without\nconstantly removing/replacing nodes in the blocks.</p>\n<h2>Reductions</h2>\n<p>Speaking of changes, let\'s discuss the way to modify the graph. The sea-of-nodes\ngraph is usually modified by doing graph reductions. We just queue all nodes in\nthe graph. Invoke our reduction function for every node in the queue. Everything\nthat this function touches (changes, replaces) is queued back, and will be\npassed to the function later on. If you have many reductions, you can just stack\nthem up together and invoke all of them on each node in the queue, or\nalternatively, you can just apply them one after another, if they depend on the\nfinal state of each other. It works like a charm!</p>\n<p>I have written a JavaScript toolset for my sea-of-nodes experiments, which\nincludes:</p>\n<ul>\n<li><a href="https://github.com/indutny/json-pipeline">json-pipeline</a> - the builder and stdlib of the graph. Provides methods\nto create nodes, add inputs to them, change their control dependencies, and\nexport/import the graph to/from the printable data!</li>\n<li><a href="https://github.com/indutny/json-pipeline-reducer">json-pipeline-reducer</a> - the reductions engine. Just create a reducer\ninstance, feed it several reduction functions, and execute the reducer on the\nexisting <a href="https://github.com/indutny/json-pipeline">json-pipeline</a> graph.</li>\n<li><a href="https://github.com/indutny/json-pipeline-scheduler">json-pipeline-scheduler</a> - library for putting back unordered graph in a\nlimited amount of blocks connected to each other by control edges (dashed\nlines).</li>\n</ul>\n<p>Combined together, these tools can solve many problems that could be formulated\nin terms of data-flow equations.</p>\n<p>Example of reduction, which will optimize our initial JS code:</p>\n<pre><code class="language-javascript"><span class="hljs-keyword">for</span> (<span class="hljs-keyword">var</span> i = <span class="hljs-number">0</span>, acc = <span class="hljs-number">0</span>; i &lt; arr.length; i++)\n  acc += arr[i];\n</code></pre>\n<h3>TL;DR</h3>\n<p>This code chunk is quite big, so if you want to skip it - here are the notes of\nwhat we will do below:</p>\n<ul>\n<li>Compute integer ranges of various nodes: literal, add, phi</li>\n<li>Compute limits that apply to branch\'s body</li>\n<li>Apply range and limit information (<code>i</code> is always a non-negative number limited\nby <code>arr.length</code>) to conclude that length check is not necessary and can be\nremoved</li>\n<li><code>arr.length</code> will be moved out of the loop automatically by\n<code>json-pipeline-scheduler</code>. This is because it does <a href="https://courses.cs.washington.edu/courses/cse501/04wi/papers/click-pldi95.pdf">Global Code Motion</a> to\nschedule nodes in blocks.</li>\n</ul>\n<pre><code class="language-js"><span class="hljs-comment">// Just for viewing graphviz output</span>\n<span class="hljs-keyword">var</span> fs = <span class="hljs-built_in">require</span>(<span class="hljs-string">\'fs\'</span>);\n\n<span class="hljs-keyword">var</span> Pipeline = <span class="hljs-built_in">require</span>(<span class="hljs-string">\'json-pipeline\'</span>);\n<span class="hljs-keyword">var</span> Reducer = <span class="hljs-built_in">require</span>(<span class="hljs-string">\'json-pipeline-reducer\'</span>);\n<span class="hljs-keyword">var</span> Scheduler = <span class="hljs-built_in">require</span>(<span class="hljs-string">\'json-pipeline-scheduler\'</span>);\n\n<span class="hljs-comment">//</span>\n<span class="hljs-comment">// Create empty graph with CFG convenience</span>\n<span class="hljs-comment">// methods.</span>\n<span class="hljs-comment">//</span>\n<span class="hljs-keyword">var</span> p = Pipeline.create(<span class="hljs-string">\'cfg\'</span>);\n\n<span class="hljs-comment">//</span>\n<span class="hljs-comment">// Parse the printable data and generate</span>\n<span class="hljs-comment">// the graph.</span>\n<span class="hljs-comment">//</span>\np.parse(<span class="hljs-string">`pipeline {\n  b0 {\n    i0 = literal 0\n    i1 = literal 0\n\n    i3 = array\n    i4 = jump ^b0\n  }\n  b0 -&gt; b1\n\n  b1 {\n    i5 = ssa:phi ^b1 i0, i12\n    i6 = ssa:phi ^i5, i1, i14\n\n    i7 = loadArrayLength i3\n    i8 = cmp "&lt;", i6, i7\n    i9 = if ^i6, i8\n  }\n  b1 -&gt; b2, b3\n  b2 {\n    i10 = checkIndex ^b2, i3, i6\n    i11 = load ^i10, i3, i6\n    i12 = add i5, i11\n    i13 = literal 1\n    i14 = add i6, i13\n    i15 = jump ^b2\n  }\n  b2 -&gt; b1\n\n  b3 {\n    i16 = exit ^b3\n  }\n}`</span>, { <span class="hljs-attr">cfg</span>: <span class="hljs-literal">true</span> }, <span class="hljs-string">\'printable\'</span>);\n\n<span class="hljs-keyword">if</span> (process.env.DEBUG)\n  fs.writeFileSync(<span class="hljs-string">\'before.gv\'</span>, p.render(<span class="hljs-string">\'graphviz\'</span>));\n\n<span class="hljs-comment">//</span>\n<span class="hljs-comment">// Just a helper to run reductions</span>\n<span class="hljs-comment">//</span>\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">reduce</span>(<span class="hljs-params">graph, reduction</span>) </span>{\n  <span class="hljs-keyword">var</span> reducer = <span class="hljs-keyword">new</span> Reducer();\n  reducer.addReduction(reduction);\n  reducer.reduce(graph);\n\n}\n\n<span class="hljs-comment">//</span>\n<span class="hljs-comment">// Create reduction</span>\n<span class="hljs-comment">//</span>\n<span class="hljs-keyword">var</span> ranges = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Map</span>();\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">getRange</span>(<span class="hljs-params">node</span>) </span>{\n  <span class="hljs-keyword">if</span> (ranges.has(node))\n    <span class="hljs-keyword">return</span> ranges.get(node);\n\n  <span class="hljs-keyword">var</span> range = { <span class="hljs-attr">from</span>: -<span class="hljs-literal">Infinity</span>, <span class="hljs-attr">to</span>: +<span class="hljs-literal">Infinity</span>, <span class="hljs-attr">type</span>: <span class="hljs-string">\'any\'</span> };\n  ranges.set(node, range);\n  <span class="hljs-keyword">return</span> range;\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">updateRange</span>(<span class="hljs-params">node, reducer, from, to</span>) </span>{\n  <span class="hljs-keyword">var</span> range = getRange(node);\n\n  <span class="hljs-comment">// Lowest type, can\'t get upwards</span>\n  <span class="hljs-keyword">if</span> (range.type === <span class="hljs-string">\'none\'</span>)\n    <span class="hljs-keyword">return</span>;\n\n  <span class="hljs-keyword">if</span> (range.from === <span class="hljs-keyword">from</span> &amp;&amp; range.to === to &amp;&amp; range.type === <span class="hljs-string">\'int\'</span>)\n    <span class="hljs-keyword">return</span>;\n\n  range.from = <span class="hljs-keyword">from</span>;\n  range.to = to;\n  range.type = <span class="hljs-string">\'int\'</span>;\n  reducer.change(node);\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">updateType</span>(<span class="hljs-params">node, reducer, type</span>) </span>{\n  <span class="hljs-keyword">var</span> range = getRange(node);\n\n  <span class="hljs-keyword">if</span> (range.type === type)\n    <span class="hljs-keyword">return</span>;\n\n  range.type = type;\n  reducer.change(node);\n}\n\n<span class="hljs-comment">//</span>\n<span class="hljs-comment">// Set type of literal</span>\n<span class="hljs-comment">//</span>\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">reduceLiteral</span>(<span class="hljs-params">node, reducer</span>) </span>{\n  <span class="hljs-keyword">var</span> value = node.literals[<span class="hljs-number">0</span>];\n  updateRange(node, reducer, value, value);\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">reduceBinary</span>(<span class="hljs-params">node, left, right, reducer</span>) </span>{\n  <span class="hljs-keyword">if</span> (left.type === <span class="hljs-string">\'none\'</span> || right.type === <span class="hljs-string">\'none\'</span>) {\n    updateType(node, reducer, <span class="hljs-string">\'none\'</span>);\n    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;\n  }\n\n  <span class="hljs-keyword">if</span> (left.type === <span class="hljs-string">\'int\'</span> || right.type === <span class="hljs-string">\'int\'</span>)\n    updateType(node, reducer, <span class="hljs-string">\'int\'</span>);\n\n  <span class="hljs-keyword">if</span> (left.type !== <span class="hljs-string">\'int\'</span> || right.type !== <span class="hljs-string">\'int\'</span>)\n    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;\n\n  <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;\n}\n\n<span class="hljs-comment">//</span>\n<span class="hljs-comment">// Just join the ranges of inputs</span>\n<span class="hljs-comment">//</span>\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">reducePhi</span>(<span class="hljs-params">node, reducer</span>) </span>{\n  <span class="hljs-keyword">var</span> left = getRange(node.inputs[<span class="hljs-number">0</span>]);\n  <span class="hljs-keyword">var</span> right = getRange(node.inputs[<span class="hljs-number">1</span>]);\n\n  <span class="hljs-keyword">if</span> (!reduceBinary(node, left, right, reducer))\n    <span class="hljs-keyword">return</span>;\n\n  <span class="hljs-keyword">if</span> (node.inputs[<span class="hljs-number">1</span>].opcode !== <span class="hljs-string">\'add\'</span> || left.from !== left.to)\n    <span class="hljs-keyword">return</span>;\n\n  <span class="hljs-keyword">var</span> <span class="hljs-keyword">from</span> = <span class="hljs-built_in">Math</span>.min(left.from, right.from);\n  <span class="hljs-keyword">var</span> to = <span class="hljs-built_in">Math</span>.max(left.to, right.to);\n  updateRange(node, reducer, <span class="hljs-keyword">from</span>, to);\n}\n\n<span class="hljs-comment">//</span>\n<span class="hljs-comment">// Detect: phi = phi + &lt;positive number&gt;, where initial phi is number,</span>\n<span class="hljs-comment">// report proper range.</span>\n<span class="hljs-comment">//</span>\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">reduceAdd</span>(<span class="hljs-params">node, reducer</span>) </span>{\n  <span class="hljs-keyword">var</span> left = getRange(node.inputs[<span class="hljs-number">0</span>]);\n  <span class="hljs-keyword">var</span> right = getRange(node.inputs[<span class="hljs-number">1</span>]);\n\n  <span class="hljs-keyword">if</span> (!reduceBinary(node, left, right, reducer))\n    <span class="hljs-keyword">return</span>;\n\n  <span class="hljs-keyword">var</span> phi = node.inputs[<span class="hljs-number">0</span>];\n  <span class="hljs-keyword">if</span> (phi.opcode !== <span class="hljs-string">\'ssa:phi\'</span> || right.from !== right.to)\n    <span class="hljs-keyword">return</span>;\n\n  <span class="hljs-keyword">var</span> number = right.from;\n  <span class="hljs-keyword">if</span> (number &lt;= <span class="hljs-number">0</span> || phi.inputs[<span class="hljs-number">1</span>] !== node)\n    <span class="hljs-keyword">return</span>;\n\n  <span class="hljs-keyword">var</span> initial = getRange(phi.inputs[<span class="hljs-number">0</span>]);\n  <span class="hljs-keyword">if</span> (initial.type !== <span class="hljs-string">\'int\'</span>)\n    <span class="hljs-keyword">return</span>;\n\n  updateRange(node, reducer, initial.from, +<span class="hljs-literal">Infinity</span>);\n}\n\n<span class="hljs-keyword">var</span> limits = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Map</span>();\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">getLimit</span>(<span class="hljs-params">node</span>) </span>{\n  <span class="hljs-keyword">if</span> (limits.has(node))\n    <span class="hljs-keyword">return</span> limits.get(node);\n\n  <span class="hljs-keyword">var</span> map = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Map</span>();\n  limits.set(node, map);\n  <span class="hljs-keyword">return</span> map;\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">updateLimit</span>(<span class="hljs-params">holder, node, reducer, type, value</span>) </span>{\n  <span class="hljs-keyword">var</span> map = getLimit(holder);\n  <span class="hljs-keyword">if</span> (!map.has(node))\n    map.set(node, { <span class="hljs-attr">type</span>: <span class="hljs-string">\'any\'</span>, <span class="hljs-attr">value</span>: <span class="hljs-literal">null</span> });\n\n  <span class="hljs-keyword">var</span> limit = map.get(node);\n  <span class="hljs-keyword">if</span> (limit.type === type &amp;&amp; limit.value === value)\n    <span class="hljs-keyword">return</span>;\n  limit.type = type;\n  limit.value = value;\n  reducer.change(holder);\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">mergeLimit</span>(<span class="hljs-params">node, reducer, other</span>) </span>{\n  <span class="hljs-keyword">var</span> map = getLimit(node);\n  <span class="hljs-keyword">var</span> otherMap = getLimit(other);\n\n  otherMap.forEach(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">limit, key</span>) </span>{\n    updateLimit(node, key, reducer, limit.type, limit.value);\n  });\n}\n\n<span class="hljs-comment">//</span>\n<span class="hljs-comment">// Propagate limit from: X &lt; Y to `if`\'s true branch</span>\n<span class="hljs-comment">//</span>\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">reduceIf</span>(<span class="hljs-params">node, reducer</span>) </span>{\n  <span class="hljs-keyword">var</span> test = node.inputs[<span class="hljs-number">0</span>];\n  <span class="hljs-keyword">if</span> (test.opcode !== <span class="hljs-string">\'cmp\'</span> || test.literals[<span class="hljs-number">0</span>] !== <span class="hljs-string">\'&lt;\'</span>)\n    <span class="hljs-keyword">return</span>;\n\n  <span class="hljs-keyword">var</span> left = test.inputs[<span class="hljs-number">0</span>];\n  <span class="hljs-keyword">var</span> right = test.inputs[<span class="hljs-number">1</span>];\n\n  updateLimit(node.controlUses[<span class="hljs-number">0</span>], left, reducer, <span class="hljs-string">\'&lt;\'</span>, right);\n  updateLimit(node.controlUses[<span class="hljs-number">2</span>], left, reducer, <span class="hljs-string">\'&gt;=\'</span>, right);\n}\n\n<span class="hljs-comment">//</span>\n<span class="hljs-comment">// Determine ranges and limits of</span>\n<span class="hljs-comment">// the values.</span>\n<span class="hljs-comment">//</span>\n\n<span class="hljs-keyword">var</span> rangeAndLimit = <span class="hljs-keyword">new</span> Reducer.Reduction({\n  <span class="hljs-attr">reduce</span>: <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">node, reducer</span>) </span>{\n    <span class="hljs-keyword">if</span> (node.opcode === <span class="hljs-string">\'literal\'</span>)\n      reduceLiteral(node, reducer);\n    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (node.opcode === <span class="hljs-string">\'ssa:phi\'</span>)\n      reducePhi(node, reducer);\n    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (node.opcode === <span class="hljs-string">\'add\'</span>)\n      reduceAdd(node, reducer);\n    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (node.opcode === <span class="hljs-string">\'if\'</span>)\n      reduceIf(node, reducer);\n  }\n});\nreduce(p, rangeAndLimit);\n\n<span class="hljs-comment">//</span>\n<span class="hljs-comment">// Now that we have ranges and limits,</span>\n<span class="hljs-comment">// time to remove the useless array</span>\n<span class="hljs-comment">// length checks.</span>\n<span class="hljs-comment">//</span>\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">reduceCheckIndex</span>(<span class="hljs-params">node, reducer</span>) </span>{\n  <span class="hljs-comment">// Walk up the control chain</span>\n  <span class="hljs-keyword">var</span> region = node.control[<span class="hljs-number">0</span>];\n  <span class="hljs-keyword">while</span> (region.opcode !== <span class="hljs-string">\'region\'</span> &amp;&amp; region.opcode !== <span class="hljs-string">\'start\'</span>)\n    region = region.control[<span class="hljs-number">0</span>];\n\n  <span class="hljs-keyword">var</span> array = node.inputs[<span class="hljs-number">0</span>];\n  <span class="hljs-keyword">var</span> index = node.inputs[<span class="hljs-number">1</span>];\n\n  <span class="hljs-keyword">var</span> limit = getLimit(region).get(index);\n  <span class="hljs-keyword">if</span> (!limit)\n    <span class="hljs-keyword">return</span>;\n\n  <span class="hljs-keyword">var</span> range = getRange(index);\n\n  <span class="hljs-comment">// Negative array index is not valid</span>\n  <span class="hljs-keyword">if</span> (range.from &lt; <span class="hljs-number">0</span>)\n    <span class="hljs-keyword">return</span>;\n\n  <span class="hljs-comment">// Index should be limited by array length</span>\n  <span class="hljs-keyword">if</span> (limit.type !== <span class="hljs-string">\'&lt;\'</span> ||\n      limit.value.opcode !== <span class="hljs-string">\'loadArrayLength\'</span> ||\n      limit.value.inputs[<span class="hljs-number">0</span>] !== array) {\n    <span class="hljs-keyword">return</span>;\n  }\n\n  <span class="hljs-comment">// Check is safe to remove!</span>\n  reducer.remove(node);\n}\n\n<span class="hljs-keyword">var</span> eliminateChecks = <span class="hljs-keyword">new</span> Reducer.Reduction({\n  <span class="hljs-attr">reduce</span>: <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">node, reducer</span>) </span>{\n    <span class="hljs-keyword">if</span> (node.opcode === <span class="hljs-string">\'checkIndex\'</span>)\n      reduceCheckIndex(node, reducer);\n  }\n});\nreduce(p, eliminateChecks);\n\n<span class="hljs-comment">//</span>\n<span class="hljs-comment">// Run scheduler to put everything</span>\n<span class="hljs-comment">// back to the CFG</span>\n<span class="hljs-comment">//</span>\n\n<span class="hljs-keyword">var</span> out = Scheduler.create(p).run();\nout.reindex();\n\n<span class="hljs-keyword">if</span> (process.env.DEBUG)\n  fs.writeFileSync(<span class="hljs-string">\'after.gv\'</span>, out.render(<span class="hljs-string">\'graphviz\'</span>));\n\n<span class="hljs-built_in">console</span>.log(out.render({ <span class="hljs-attr">cfg</span>: <span class="hljs-literal">true</span> }, <span class="hljs-string">\'printable\'</span>));\n</code></pre>\n<p>Thank you for reading this. Please expect more information about this\nsea-of-nodes approach.</p>\n<hr>\n<p>Special thanks to <a href="https://github.com/paulfryzel">Paul Fryzel</a> for proof-reading this, and providing\nvaluable feedback and grammar fixes!</p>\n'},{slug:"c.cpp-in-node",title:"Diving into C++ internals of node",date:"2015-05-16T00:00:00.000Z",html:'<h2>Intro</h2>\n<p>There is nothing to be scared about in the C++ internals of the project,\nespecially in internals of <a href="https://github.com/nodejs/io.js">io.js</a> and <a href="https://github.com/nodejs/node">node.js</a>.</p>\n<p>If you ever tried to optimize JavaScript code to squeeze out every possible\nperformance or memory usage improvement out of it - you already wrote some C++\ncode.</p>\n<p>Many blogs, workshops mention JavaScript optimizations, and some of the popular\nsuggestions are:</p>\n<h3>Hidden Classes</h3>\n<p>Declare all properties in the constructor to avoid creating extra\n&quot;hidden classes&quot;. This makes them pretty much the same as a C structures,\nor C++ classes, where properties are declared ahead of time to help the\ncompiler optimize access to them.</p>\n<p>Example:</p>\n<pre><code class="language-javascript"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">Point</span>(<span class="hljs-params">x, y, z</span>) </span>{\n  <span class="hljs-keyword">this</span>.x = x\n  <span class="hljs-keyword">this</span>.y = y\n  <span class="hljs-keyword">this</span>.z = z\n}\n</code></pre>\n<p>Similar code in C++:</p>\n<pre><code class="language-c"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Point</span> {</span>\n <span class="hljs-keyword">public</span>:\n  <span class="hljs-keyword">double</span> x;\n  <span class="hljs-keyword">double</span> y;\n  <span class="hljs-keyword">double</span> z;\n};\n</code></pre>\n<h3>Avoid Polymorphism</h3>\n<p>Avoid storing different types of values in a variables, and avoid passing\ndifferent types of values as an arguments to the function. This principle could\nalso be called &quot;Make your code monomorphic&quot;, or &quot;don\'t mess with Compiler&quot;.\nThis makes code look like as it has static typing, which is what we do in\nC++.</p>\n<pre><code class="language-javascript"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">add</span>(<span class="hljs-params">x, y</span>) </span>{\n  <span class="hljs-keyword">return</span> x + y;\n}\n\nadd(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>); <span class="hljs-comment">// &lt;- good</span>\nadd(<span class="hljs-string">\'foo\'</span>, <span class="hljs-string">\'bar\'</span>); <span class="hljs-comment">// &lt;- polymorphism!</span>\n</code></pre>\n<p>Compare to:</p>\n<pre><code class="language-c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-keyword">int</span> x, <span class="hljs-keyword">int</span> y)</span> </span>{\n  <span class="hljs-keyword">return</span> x + y;\n}\n</code></pre>\n<h3>Cache and Reuse</h3>\n<p>Cache and reuse instances of objects that are expensive to create and are\nallocated often. This is one is similar to manual memory allocation in C++.</p>\n<pre><code class="language-javascript"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">Parser</span>(<span class="hljs-params"></span>) </span>{\n}\n\nParser.freelist = [];\n\nParser.get = <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n  <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>.freelist.length)\n    <span class="hljs-keyword">return</span> <span class="hljs-keyword">this</span>.freelist.pop();\n  <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Parser();\n};\n\nParser.prototype.release = ...;\n</code></pre>\n<p>In C++:</p>\n<pre><code class="language-c">Parser* p = <span class="hljs-keyword">new</span> Parser();\n<span class="hljs-keyword">delete</span> p;\n</code></pre>\n<p>To conclude, even if you never wrote C++ code, you actually very likely did it\nin JS.</p>\n<p>It is no surprise we use C++ in io.js/node.js. After all, V8 is written in C++\nand it provides only a limited set of ECMAScript JavaScript APIs. They are\ndefinitely cool, but if you got used to <code>setTimeout()</code> / <code>clearTimeout()</code> -\nyou\'ll be pretty disappointed to use just plain ECMA.</p>\n<p>Our C++ layer lives on top of the event-loop and provides all sorts of APIs:\nfrom net sockets to dns queries, from file system events to the zlib bindings.\nWhich is the main reason why node.js was created in the first place!</p>\n<h2>Short History of C++ layer</h2>\n<p><img src="/images/history_of_git_blame.jpg" alt="History of git blame"></p>\n<p>To better understand all of these, and to ease the contribution process - it\nmight be a good idea to start with the history of the subject. Luckily, from its\ninception, node.js is using VCS, in particular git, so the history of the\ndevelopment might be revealed by running <code>git log</code> and <code>git blame</code> on it.</p>\n<p>Briefly, <code>git log deps/v8</code> - has the history of v8 fighting us, and\n<code>git log src/</code> - has the history of us fighting v8.</p>\n<h2>Very first version</h2>\n<p>Jokes aside, everything started from <a href="https://github.com/nodejs/io.js/commit/61890720">61890720</a> commit. The commit log\njust says:</p>\n<pre><code>add readme and initial code\n</code></pre>\n<p>Unfortunately, we can\'t elaborate much from it, and need to figure out the\ndetails ourselves. What do we see there?</p>\n<ul>\n<li><a href="https://github.com/taf2/libebb">libebb</a> - which was used as an HTTP parser. Ryan used the code\nfrom the <a href="https://github.com/gnosek/ebb">Ebb</a> server that he has previously written for Ruby</li>\n<li><a href="https://cs.fit.edu/code/projects/cse2410_fall2014_bounce/repository/revisions/90fc8d36220c0d66c352ee5f72080b8592d310d5/show/deps/liboi">liboi</a>- which was as a TCP server framework on top of the <a href="http://software.schmorp.de/pkg/libev.html">libev</a>.\nliboi stands for <code>Library for Output Input</code></li>\n</ul>\n<p>So the first code (that actually started compiling only at <a href="https://github.com/nodejs/io.js/commit/7b7ceea">7b7ceea</a>) only\nhad one HTTP server and supplied JavaScript source code was just a handler for\nit.</p>\n<pre><code class="language-javacsript">function Process(request) {\n  if (options.verbose) {\n    log(&quot;Processing &quot; + request.host +\n        request.path +\n        &quot; from &quot; + request.referrer +\n        &quot;@&quot; + request.userAgent);\n  }\n  if (!output[request.host])\n    output[request.host] = 1;\n  else\n    output[request.host]++\n}\n</code></pre>\n<p>How was it organized internally?</p>\n<p>There was a <code>server.cc</code> file which was reading the command line options, loading\nthe JavaScript source file, feeding all of these into V8, and starting the HTTP\nserver.</p>\n<p>Second C++ file was <code>js_http_request_processor.cc</code> and it was responsible for\ninvoking the JavaScript http request handler. Not that much for a separate C++\nfile, right?</p>\n<p>It wasn\'t working that much at that point, and didn\'t have any of\nfunctionality that is provided today. So let\'s conclude and move on from it\nquickly.</p>\n<p>This version is characterized by following:</p>\n<ul>\n<li>One file to setup V8 and let JavaScript know about command-line arguments</li>\n<li>HTTP server fully implemented in C/C++, not invoking the JavaScript for any\nnetworking activities</li>\n<li>One C++ instance per every incoming request, this instance maps some of the\nHTTP fields (like host, url, method) to the JavaScript object.</li>\n</ul>\n<p>The last bullet point is very important to note: the C++ instance &lt;-&gt; JS object\nmapping is a building brick of all future releases of node.js (including the\npresent one).</p>\n<h2>064c8f02</h2>\n<p>Now we quickly jump to <a href="https://github.com/nodejs/io.js/commit/064c8f02">064c8f02</a>. The commit log says:</p>\n<pre><code>Use ObjectWrap base class for File, Socket, Server.\n</code></pre>\n<p>And this is the point where node.js has introduced one API to wrap all objects.</p>\n<p><code>net.Server</code>, <code>net.Socket</code>, and <code>File</code> C++ classes are children of this\n<code>ObjectWrap</code> class. Which means that for every instance of them -\nthere will be one instance of a JS object. Invoking methods on this JS object\nwill invoke C++ methods on the corresponding C++ class, and the constructor\nitself is a C++ class constructor.</p>\n<p>There are now different files for different parts of the provided API:</p>\n<ul>\n<li><code>src/node.cc</code> to set up C++ libraries and invoke <code>src/main.js</code> which\nloads the script file and does some JavaScript initialization. (At this commit\nwe started to write as much code as possible in JavaScript, and leave\nthe rest in the C++ land. This pattern is used in io.js and node.js now too)</li>\n<li><code>src/http.cc</code> - http server API, Connection, HttpRequest objects</li>\n<li><code>src/file.cc</code>, <code>src/file.js</code> - future <code>fs</code> module.\n<code>src/file.js</code> consists of the API abstractions for the C++ layer,\nbasically the same thing as with <code>src/node.cc</code> and <code>src/main.js</code></li>\n<li><code>src/process.cc</code> has only <code>exit()</code> method so far, will evolve into the\n<code>process</code> object</li>\n<li><code>src/timers.cc</code> is about <code>setTimeout</code>/<code>setInterval</code></li>\n</ul>\n<p>Just a side note: HTTP server is still provided by <a href="https://cs.fit.edu/code/projects/cse2410_fall2014_bounce/repository/revisions/90fc8d36220c0d66c352ee5f72080b8592d310d5/show/deps/liboi">liboi</a>, and node.js is\nusing <a href="http://software.schmorp.de/pkg/libev.html">libev</a>.</p>\n<h2>v0.2</h2>\n<p>There was lots of growing and maturing from that commit to the v0.2, and most\nnotable of them were about separating the JS parts from the C++ ones,\nadding CommonJS support, and tons of new modules! The file structure is\nbeginning to look like what we have now:</p>\n<ul>\n<li><code>lib/</code> folder for all JavaScript CommonJS modules</li>\n<li><code>src/</code> for their C++ counterparts</li>\n<li><code>deps/</code> for all dependencies: v8, http-parser, c-ares (for async DNS),\nlibeio (for async FS), and libev (for async networking and auxiliary stuff)</li>\n</ul>\n<p>Previously barely used through the <code>src/</code>, <code>ObjectWrap</code> now became a public API,\nwhich helped polish it out a lot and improved our core use case as well.</p>\n<p>Very importantly, in <a href="https://github.com/nodejs/io.js/commit/064c8f02">064c8f02</a> all C++ interfaces were global objects. In\nv0.2 they are provided by <code>process.binding</code> and are thus not directly visible to\nthe user\'s code.</p>\n<p>For example, <code>process.binding(\'fs\')</code>:</p>\n<pre><code class="language-javascript">&gt; process.binding(<span class="hljs-string">\'fs\'</span>);\n{ <span class="hljs-attr">access</span>: [<span class="hljs-built_in">Function</span>: access],\n  <span class="hljs-attr">close</span>: [<span class="hljs-built_in">Function</span>: close],\n  <span class="hljs-attr">open</span>: [<span class="hljs-built_in">Function</span>: open],\n  ...lots <span class="hljs-keyword">of</span> stuff...\n</code></pre>\n<p>returns lots of C++ methods and classes that are heavily used for interoperation\nbetween C++ and JS in <code>lib/fs.js</code>. Similar stuff is done for the rest of the\n<code>lib/</code> modules.</p>\n<h2>v0.6</h2>\n<p>Just a short note: <code>libev</code> was removed and replaced by <a href="https://github.com/libuv/libuv">libuv</a>. A product of\nlots of work by Ben Noordhuis, Bert Belder, Ryan Dahl, and others!</p>\n<p>The v0.6 version is a major milestone in evolution of node.js. Partly because\nWindows is now in the list of the officially supported platforms, partly because\nwe have our own single event-loop platform that supports both async File System\nand async networking operations.</p>\n<h2>v0.10</h2>\n<p>Good, stable, but boring...</p>\n<h2>v0.12 and io.js</h2>\n<p>Lots of new stuff! :)</p>\n<p>Mainly, we have outgrown the <code>ObjectWrap</code> to accommodate the tracing API (which\nis still needs lots of rework, AFAIK). The hip thing now is <code>AsyncWrap</code> which is\nin many ways the same thing, but now is attached to some particular domain of\noperation (i.e. http, dns, tls) and which might have the another <code>AsyncWrap</code> as\na parent. Note that <code>ObjectWrap</code> lives in <code>src/node_object_wrap.h</code>, and\n<code>AsyncWrap</code> in <code>src/async-wrap.h</code>.</p>\n<p>This is now the present point of the node.js evolution, and I would like to\nstop with the Software Archeology at this point.</p>\n<h2>Interoperation, handles, wraps, and unicorns!</h2>\n<p>We are finally ready to dive into the C++ internals, and explore them in a\ngreater detail.</p>\n<p>As we already figured out - whole APIs provided by the node.js/io.js live in\ntwo folders: <code>lib</code> and <code>src</code>. <code>lib</code> holds the core modules, <code>src</code> holds their\nC++ counterparts.</p>\n<p>When you call <code>require(\'fs\')</code> - it does nothing but just executes the contents\nof the <code>lib/fs.js</code> file. No magic here.</p>\n<p>Now comes the interesting part, JavaScript is not capable of file system\noperations, nor it is capable of networking. This is actually for the\nbest! (You don\'t want your browser to mess up whole file system,\nright?) So when you do <code>fs.writeFileSync</code>, or when you are calling\n<code>http.request()</code> there is a lot of low-level C++ stuff happening outside of the\nJS-land.</p>\n<p>While the <code>fs</code> module is quite simple to explain, it is quite boring too. After\nall, in most of the cases it is just using number to represent the opened\nfile (so called <code>file descriptor</code>), and it is passing this number around:\nfrom C++ to JS, and from JS to C++. Nothing interesting, let\'s move on!</p>\n<p>Certainly much more attractive is the <code>net</code> module. We create sockets, get\nthe <code>connect</code> events, and expect the <code>.write()</code> callbacks to be eventually\ninvoked. All of these should be powered by the C++ machinery!</p>\n<p>Here is where most of the interoperation is happening. The\n<code>tcp_wrap</code> and <code>stream_wrap</code> bindings (remember, <code>process.binding()</code>, right?)\nprovide very useful classes for JS-land: TCP, TCPConnectWrap, WriteWrap,\nShutdownWrap.</p>\n<ul>\n<li><code>TCP</code> holds the TCP socket and provides methods for writing and reading\nstuff</li>\n<li><code>*Wrap</code> objects are what you pass to the <code>TCP</code> methods when you expect\nsome async action to happen, and need to receive notification (callback) on\ntheir completion.</li>\n</ul>\n<p>For example, the normal workflow for <code>net.connect()</code> follows:</p>\n<ul>\n<li>Create <code>TCP</code> instance in <code>lib/net.js</code>, store it in the <code>_handle</code> property of\nthe <code>net.Socket</code> object</li>\n<li>Parse all arguments to <code>net.connect()</code></li>\n<li>Create <code>TCPConnectWrap</code> instance (usually named <code>req</code>)</li>\n<li>Invoke <code>.connect()</code> method with <code>req, port, host</code></li>\n<li>Get <code>req.oncomplete</code> function invoked eventually, once the connection was\nestablished, or once the kernel reported an error</li>\n</ul>\n<p>In conclusion: most of the C++ classes are either handles, or requests.\nRequests are very temporary and never outlive the handle that they are bound to,\nwhile the handles are something that live much longer (i.e. for the entire life\ntime of the TCP connection).</p>\n<p>Speaking of the file structure: <code>TCP</code> is represented by the <code>TCPWrap</code> class in\n<code>src/tcp_wrap.cc</code>, <code>TCPConnectWrap</code> lives in the same place, and <code>WriteWrap</code>\nis in the <code>stream_base.cc</code> file (in io.js).</p>\n<h2>Structure of C++ files</h2>\n<p>But how does the C++ provide this classes to JavaScript?</p>\n<p>Each binding has a <code>NODE_MODULE_CONTEXT_AWARE_BUILTIN</code> macro that registers it\nin the <code>node.cc</code>. This has the same effect as following JavaScript snippet:</p>\n<pre><code class="language-javascript">modules[moduleName] = {\n  <span class="hljs-attr">initialized</span>: <span class="hljs-literal">false</span>,\n  <span class="hljs-attr">initFn</span>: moduleInitFn\n};\n</code></pre>\n<p>When <code>process.binding(\'moduleName\')</code> is invoked, <code>node.cc</code> looks up the proper\ninternal binding in this hashmap and initializes it (if it wasn\'t previously\ninitialized) by calling the supplied function.</p>\n<pre><code class="language-javascript">process.binding = <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">moduleName</span>) </span>{\n  <span class="hljs-keyword">var</span> <span class="hljs-built_in">module</span> = modules[moduleName];\n  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">module</span>.initialized)\n    <span class="hljs-keyword">return</span> <span class="hljs-built_in">module</span>.exports;\n\n  <span class="hljs-built_in">module</span>.exports = {};\n  <span class="hljs-built_in">module</span>.initFn(<span class="hljs-built_in">module</span>.exports);\n  <span class="hljs-keyword">return</span> <span class="hljs-built_in">module</span>.exports;\n};\n</code></pre>\n<p>This initialization function receives <code>exports</code> object as an input, and exports\nthe methods and classes to it in pretty much the same way as you normally do\nin CommonJS modules.</p>\n<p>Each of the exported classes are bound to some C++ classes, and most of them are\nactually derived from the <code>AsyncWrap</code> C++ class.</p>\n<p>The Handle instances are destroyed automatically by V8\'s GC (once they are\nclosed in JS), and the Wraps are manually destroyed by the Handle, once they are\nnot used anymore.</p>\n<p>Side-note:</p>\n<p>there are two types of references to the JS\nobjects from C++ land: normal and weak. By default <code>AsyncWrap</code>s are referencing\ntheir objects in a <code>normal</code> way, which means that the JS objects representing\nthe C++ classes won\'t be garbage collected until C++ class will dispose the\nreference. The weak mode is turned on only when the <code>MakeWeak</code> is called\nsomewhere in C++. This might be very useful when debugging memory leaks.</p>\n<h2>Small exam</h2>\n<h3>Situation</h3>\n<p>You debug some io.js/node.js issue, and find that it is crashing when\ninstantiating a class provided by <code>process.binding(\'broken\')</code>. Where will you\nattempt to search for the C++ source code of that class?</p>\n<h3>Answer</h3>\n<p>Somewhere in <code>src/</code>. Find\n<code>NODE_MODULE_CONTEXT_AWARE_BUILTIN(broken, ...)</code> and it is most like going to be\nin <code>src/broken_something.cc</code>.</p>\n<h2>C++ Streams</h2>\n<p>Now comes one of my recent obsessions. The C++ Stream API.</p>\n<p>It is a established fact for me that exposing the building blocks of APIs helps\nto renovate, reshape and make them better <em>a lot better</em>. One of such thing\nthat I was always keen to re-do was a <code>StreamWrap</code> instance.</p>\n<p>It was ok-ish in v0.10, but when we moved TLS (SSL) implementation into C++\nland it changed dramatically... and, honestly saying, not in a good way.</p>\n<p>The previously singular <code>StreamWrap</code> instance, now became a monster that was\ncapable of passing the incoming data elsewhere, skipping the JavaScript\ncallbacks completely and doing some dark-magic OpenSSL machinery on top of it.\nThe implementation worked like a charm, providing much better TLS performance,\nbut the source code became cluttered and rigid.</p>\n<p>This &quot;move-parsing-to-elsewhere&quot; thing reminded me a lot about the\n<code>stream.pipe</code> that we had for JavaScript streams for ages. The natural thing to\ndo about it was to introduce something similar in the C++ land too. This is\nexactly what was done in io.js, and the results of this live in\n<code>src/stream_base.cc</code>.</p>\n<h2>Next step with the C++ Stream APIs</h2>\n<p>Now we have a very general implementation of this thing that could be reused in\nmany places. The first thing that I expect will be using this might be an\nHTTP2 stream. To do it in core, we should do it in user-land first, and it could\nbe accomplished only by exposing the C++ Stream API, in the same way as we did\nit with ObjectWrap.</p>\n<h2>Epilogue</h2>\n<p>I\'m going to ask you to:</p>\n<ul>\n<li>Clone the io.js repo</li>\n<li>Open the <code>src/</code></li>\n<li>Go through files in it, and check what you read about it</li>\n<li>Open <code>src/stream_base.h</code>, <code>src/stream_base.cc</code> and friends and figure out\nwhat seems to be wrong to you</li>\n<li><a href="https://github.com/nodejs/io.js/pulls">Send a PR</a></li>\n<li>Have fun!</li>\n</ul>\n'},{slug:"b.side-projects",title:"Side Projects",date:"2015-02-26T00:00:00.000Z",html:'<p>After reading <a href="https://github.com/antirez">antirez</a>\'s <a href="http://antirez.com/news/86">blog post</a> I decided that it might be a good\nexercise to write down the notable side projects that I spent my time upon since\nJan 2014.</p>\n<p>Here is the list and some comments from me:</p>\n<h3><a href="https://github.com/indutny/bn.js">bn.js</a></h3>\n<p>JavaScript library for working with Big Numbers. <a href="https://github.com/indutny/bn.js">bn.js</a> is an ultra-fast\n<a href="https://github.com/justmoon/node-bignum">bignum</a> alternative with support for running in io.js/node.js and browsers.</p>\n<p>This one took lots of time and effort through whole year with some periodic\n<a href="https://github.com/indutny/bn.js/graphs/contributors">sparks in a contributions graph</a>, and many PRs from OpenSource community.\nSeriously, big kudos to you people for helping me with it!</p>\n<h3><a href="https://github.com/indutny/elliptic">elliptic</a></h3>\n<p>JS library for doing Elliptic Curve crypto. It was the reason for creating the\n<a href="https://github.com/indutny/bn.js">bn.js</a> in the first place, and excuse for me to learn more about EC\ncryptography and crazy math behind it.</p>\n<h3><a href="https://github.com/indutny/bud">bud</a></h3>\n<p>A friendly and clever TLS-terminating proxy in C.</p>\n<p>Although I worked on it since Nov 2013, lots of development happened during the\n2014 year. This is my biggest project in C so far, and it has taught me a lot\nabout designing the APIs and interfaces in low-level languages.</p>\n<p>Bud seens lots of love from <a href="https://github.com/odeke-em">Emmanuel Odeke</a>. Big thanks to you, Emmanuel!</p>\n<h3><a href="https://github.com/indutny/tls.js">tls.js</a></h3>\n<p>(Incomplete) TLS implementation in JavaScript.</p>\n<p>Totally experimental protocol implementation. Did it just for fun, but it turned\nto be useful in screening the web servers.</p>\n<h3><a href="https://github.com/indutny/hash.js">hash.js</a></h3>\n<p>Implementations of SHA1, SHA224, SHA256, SHA384, SHA512, RIPEMD160, various\nHMACs. One of the mandatory dependencies of...</p>\n<h3><a href="https://github.com/indutny/bcoin">bcoin</a></h3>\n<p>BitCoin SPV client implementation. Purely experimental, but I heard that some\npeople do use it.</p>\n<p>Lots of contributions from <a href="https://github.com/chjj">Christopher Jeffrey</a> here. Thank you!</p>\n<h3><a href="https://chrome.google.com/webstore/detail/bthread/ldbfhhncehnfgppdlgjhfgffachpehkd">bthread</a> (<a href="https://github.com/indutny/bthread">src</a>)</h3>\n<p>Writing blog posts in a BitCoin block-chain.</p>\n<p><em>I know many people hate me for this, but still I wanted to experiment with it\na little</em>.</p>\n<h3><a href="https://github.com/js-js/js.js">js.js</a></h3>\n<p>JS JIT compiler written in JS.</p>\n<p>Very preliminary implementation with little or no compatibility with ECMAScript\nyet :)</p>\n<h3><a href="https://github.com/js-js">heap.js, jit.js, cfg.js, ...</a></h3>\n<p>Various <a href="https://github.com/js-js/js.js">js.js</a> dependencies.</p>\n<h3><a href="https://github.com/indutny/lll-reduction">lll-reduction</a></h3>\n<p><a href="http://en.wikipedia.org/wiki/Lenstra%E2%80%93Lenstra%E2%80%93Lov%C3%A1sz_lattice_basis_reduction_algorithm">LenstraLenstraLovsz algorithm</a> JavaScript implementation.</p>\n<p>I don\'t remember exact reasons for writing this, but I guess I thought about\ndoing more optimal <a href="http://www.hyperelliptic.org/tanja/conf/ECC08/slides/Mike-Scott.pdf">GLV Method</a> for <a href="https://github.com/indutny/elliptic">elliptic</a>.</p>\n<h3><a href="https://github.com/indutny/core2dump">core2dump</a></h3>\n<p>Creating heap snapshots out of the core file on OS X, linuxes, and FreeBSD.</p>\n<h3><a href="https://github.com/indutny/asn1.js">asn1.js</a></h3>\n<p>ASN.1 encoding implementation in JS.</p>\n<h3><a href="https://github.com/indutny/miller-rabin">miller-rabin</a></h3>\n<p>Miller-Rabin primality test in JS.</p>\n<h3><a href="https://github.com/indutny/caine">caine</a></h3>\n<p>Butler bot for github projects. I wanted it to be used for io.js, but we decided\nto walk a different road.</p>\n<h4>Epilogue</h4>\n<p>I guess that\'s it.</p>\n<p>Most of these projects were a big incentive for me to dig into the protocols,\ntechnology, science. I find it much more enjoyable and interesting to\ninvestigate new topics through their applications.</p>\n<p><strong>Thank you for all your contributions, people! It is really awesome to see\nyou interested in helping me with these and other projects!</strong></p>\n<p>Thanks for reading this.</p>\n'},{slug:"a.deoptimize-me-not",title:"Deoptimize me not, v8",date:"2014-12-15T00:00:00.000Z",html:"<p>Compilers are awesome, right? If any programming concept may exist, it will\nprobably be used in compiler implementation at some point. I am always amazed\nby my findings during v8 bug triaging or just random code exploration.</p>\n<p>The interesting thing about v8 that I was always passionate about, but never\ntruly understood, was the Deoptimizer. The idea here is that v8 optimizes\ncode to make it run faster, but this optimization relies on assumptions\nabout types, ranges, actual values, const-ness, etc. These assumptions imply\nthat the optimized code won't run when these conditions are not met,\nsince the compiler needs to &quot;deoptimize&quot; it by returning to the previous\n&quot;no-assumptions&quot; version of generated code when the assumptions are failing.</p>\n<p>Technically it means that the compiler is in fact two compilers:\na base compiler and an &quot;optimizer&quot;. (Or even more, if we are talking about JSC\nand SpiderMonkey). The concept is quite sound and can yield incredible\nperformance, but there is a nuance: the optimized code may be &quot;deoptimized&quot; in\nvarious places, not just at the entry point, meaning that the environment (local\nvariables, arguments, context) should be mapped and moved around.</p>\n<h2>Stack machines</h2>\n<p>To better understand what needs to be done and how things are happening let's\nconsider a basic stack machine, like the one that we might use to interpret\nprogram instead of JIT compiling it.</p>\n<p><em>Note that this stack machine and assembly below are just an output of some\nabstract compiler and has nothing do to with v8. Thus here only for\ndemonstration purposes</em></p>\n<pre><code>push a\npush b\npush c\nmul     ; pop 2 values and push `arg0 * arg1`\npush d\nmul     ; b * c * d\nadd     ; pop 2 values and push `arg0 + arg`\nret     ; pop and return value\n</code></pre>\n<p>The interpreter will execute instructions one-by-one, maintaining the stack at\nevery point.</p>\n<p>Now we let's imagine some register machine (like x86_64), and write down\nthe same program in assembly language. To make it a bit more interesting,\nconsider that the target architecture has only two registers and the rest of the\nvalues need to be stored in memory (on-stack).</p>\n<pre><code class=\"language-asm\">mov [slot0], a   ; store value in 0 memory slot\nmov rax, b       ; store value in rax register\nmov rbx, c       ; store value in rbx register\nmul rax, rbx     ; rax = rax * rbx\nmov rbx, d\nmul rax, rbx     ; rax = b * c * d\nmov rbx, [slot0] ; load value from 0 memory slot\nadd rax, rbx     ; rax = b * c * d + a\n</code></pre>\n<p>The instructions are executed one-by-one, maintaining the register values and\nmemory slots.</p>\n<p>In terms of our compiler, the former code is an unoptimized version of our\nprogram, and the latter one is optimized. In fact, this is a completely valid\nclaim if we would like to run it on x86_64 platform, as assembly has much higher\nexecution speed than interpreted code that needs to be emulated.</p>\n<p>Suppose that the second <code>mul</code> instruction in assembly works only when the <code>d</code>\n(which is in <code>rbx</code> register) is a small integer. Now if the execution will\nreach the <code>mul</code> and find that there is a JavaScript string, it will just fail\nto do the &quot;right thing&quot;. This <code>mul(num, str)</code> operation will definitely require\nsome sort of type coercion, and could be easily handled by the interpreter.\nDoing it in assembly will very likely be much more costly in terms of\nperformance. To deal with this the compiler inserts check instructions:</p>\n<pre><code>mov [slot0], a\nmov rax, b\nmov rbx, c\ncheckSmallInt rax\ncheckSmallInt rbx\nmul rax, rbx\nmov rbx, d\ncheckSmallInt rax\ncheckSmallInt rbx\nmul rax, rbx ;\nmov rbx, [slot0]\nadd rax, rbx\n</code></pre>\n<p>So in such an uncommon case, where the argument of <code>mul</code> is not a small integer,\nthis code should somehow be &quot;deoptimized&quot; from assembly code to the stack\nmachine and continue execution in the interpreted version. Here is the position\nin the optimized code where it will stop:</p>\n<pre><code>mov [slot0], a\nmov rax, b\nmov rbx, c\ncheckSmallInt rax\ncheckSmallInt rbx\nmul rax, rbx\nmov rbx, d\ncheckSmallInt rax\ncheckSmallInt rbx &lt;-----\nmul rax, rbx ;\nmov rbx, [slot0]\nadd rax, rbx\n</code></pre>\n<p>...and position in unoptimized code, where would like it to continue:</p>\n<pre><code>push a\npush b\npush c\nmul\npush d\nmul     ; &lt;-----\nadd\nret\n</code></pre>\n<p>How could it do that? The simplest way is just to re-execute all code from the\nprogram's entry point using the input arguments. This solution is very limited\nthough, because it is possible only if the optimized function was pure, or in\nother words had no instructions with side effects (like function calls, etc...).</p>\n<p>The more general solution is to find all live values (the ones that may be used\nby later functions) at the deoptimization point, find their locations in both\noptimized and unoptimized code, and copy the values from the registers/memory\nto stack machine's slot.</p>\n<p>This is exactly what the &quot;deoptimizer&quot; in v8 does. The main difference from our\nimaginary example is that both unoptimized and optimized codes are in <code>x86_64</code>\nassembly language.</p>\n<h2>Simulates</h2>\n<p>Now we know what to do, but how is it actually implemented in v8?</p>\n<p>These mappings are possible thanks to the special high-level instructions called\n<code>Simulate</code>s. This is how they look in the v8's high-level intermediate\nrepresentation (abbr. IR, see my <a href=\"https://www.youtube.com/watch?v=tf6YTgO6Org\">EmpireNode talk</a> for more info on the IRs):</p>\n<pre><code>v9 BlockEntry  &lt;|@\nv10 Simulate id=3 var[3] = t8 &lt;|@\nv11 StackCheck  changes[NewSpacePromotion] &lt;|@\nv12 UseConst t8 &lt;|@\nt13 ThisFunction  &lt;|@\nt14 CheckNonSmi t3 &lt;|@\nt15 CheckMaps t3 [0x2e26d7019781] &lt;|@\nv16 CheckPrototypeMaps [...] &lt;|@\nv17 Simulate id=24 push t3, push t4, push t8, var[3] = t13 &lt;|@\nv18 EnterInlined middle, id=4 &lt;|@\nt54 PushArgument t3 &lt;|@\nt55 PushArgument t4 &lt;|@\nt56 ArgumentsElements  &lt;|@\nv19 UseConst t1 &lt;|@\nt20 Constant ... &lt;|@\nv25 Simulate id=26 pop 1, push t19, var[3] = t2, var[4] = t20 &lt;|@\n</code></pre>\n<p>(Note that you can obtain such IR by running node.js with <code>--trace-hydrogen</code>\nflag, which will print it out into the <code>hydrogen.cfg</code> or <code>hydrogen-&lt;pid&gt;.cfg</code>\nfile).</p>\n<p>The thing is called <code>Simulate</code> with good reason. Strip away all other\ninstructions:</p>\n<pre><code>v10 Simulate id=3 var[3] = t8 &lt;|@\nv17 Simulate id=24 push t3, push t4, push t8, var[3] = t13 &lt;|@\nv25 Simulate id=26 pop 1, push t19, var[3] = t2, var[4] = t20 &lt;|@\n</code></pre>\n<p>...and we will see something that resembles... our simplified stack machine!\nHaving a stack machine means that we could &quot;simulate&quot; it's state by executing\ninstructions one-by-one. v8's has a couple of them:</p>\n<ul>\n<li><code>var[index] = value</code> - put a value in some on-stack slot</li>\n<li><code>push value</code> - push a value to a virtual stack</li>\n<li><code>pop count</code> - pop <code>count</code> of values from the stack</li>\n</ul>\n<p>Let's simulate some states out of the above sample:</p>\n<pre><code>v10: var = { 3: t8 }, stack = []\nv17: var = { 3: t13 }, stack = [ t3, t4, t8 ]\nv25: var = { 3: t13, 4: t20 }, stack = [ t3, t4, t19 ]\n</code></pre>\n<p><em>Note that this &quot;simulation&quot; happens at compile-time, not when actually\ndeoptimizing.</em></p>\n<p>These states can be used to map the values from optimized to unoptimized code.\nFor example, if we would like to &quot;deoptimize&quot; at <code>t56</code>, we will have to find the\nlatest state which was at <code>v17</code>: <code>var = { 3: t13 }, stack = [ t3, t4, t8 ]</code>, and\njust place the present values into a proper stack slots and local variables (for\n<code>var</code> ones).</p>\n<p>With the <code>--trace-deopt</code> flag v8 will give us some insights on how it is doing\nthis:</p>\n<pre><code>**** DEOPT: outer at bailout #14, address 0x0, frame size 56\n[deoptimizing: begin 0x341ad2082a49 outer @14]\ntranslating outer =&gt; node=24, height=8\n0x7fff5fbff3e8: [top + 72] &lt;- 0xb7720f7d8b9 ; [sp + 96] 0xb7720f7d8b9 &lt;an O&gt;\n0x7fff5fbff3e0: [top + 64] &lt;- 0xb7720f7d8b9 ; rbx 0xb7720f7d8b9 &lt;an O&gt;\n0x7fff5fbff3d8: [top + 56] &lt;- 0x21ba55263fa9 ; caller's pc\n0x7fff5fbff3d0: [top + 48] &lt;- 0x7fff5fbff410 ; caller's fp\n0x7fff5fbff3c8: [top + 40] &lt;- 0xb7720f7d479; context\n0x7fff5fbff3c0: [top + 32] &lt;- 0x341ad2082ad9; function\n0x7fff5fbff3b8: [top + 24] &lt;- 0x341ad2004121 &lt;undefined&gt; ; literal\n0x7fff5fbff3b0: [top + 16] &lt;- 0x341ad2082ad9 &lt;JS Function inner&gt; ; literal\n0x7fff5fbff3a8: [top + 8] &lt;- 0xb7720f7d8b9 ; [sp + 24] 0xb7720f7d8b9 &lt;an O&gt;\n0x7fff5fbff3a0: [top + 0] &lt;- 0x341ad2004121 ; rax 0x341ad2004121 &lt;undefined&gt;\n</code></pre>\n<p>Arrows here indicate the direction of movement. The output frame of the\nunoptimized code is on the left side, and on the right side - optimized code's\nvalues.</p>\n<p>The mentioned frame is an on-stack structure used for storing the caller address\n(to make <code>return</code> statements work), caller's frame address, and sometimes some\nadditional stuff (like JS context, <code>this</code>, arguments, and the function itself):</p>\n<p><img src=\"/images/callstack.png\" alt=\"Callstack\"></p>\n<p>Ignoring all the internal frame things, the interesting part would be:</p>\n<pre><code>translating outer =&gt; node=24, height=8\n0x7fff5fbff3a8: [top + 8] &lt;- 0xb7720f7d8b9 ; [sp + 24] 0xb7720f7d8b9 &lt;an O&gt;\n0x7fff5fbff3a0: [top + 0] &lt;- 0x341ad2004121 ; rax 0x341ad2004121 &lt;undefined&gt;\n</code></pre>\n<p>The high-level IR of the code that generated this trace contained:</p>\n<pre><code>0 0 v10 Simulate id=3 var[3] = t8 &lt;|@\n...\n0 0 v17 Simulate id=24 push t3, push t4 &lt;|@\n</code></pre>\n<p>There is only one simulate instruction, and the state is: <code>stack = [t3, t4]</code>.\n(Sorry ignoring the local variables for this blog post).\nThus, the deoptimizer needs to put the values of the <code>t3</code> and <code>t4</code> instructions\ninto the stack slots. This information was stored ahead of time, and will be\nlooked up right when deoptimizing the code. Here, <code>t3</code> was in the <code>[sp + 24]</code>\nstack slot in the optimized code, and <code>t4</code> was in <code>rax</code>. This process is called\na &quot;frame translation&quot;. Afterwards the execution will be redirected to the\nunoptimized code, which will just continue operating on the values at the place\nwhere the optimized code has been &quot;deoptimized&quot;.</p>\n<h2>Conclusion</h2>\n<p>The &quot;deoptimizer&quot; is really an interesting tool, and it is one of the main\ncogs in <a href=\"http://blog.chromium.org/2010/12/new-crankshaft-for-v8.html\">Crankshaft</a>'s engine. This instrument helps the compiler in\nexecuting the dynamic-language code as if it had been written in C++, because\nit can always return to the slow unoptimized code with &quot;true&quot; JavaScript\nsemantics.</p>\n<p><em>Note that things are a bit more tricky with inlined functions, but this is a\ntopic for another blog post.</em></p>\n<p><em>Big kudos to</em>:</p>\n<ul>\n<li><em>Vyacheslav Egorov</em></li>\n<li><em>Ben Noordhuis</em></li>\n<li><em>Jeremiah Senkpiel</em></li>\n</ul>\n<p><em>for proof-reading this and providing valuable feedback.</em></p>\n"},{slug:"9.heartbleed",title:"Cracking Cloudflare's heartbleed challenge",date:"2014-04-16T00:00:00.000Z",html:'<h2>Challenge</h2>\n<p>At April 11th 2014 Cloudflare has published a <a href="http://blog.cloudflare.com/answering-the-critical-question-can-you-get-private-ssl-keys-using-heartbleed">blog post</a> suggesting to\ntry out extracting a private key of their specially prepared\n<a href="https://www.cloudflarechallenge.com/heartbleed">challenge site</a> using the <a href="http://heartbleed.com/">Heartbleed</a> OpenSSL vulnerability. Being busy\nat the time, I decided to give it a try a couple of hours later, if noone would\ncrack it yet. This was a legal way to do some hackery, after all!</p>\n<h2>Method</h2>\n<p>The method of attack was following:</p>\n<ol>\n<li>Send a lot of random-sized fake heartbeats (without body)</li>\n<li>Try to find a 128-byte prime factor of the certificate\'s <a href="http://en.wikipedia.org/wiki/RSA_(cryptosystem)#Key_generation">modulus</a></li>\n<li>Generate the rest of the private key\'s parameters out of it</li>\n</ol>\n<p>I wasn\'t searching for a PEM-encoded private key and/or:</p>\n<pre><code>-----BEGIN RSA PRIVATE KEY-----\n</code></pre>\n<p>for a couple of reasons:</p>\n<ul>\n<li>It is loaded only at the process startup</li>\n<li>The key may be encrypted, and there is no point in brute forcing it</li>\n</ul>\n<p>According to my tests, DER-encoded key wasn\'t appearing in the memory either, so\ntrying to extract primes that are definitely in memory seem more feasible,\nbecause they are stored in the following struct in OpenSSL:</p>\n<pre><code class="language-C"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">rsa_st</span>\n  {</span>\n  <span class="hljs-comment">/* The first parameter is used to pickup errors where\n   * this is passed instead of aEVP_PKEY, it is set to 0 */</span>\n  <span class="hljs-keyword">int</span> pad;\n  <span class="hljs-keyword">long</span> version;\n  <span class="hljs-keyword">const</span> RSA_METHOD *meth;\n  <span class="hljs-comment">/* functional reference if \'meth\' is ENGINE-provided */</span>\n  ENGINE *engine;\n  BIGNUM *n;\n  BIGNUM *e;\n  BIGNUM *d;\n  BIGNUM *p;\n  BIGNUM *q;\n  BIGNUM *dmp1;\n  BIGNUM *dmq1;\n  BIGNUM *iqmp;\n  <span class="hljs-comment">/* be careful using this if the RSA structure is shared */</span>\n  CRYPTO_EX_DATA ex_data;\n  <span class="hljs-keyword">int</span> references;\n  <span class="hljs-keyword">int</span> flags;\n\n  <span class="hljs-comment">/* Used to cache montgomery values */</span>\n  BN_MONT_CTX *_method_mod_n;\n  BN_MONT_CTX *_method_mod_p;\n  BN_MONT_CTX *_method_mod_q;\n\n  <span class="hljs-comment">/* all BIGNUM values are actually in the following data, if it is not\n   * NULL */</span>\n  <span class="hljs-keyword">char</span> *bignum_data;\n  BN_BLINDING *blinding;\n  BN_BLINDING *mt_blinding;\n  };\n</code></pre>\n<p>Where <code>BIGNUM</code> is:</p>\n<pre><code class="language-C"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">bignum_st</span>\n  {</span>\n  BN_ULONG *d;\t<span class="hljs-comment">/* Pointer to an array of \'BN_BITS2\' bit chunks. */</span>\n  <span class="hljs-keyword">int</span> top;\t<span class="hljs-comment">/* Index of last used d +1. */</span>\n  <span class="hljs-comment">/* The next are internal book keeping for bn_expand. */</span>\n  <span class="hljs-keyword">int</span> dmax;\t<span class="hljs-comment">/* Size of the d array. */</span>\n  <span class="hljs-keyword">int</span> neg;\t<span class="hljs-comment">/* one if the number is negative */</span>\n  <span class="hljs-keyword">int</span> flags;\n  };\n</code></pre>\n<p>And <code>d</code> field of <code>BIGNUM</code> is a pointer to a little-endian representation of the\nnumber. Note that I could have been searching for a <code>dmp1</code>, <code>dmpq1</code> or <code>iqmp</code> as\nwell, but I was too lame at the time to put this in my tests.</p>\n<h2>Implementation</h2>\n<p>Being a node.js core developer, the platform choice for the extraction script\nwas obvious to me. Unfortunately, since node.js is embedding OpenSSL and\nexposing only some limited amount of methods as a JavaScript API, the\n<a href="https://github.com/indutny/heartbleed/blob/master/node-v0.10.26.patch">patch to add fake heartbeat methods</a> was needed. (Update: patch is no longer\nneeded, just install module from npm).</p>\n<p>Having this at hand, the implementation was almost straightforward. It is\navailable as an <a href="https://github.com/indutny/heartbleed">OpenSource project on github</a> now. Here are instructions for\nobtaining and using it:</p>\n<pre><code class="language-bash"><span class="hljs-comment"># Update: patch is no longer needed, just install module from npm</span>\ngit <span class="hljs-built_in">clone</span> git://github.com/indutny/heartbleed\ngit <span class="hljs-built_in">clone</span> git://github.com/joyent/node -b v0.10.26 node-hb\n<span class="hljs-built_in">cd</span> node-hb\ngit apply ../heartbleed/node-v0.10.26.patch\n./configure --prefix=<span class="hljs-variable">$HOME</span>/.node/0.10.26-hb\nmake -j24 install\nls ./node\n\n<span class="hljs-built_in">export</span> PATH=<span class="hljs-string">"<span class="hljs-variable">$HOME</span>/.node/0.10.26-hb/bin:<span class="hljs-variable">$PATH</span>"</span>\n\n<span class="hljs-comment"># Here it goes</span>\nnpm install -g heartbleed.js\n\nheartbleed -h cloudflarechallenge.com -c 1000 &gt;&gt; key.pem\n</code></pre>\n<p>Note that it won\'t produce any result immediately, it took me 3 hours and a\ncertain amount of luck to obtain the key in a Cloudflare\'s challenge.</p>\n'},{slug:"8.bud-a-tls-swiss-knife",title:'Bud - a TLS "swiss knife"',date:"2014-04-03T00:00:00.000Z",html:'<h2>Bud</h2>\n<p>To terminate TLS or not? Good question, but instead of answering it - I\'ll try\nto make you believe that if you need a TLS terminator - the <a href="http://github.com/indutny/bud">Bud</a> is just\nthe right choice.</p>\n<h2>Other choices</h2>\n<p>Certainly, there are some other choices for TLS termination like:</p>\n<ul>\n<li><a href="https://github.com/voxer/stud">stud</a></li>\n<li><a href="http://www.stunnel.org/">stunnel</a></li>\n<li><a href="http://nginx.org/">nginx</a> (though, not only a TLS terminator, but a web server too)</li>\n<li><a href="http://haproxy.1wt.eu/">haproxy</a> (much more than just a TLS terminator, but quite good!)</li>\n<li>...probably some others?</li>\n</ul>\n<p>However, in many cases <a href="http://github.com/indutny/bud">bud</a> could do their job as well as they do and also\nprovide some unique features.</p>\n<h2>Features</h2>\n<h3>Speed</h3>\n<p>Bud is as fast as all of it rivals, here are comparison of it to <a href="https://github.com/voxer/stud">stud</a>:</p>\n<p>Normal response:</p>\n<p><img src="/images/bud/normal-rps.png" alt="Normal RPS">\n<img src="/images/bud/normal-response.png" alt="Normal Response"></p>\n<p>Big response:</p>\n<p><img src="/images/bud/big-rps.png" alt="Big RPS">\n<img src="/images/bud/big-response.png" alt="Big Response"></p>\n<h3>Asynchronous SNI and balancing</h3>\n<p>This is a killer feature for any serious PaaS offering an HTTPS access to the\nhosted applications. When enabled in configuration, on every incoming request\nbud will do an http query to receive a TLS certificate/key pair and an address\nof the backend to which this connection should be balanced.</p>\n<p>See <a href="https://github.com/indutny/bud#sni-storage">docs</a> for details.</p>\n<h3>Asynchronous OCSP stapling</h3>\n<p>The same kind of thing could be used to perform <a href="http://en.wikipedia.org/wiki/OCSP_stapling">OCSP stapling</a>\nasynchronously, which is pretty useful if certificates are loaded dynamically\nand it isn\'t possible to store all of them in memory.</p>\n<p>See <a href="https://github.com/indutny/bud#ocsp-stapling">docs</a> for more details.</p>\n<p>All that asynchronous APIs are JSON based, so replying to such requests is as\neasy as possible for almost any platform (including node.js).</p>\n<h3>X-Forwarded-For</h3>\n<p>The latest feature that I have implemented so far is an <code>x-forward</code> backend\noption. When enabled, bud will add <code>X-Forwarded-For</code> header to the first request\nof all incoming HTTP connections and send custom <code>X_FORWARD</code> frame for all\n<a href="http://en.wikipedia.org/wiki/SPDY">SPDY</a> connections.</p>\n<p>This custom <code>X_FORWARD</code> frame is already supported in <a href="https://www.npmjs.org/package/spdy">node-spdy@1.25.0</a> and\nwill automatically add <code>X-Forwarded-For</code> header to all requests on that SPDY\nconnection.</p>\n<p>The main pros of this method is that no actual protocol parsing is happening.\nThe cons is that, in case of HTTP protocol, only first request gets this header\nadded. This could be worked around by checking this header on incoming request\nand associating it with a underlying socket (<code>req.socket</code> in node.js.)</p>\n<h2>Try it out!</h2>\n<p>Hearing all that awesome things - you may become interested in giving it a try,\nthanks to <a href="https://npmjs.org/">npm</a> it is quite simple:</p>\n<pre><code>npm install -g bud-tls\n</code></pre>\n<p>Generating a configuration is easy too:</p>\n<pre><code>bud --default-config &gt; config.json\nvim config.json\n</code></pre>\n<p>All this options are documented in the <a href="https://github.com/indutny/bud#bud-">project\'s readme</a>.</p>\n<p>Just in case, this blog is running behind <a href="http://github.com/indutny/bud">bud</a>!</p>\n<h2>Reporting issues</h2>\n<p>Something does not work as expected or just crashes? Please do not hesitate to\nreport it on <a href="https://github.com/indutny/bud/issues">github issues</a>.</p>\n'},{slug:"7.freebsd-dtrace",title:"Running node.js + DTrace on FreeBSD",date:"2014-04-01T00:00:00.000Z",html:'<h2>Preface</h2>\n<p>Tracing node.js activity and detecting performance problems and bottlenecks\nhas always been an important topic for many people in the community. Though,\nvarious ways to do this were available, including: systemtap, ETW and perfctr on\nWindows. The most complete tracing support was done by Joyent guys for the\nDTrace tool which works best on their <a href="http://wiki.illumos.org/display/illumos/illumos+Home">Illumos</a> fork, called <a href="http://smartos.org/">SmartOS</a>.</p>\n<p>Fortunately, since 9.0 version, FreeBSD maintainers have started fixing and\ntweaking their DTrace implementation too (which is actually a backport from\nSolaris). Considering that FreeBSD is much easier to install and is much\nmore usable as a primary OS for developers, being able to do flamegraphs for\nnode.js on it is something that I highly desired at the time.</p>\n<h2>What was broken</h2>\n<p>Sadly, it wasn\'t working out-of-the-box. After the installation of FreeBSD in a\nVirtualBox has finished, I immediately tried to build and dtrace node with a\n<code>jstack()</code> utility (see my previous <a href="/3.dtrace-ustack-helper">blog post</a> on that topic), but it did\nnot work out. After some struggling it became obvious that <code>/dev/dtrace/helper</code>\nhas pretty narrow permissions and the node, running under non-root user, wasn\'t\nable to register itself within the system\'s DTrace module.</p>\n<p>Calling <code>sudo chmod 666 /dev/dtrace/helper</code> improved the situation, but not that\nmuch: version 0.11 of node.js was crashing, and version v0.10 was still not\nregistering it\'s ustack helper and DTrace provider (see <a href="http://www.solarisinternals.com/wiki/index.php/DTrace_Topics_USDT#USDT">USDT</a> docs). This\nproblem was a bit tougher than the helper permissions, and took awhile to fix.</p>\n<h2>How node interacts with DTrace</h2>\n<p>First of all, a bit of information about how node.js compiles it\'s DTrace\nhelpers and how they are used by the system. There were <a href="http://www.bsdcan.org/2008/schedule/attachments/60_dtrace_bsdcan.pdf">some slides</a> on that\ntopic (how DTrace USDT interacts with kernel), but at that moment I figured it\nout by reading the implementation\'s source.</p>\n<p>There are two <code>.d</code> files in the node.js source tree: <code>src/node_provider.d</code> and\n<code>src/v8ustack.d</code>. The former declares a <code>node</code> DTrace USDT provider and the\nlatter exports an ustack helper Both of these files are compiled with\n<code>dtrace -G -s &lt;file.d&gt; -o &lt;out.o&gt;</code>, which in fact does the following thing:</p>\n<ol>\n<li>Compile all D-language chunks into DIFs (<a href="https://github.com/freebsd/freebsd/blob/3ecc6f129801776dd571d69cf9a262a97ad23968/sys/cddl/contrib/opensolaris/uts/common/sys/dtrace.h#L112">DTrace Intermediate Format</a></li>\n<li>Encode them in the DOF (<a href="https://github.com/freebsd/freebsd/blob/3ecc6f129801776dd571d69cf9a262a97ad23968/sys/cddl/contrib/opensolaris/uts/common/sys/dtrace.h#L570">DTrace Object File</a>) format</li>\n<li>Put them into the special <code>._SUNW_dof</code> ELF section</li>\n<li>Link it to the internally-stored <code>drti.o</code>, providing <code>dtrace_dof_init</code> and\n<code>dtrace_dof_fini</code> helper functions.</li>\n</ol>\n<p>These functions are called on the executable\'s initialization and\ndeinitialization (surprisingly!), each making an <code>ioctl()</code> syscall on the\n<code>/dev/dtrace/helper</code>. Specifically, <code>dtrace_dof_init()</code> loads and verifies the\n<code>._SUNW_dof</code> section of an ELF-file and registers it with-in the kernel.</p>\n<h2>How I fixed it</h2>\n<p>I decided to investigate the node.js v0.11 crashes. It was crashing on a\n<a href="https://github.com/freebsd/freebsd/blob/4d784918edbf9aefbab5ab12e4701d3104c3ff45/cddl/contrib/opensolaris/lib/libdtrace/common/drti.c#L110">this line</a>, so it was either an ELF symbol problem or a DOF string\nproblem. Initially, I found that the DOF did not contain the STRTAB section\nthat <code>dtri.o</code> was searching for, but it turned out to be a slightly bigger\nproblem. Since node.js has two separate <code>.d</code> files, it has two DOFs for\neach of them in it\'s <code>._SUNW_dof</code> section, but the <code>drti.o</code> was loading only\none! After all I came up with a following patch:</p>\n<pre><code class="language-patch">commit c46786f47483e7fc218727aa52cf6b2278a45053\nAuthor: Fedor Indutny &lt;fedor.indutny@gmail.com&gt;\nDate:   Mon Feb 17 01:16:13 2014 +0400\n\n    dtrace: proper symbol fixup and import in drti\n    \n    Application may contain multiple DOFs, merged into one ._SUNW_dof ELF\n    section. Process all of them and fix symbols only in those ones that\n    actaully define a provider. Use proper strtab for resolving symbols.\n\ndiff --git a/cddl/contrib/opensolaris/lib/libdtrace/common/drti.c b/cddl/contrib/opensolaris/lib/libdtrace/common/drti.c\nindex 3b4a38c..e47cfb4d 100644\n<span class="hljs-comment">--- a/cddl/contrib/opensolaris/lib/libdtrace/common/drti.c</span>\n<span class="hljs-comment">+++ b/cddl/contrib/opensolaris/lib/libdtrace/common/drti.c</span>\n<span class="hljs-meta">@@ -20,6 +20,7 @@</span>\n  */\n /*\n  * Copyright 2008 Sun Microsystems, Inc.  All rights reserved.\n<span class="hljs-addition">+ * Copyright 2013 Voxer Inc. All rights reserved.</span>\n  * Use is subject to license terms.\n  */\n \n@@ -144,7 +145,8 @@ dtrace_dof_init(void)\n \tLmid_t lmid;\n #else\n \tu_long lmid = 0;\n<span class="hljs-deletion">-\tdof_sec_t *sec;</span>\n<span class="hljs-addition">+\tdof_sec_t *sec, *secstart, *dofstrtab, *dofprobes;</span>\n<span class="hljs-addition">+\tdof_provider_t *dofprovider;</span>\n \tsize_t i;\n #endif\n \tint fd;\n@@ -152,12 +154,13 @@ dtrace_dof_init(void)\n #if !defined(sun)\n \tElf *e;\n \tElf_Scn *scn = NULL;\n<span class="hljs-deletion">-\tElf_Data *symtabdata = NULL, *dynsymdata = NULL;</span>\n<span class="hljs-addition">+\tElf_Data *symtabdata = NULL, *dynsymdata = NULL, *dofdata = NULL;</span>\n<span class="hljs-addition">+\tdof_hdr_t *dof_next = NULL;</span>\n \tGElf_Shdr shdr;\n \tint efd, nprobes;\n \tchar *s;\n<span class="hljs-addition">+\tchar *dofstrtabraw;</span>\n \tsize_t shstridx, symtabidx = 0, dynsymidx = 0;\n<span class="hljs-deletion">-\tunsigned char *dofstrtab = NULL;</span>\n \tunsigned char *buf;\n \tint fixedprobes = 0;\n #endif\n@@ -209,7 +212,9 @@ dtrace_dof_init(void)\n \t\t} else if (shdr.sh_type == SHT_PROGBITS) {\n \t\t\ts = elf_strptr(e, shstridx, shdr.sh_name);\n \t\t\tif  (s &amp;&amp; strcmp(s, ".SUNW_dof") == 0) {\n<span class="hljs-deletion">-\t\t\t\tdof = elf_getdata(scn, NULL)-&gt;d_buf;</span>\n<span class="hljs-addition">+\t\t\t\tdofdata = elf_getdata(scn, NULL);</span>\n<span class="hljs-addition">+\t\t\t\tdof = dofdata-&gt;d_buf;</span>\n<span class="hljs-addition">+\t\t\t\tbreak;</span>\n \t\t\t}\n \t\t}\n \t}\n@@ -219,6 +224,9 @@ dtrace_dof_init(void)\n \t\tclose(efd);\n \t\treturn;\n \t}\n<span class="hljs-addition">+</span>\n<span class="hljs-addition">+\twhile ((char *) dof &lt; (char *) dofdata-&gt;d_buf + dofdata-&gt;d_size) {</span>\n<span class="hljs-addition">+\t\tdof_next = (void *) ((char *) dof + dof-&gt;dofh_filesz);</span>\n #endif\n \n \tif (dof-&gt;dofh_ident[DOF_ID_MAG0] != DOF_MAG_MAG0 ||\n@@ -290,34 +298,49 @@ dtrace_dof_init(void)\n \t * We are assuming the number of probes is less than the number of\n \t * symbols (libc can have 4k symbols, for example).\n \t */\n<span class="hljs-deletion">-\tsec = (dof_sec_t *)(dof + 1);</span>\n<span class="hljs-addition">+\tsecstart = sec = (dof_sec_t *)(dof + 1);</span>\n \tbuf = (char *)dof;\n \tfor (i = 0; i &lt; dof-&gt;dofh_secnum; i++, sec++) {\n<span class="hljs-deletion">-\t\tif (sec-&gt;dofs_type == DOF_SECT_STRTAB)</span>\n<span class="hljs-deletion">-\t\t\tdofstrtab = (unsigned char *)(buf + sec-&gt;dofs_offset);</span>\n<span class="hljs-deletion">-\t\telse if (sec-&gt;dofs_type == DOF_SECT_PROBES &amp;&amp; dofstrtab)</span>\n<span class="hljs-addition">+\t\tif (sec-&gt;dofs_type != DOF_SECT_PROVIDER)</span>\n<span class="hljs-addition">+\t\t\tcontinue;</span>\n<span class="hljs-addition">+</span>\n<span class="hljs-addition">+\t\tdofprovider = (void *) (buf + sec-&gt;dofs_offset);</span>\n<span class="hljs-addition">+\t\tdofstrtab = secstart + dofprovider-&gt;dofpv_strtab;</span>\n<span class="hljs-addition">+\t\tdofprobes = secstart + dofprovider-&gt;dofpv_probes;</span>\n<span class="hljs-addition">+</span>\n<span class="hljs-addition">+\t\tif (dofstrtab-&gt;dofs_type != DOF_SECT_STRTAB) {</span>\n<span class="hljs-addition">+\t\t\tfprintf(stderr, "WARNING: expected STRTAB section, but got %d\\n",</span>\n<span class="hljs-addition">+\t\t\t\t\tdofstrtab-&gt;dofs_type);</span>\n \t\t\tbreak;\n<span class="hljs-deletion">-\t</span>\n<span class="hljs-deletion">-\t}</span>\n<span class="hljs-deletion">-\tnprobes = sec-&gt;dofs_size / sec-&gt;dofs_entsize;</span>\n<span class="hljs-deletion">-\tfixsymbol(e, symtabdata, symtabidx, nprobes, buf, sec, &amp;fixedprobes,</span>\n<span class="hljs-deletion">-\t    dofstrtab);</span>\n<span class="hljs-deletion">-\tif (fixedprobes != nprobes) {</span>\n<span class="hljs-deletion">-\t\t/*</span>\n<span class="hljs-deletion">-\t\t * If we haven\'t fixed all the probes using the</span>\n<span class="hljs-deletion">-\t\t * symtab section, look inside the dynsym</span>\n<span class="hljs-deletion">-\t\t * section.</span>\n<span class="hljs-deletion">-\t\t */</span>\n<span class="hljs-deletion">-\t\tfixsymbol(e, dynsymdata, dynsymidx, nprobes, buf, sec,</span>\n<span class="hljs-deletion">-\t\t    &amp;fixedprobes, dofstrtab);</span>\n<span class="hljs-deletion">-\t}</span>\n<span class="hljs-deletion">-\tif (fixedprobes != nprobes) {</span>\n<span class="hljs-deletion">-\t\tfprintf(stderr, "WARNING: number of probes "</span>\n<span class="hljs-deletion">-\t\t    "fixed does not match the number of "</span>\n<span class="hljs-deletion">-\t\t    "defined probes (%d != %d, "</span>\n<span class="hljs-deletion">-\t\t    "respectively)\\n", fixedprobes, nprobes);</span>\n<span class="hljs-deletion">-\t\tfprintf(stderr, "WARNING: some probes might "</span>\n<span class="hljs-deletion">-\t\t    "not fire or your program might crash\\n");</span>\n<span class="hljs-addition">+\t\t}</span>\n<span class="hljs-addition">+\t\tif (dofprobes-&gt;dofs_type != DOF_SECT_PROBES) {</span>\n<span class="hljs-addition">+\t\t\tfprintf(stderr, "WARNING: expected PROBES section, but got %d\\n",</span>\n<span class="hljs-addition">+\t\t\t    dofprobes-&gt;dofs_type);</span>\n<span class="hljs-addition">+\t\t\tbreak;</span>\n<span class="hljs-addition">+\t\t}</span>\n<span class="hljs-addition">+</span>\n<span class="hljs-addition">+\t\tdprintf(1, "found provider %p\\n", dofprovider);</span>\n<span class="hljs-addition">+\t\tdofstrtabraw = (char *)(buf + dofstrtab-&gt;dofs_offset);</span>\n<span class="hljs-addition">+\t\tnprobes = dofprobes-&gt;dofs_size / dofprobes-&gt;dofs_entsize;</span>\n<span class="hljs-addition">+\t\tfixsymbol(e, symtabdata, symtabidx, nprobes, buf, dofprobes, &amp;fixedprobes,</span>\n<span class="hljs-addition">+\t\t\t\tdofstrtabraw);</span>\n<span class="hljs-addition">+\t\tif (fixedprobes != nprobes) {</span>\n<span class="hljs-addition">+\t\t\t/*</span>\n<span class="hljs-addition">+\t\t\t * If we haven\'t fixed all the probes using the</span>\n<span class="hljs-addition">+\t\t\t * symtab section, look inside the dynsym</span>\n<span class="hljs-addition">+\t\t\t * section.</span>\n<span class="hljs-addition">+\t\t\t */</span>\n<span class="hljs-addition">+\t\t\tfixsymbol(e, dynsymdata, dynsymidx, nprobes, buf, dofprobes,</span>\n<span class="hljs-addition">+\t\t\t\t\t&amp;fixedprobes, dofstrtabraw);</span>\n<span class="hljs-addition">+\t\t}</span>\n<span class="hljs-addition">+\t\tif (fixedprobes != nprobes) {</span>\n<span class="hljs-addition">+\t\t\tfprintf(stderr, "WARNING: number of probes "</span>\n<span class="hljs-addition">+\t\t\t    "fixed does not match the number of "</span>\n<span class="hljs-addition">+\t\t\t    "defined probes (%d != %d, "</span>\n<span class="hljs-addition">+\t\t\t    "respectively)\\n", fixedprobes, nprobes);</span>\n<span class="hljs-addition">+\t\t\tfprintf(stderr, "WARNING: some probes might "</span>\n<span class="hljs-addition">+\t\t\t    "not fire or your program might crash\\n");</span>\n<span class="hljs-addition">+\t\t}</span>\n \t}\n #endif\n \tif ((gen = ioctl(fd, DTRACEHIOC_ADDDOF, &amp;dh)) == -1)\n@@ -330,7 +353,12 @@ dtrace_dof_init(void)\n \t}\n \n \t(void) close(fd);\n<span class="hljs-addition">+</span>\n #if !defined(sun)\n<span class="hljs-addition">+\t\t/* End of while loop */</span>\n<span class="hljs-addition">+\t\tdof = dof_next;</span>\n<span class="hljs-addition">+\t}</span>\n<span class="hljs-addition">+</span>\n \telf_end(e);\n \t(void) close(efd);\n #endif\n</code></pre>\n<p>Although, node.js v0.11 has stopped crashing after applying it to the kernel\nsource code and rebuilding <code>libdtrace</code>, it still wasn\'t registering an ustack\nhelper and a provider (<code>sudo dtrace -l</code> did not contain any\n<code>node&lt;pid&gt;:::</code> probes).</p>\n<p>While reading <a href="https://github.com/freebsd/freebsd/blob/4d784918edbf9aefbab5ab12e4701d3104c3ff45/cddl/contrib/opensolaris/lib/libdtrace/common/drti.c#L52">FreeBSD\'s source code</a> further, I found an environment\nvariable <code>DTRACE_DOF_INIT_DEBUG</code> that helped me to take a deeper look into\nwhat was happening for both node.js v0.10 and v0.11. After setting it to\n<code>DTRACE_DOF_INIT_DEBUG=1</code> node.js has started printing following things to the\nstderr:</p>\n<pre><code>dtrace DOF node: DTrace ioctl failed for DOF at 0x804c00000:\nArgument list too long\n</code></pre>\n<p>This was totally uninformative, and I started grepping through a DTrace kernel\nmodule with a hope to find some clues to this errors. <code>Argument list too long</code>\nis a verbose description of the <code>E2BIG</code> errno, and luckily the <a href="https://github.com/freebsd/freebsd/blob/3ecc6f129801776dd571d69cf9a262a97ad23968/sys/cddl/contrib/opensolaris/uts/common/dtrace/dtrace.c#L11989">first place</a>\nwhere it is used was the place that I needed to fix. Basically, for the security\npurpose kernel limits the size of the DOF that could be loaded in it\'s memory.\nThis limit is set to the 128 KB by default, and the node.js now has\nsignificantly bigger ustack helper (7 MB for v0.11). Instead of just raising it\nto a higher value, I decided to export <code>sysctl</code> variable to make it configurable\nwithout rebuilding the kernel. Running node again after this tweaks gave me:</p>\n<pre><code>dtrace DOF node: DTrace ioctl failed for DOF at 0x804c00000:\nInvalid argument\n</code></pre>\n<p>This failure was even more vague, since it meant that the <code>EINVAL</code> was returned\nsomewhere, and there was tons of places where it could have happened. After\ninserting tons of debug prints in all possible places in kernel, I have isolated\nit down to <a href="https://github.com/freebsd/freebsd/blob/3ecc6f129801776dd571d69cf9a262a97ad23968/sys/cddl/contrib/opensolaris/uts/common/dtrace/dtrace.c#L12462">this place</a>. Indeed, both of node DOFs contained a lot of\nactions and the default limit (16 * 1024) was way to small for it. Exporting\nanother sysctl variable has solved all problems and running node.js has finally\nprinted this:</p>\n<pre><code>dtrace DOF node: DTrace ioctl succeeded for DOF at 0x8052c2c2c\ndtrace DOF node: DTrace ioctl succeeded for DOF at 0x804c00000\ndtrace DOF node: found provider 0x8052c3000\n</code></pre>\n<p>Just to confirm it, I checked the <code>dtrace -l</code> output and (yikes!) it was there\ntoo:</p>\n<pre><code>48986 node909 node ... gc-done\n48987 node909 node ... gc-start\n48988 node909 node ... http-client-request\n48989 node909 node ... http-client-response\n48990 node909 node ... http-server-request\n48991 node909 node ... http-server-response\n48992 node909 node ... net-server-connection\n48993 node909 node ... net-socket-read\n48994 node909 node ... net-socket-write\n48995 node909 node ... net-stream-end\n</code></pre>\n<h2>How to apply all this patches</h2>\n<p>I have came up with <a href="https://github.com/indutny/freebsd/compare/release/10.0.0...feature/10.0-dtrace-patches">this instruction</a> for fixing your FreeBSD installation\nto make node.js DTrace helpers work. Just a brief in-line description:</p>\n<ol>\n<li>Apply <a href="https://github.com/indutny/freebsd/compare/release/10.0.0...feature/10.0-dtrace-patches">these patches</a> to <code>/usr/src</code></li>\n<li>Rebuild and install kernel:\n<code>sudo make buildkernel &amp;&amp; sudo make installkernel</code></li>\n<li>Reboot <code>sudo shutdown -r</code></li>\n<li>Raise sysctl limits:</li>\n</ol>\n<ul>\n<li><code>sudo sysctl -w kern.dtrace.helper_actions_max=16000</code></li>\n<li><code>sudo sysctl -w kern.dtrace.dof_maxsize=8000000</code></li>\n</ul>\n<ol start="5">\n<li>Clone node.js:\n<code>git clone git://github.com/joyent/node &amp;&amp; cd node &amp;&amp; git checkout v0.10</code></li>\n<li>Configure it: <code>./configure --prefix=... --with-dtrace</code></li>\n<li>Build and install it: <code>gmake -j24 &amp;&amp; gmake install</code></li>\n<li>Make DTrace device accessible to non-root users:\n<code>sudo chmod 666 /dev/dtrace/helper</code></li>\n<li>Verify that node.js DTrace probes are inserted:\n<code>DTRACE_DOF_INIT_DEBUG=1 /path/to/node</code>.</li>\n</ol>\n<p>Thanks for reading this, and please let me know if any of these patches don\'t\nwork for you!</p>\n'},{slug:"6.smis-and-doubles",title:"SMIs and Doubles",date:"2013-11-14T00:00:00.000Z",html:'<p>This is a third post in the series of the JIT compiling crash-course. For a\ncontext please consider reading <a href="/4.how-to-start-jitting">the first one</a> and <a href="/5.allocating-numbers">the second</a>.</p>\n<h2>Goal</h2>\n<p>Last time we created very basic bump memory allocator and made our existing\ncode work with floating point double numbers, stored in the allocated heap\nobjects. However floating point numbers are not suitable for some of\nprecision-dependent operations and also, since they are stored in memory,\nrequiring additional memory loads and stores, slowing down the code performance.</p>\n<p>Both of this problems could be solved by working with the integers stored in the\nregisters (as we did it in <a href="/4.how-to-start-jitting">first blog post</a>), which means that we will need\nto support both types of numbers in our compiler\'s runtime (doubles and\nintegers).</p>\n<h2>Tagging</h2>\n<p>Let\'s recall that we are storing both pointers and numbers in the 64bit general\npurpose registers (<code>rax</code>, <code>rbx</code>, ...). The main issue here is that, given some\nregister (say <code>rax</code>), we should be able to tell if it is a pointer to the heap\nobject (a &quot;boxed value&quot;) or an integer itself (an &quot;unboxed value&quot;,\nSmall Integer, or <em>SMI</em>).</p>\n<p>Usually, a method called &quot;tagging&quot; is used to solve this. While there are\n<a href="http://wingolog.org/archives/2011/05/18/value-representation-in-javascript-implementations">various ways</a> to implement tagging, including: <a href="http://evilpie.github.io/sayrer-fatval-backup/cache.aspx.htm">Nan-Boxing</a> (scroll down\nto <em>Mozillas New JavaScript Value Representation</em>), Nun-Boxing, and probably\nsome others, our compiler will just reserve the least significant bit of the\n64bit register and put <code>1</code> here if the value is a pointer and <code>0</code> if it is a\n<em>SMI</em> (Small Integer).</p>\n<p>Here is an example of this representation:</p>\n<p><img src="/images/smi-and-pointer.png" alt="Smi and Pointer"></p>\n<p>Note that to get the actual value of a SMI (&quot;untag&quot;) we will need to shift it\nright for one bit (<code>&gt;&gt; 1</code>), and to convert an integer to the SMI - shift left\n(<code>&lt;&lt; 1</code>). Using zero for tagging SMIs pays off greatly, since we don\'t need to\nto untag numbers to perform addition and subtraction.</p>\n<p>To use tagged pointers to heap objects we\'ll need to look one byte behind the\nactual value, which is relatively simple in the assembly language:</p>\n<pre><code class="language-javascript"><span class="hljs-comment">// Lets say that tagged pointer is in rbx</span>\n<span class="hljs-comment">// And we\'re loading its contents into the rax</span>\n<span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rax\'</span>, [<span class="hljs-string">\'rbx\'</span>, <span class="hljs-number">-1</span>]);\n</code></pre>\n<p>And just for the convenience - example of untagging SMIs:</p>\n<pre><code class="language-javascript"><span class="hljs-comment">// Untag</span>\n<span class="hljs-keyword">this</span>.shr(<span class="hljs-string">\'rax\'</span>, <span class="hljs-number">1</span>);\n<span class="hljs-comment">// Tag</span>\n<span class="hljs-keyword">this</span>.shl(<span class="hljs-string">\'rax\'</span>, <span class="hljs-number">1</span>);\n</code></pre>\n<p>And now the most important part that we\'re going to do a lot - checking if the\nvalue is a pointer:</p>\n<pre><code class="language-javascript"><span class="hljs-comment">// Test that \'rax\' has the last bit</span>\n<span class="hljs-keyword">this</span>.test(<span class="hljs-string">\'rax\'</span>, <span class="hljs-number">1</span>);\n\n<span class="hljs-comment">// \'z\' stands for zero</span>\n<span class="hljs-comment">// Basically, jump to the label if `(rax &amp; 1) == 0`</span>\n<span class="hljs-keyword">this</span>.j(<span class="hljs-string">\'z\'</span>, <span class="hljs-string">\'is-smi\'</span>);\n\n<span class="hljs-comment">// \'nz\' stands for non-zero</span>\n<span class="hljs-comment">// Basically, jump to the label if `(rax &amp; 1) != 0`</span>\n<span class="hljs-keyword">this</span>.j(<span class="hljs-string">\'ne\'</span>, <span class="hljs-string">\'is-heap-object-pointer\'</span>);\n</code></pre>\n<h2>Reworking previous code</h2>\n<p>Using <a href="https://github.com/indutny/jit.js/tree/master/example/heap">the code from the previous blog post</a>, we can finally proceed to\nimplementing all this recently learned stuff.</p>\n<p>First, let\'s add a convenient helper methods to the assembly context.</p>\n<pre><code class="language-javascript"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">untagSmi</span>(<span class="hljs-params">reg</span>) </span>{\n  <span class="hljs-keyword">this</span>.shr(reg, <span class="hljs-number">1</span>);\n};\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">checkSmi</span>(<span class="hljs-params">value, t, f</span>) </span>{\n  <span class="hljs-comment">// If no `true-` and `false-` bodies were specified -</span>\n  <span class="hljs-comment">// just test the value.</span>\n  <span class="hljs-keyword">if</span> (!t &amp;&amp; !f)\n    <span class="hljs-keyword">return</span> <span class="hljs-keyword">this</span>.test(value, <span class="hljs-number">1</span>);\n\n  <span class="hljs-comment">// Enter the scope to be able to use named labels</span>\n  <span class="hljs-keyword">this</span>.labelScope(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n    <span class="hljs-comment">// Test the value</span>\n    <span class="hljs-keyword">this</span>.test(value, <span class="hljs-number">1</span>);\n\n    <span class="hljs-comment">// Skip SMI case if result is non-zero</span>\n    <span class="hljs-keyword">this</span>.j(<span class="hljs-string">\'nz\'</span>, <span class="hljs-string">\'non-smi\'</span>);\n\n    <span class="hljs-comment">// Run SMI case</span>\n    t.call(<span class="hljs-keyword">this</span>);\n\n    <span class="hljs-comment">// Jump to the shared end</span>\n    <span class="hljs-keyword">this</span>.j(<span class="hljs-string">\'end\'</span>);\n\n    <span class="hljs-comment">// Non-SMI case</span>\n    <span class="hljs-keyword">this</span>.bind(<span class="hljs-string">\'non-smi\'</span>);\n    f.call(<span class="hljs-keyword">this</span>);\n\n    <span class="hljs-comment">// Shared end</span>\n    <span class="hljs-keyword">this</span>.bind(<span class="hljs-string">\'end\'</span>);\n  });\n};\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">heapOffset</span>(<span class="hljs-params">reg, offset</span>) </span>{\n  <span class="hljs-comment">// <span class="hljs-doctag">NOTE:</span> 8 is the size of pointer on x64 arch.</span>\n  <span class="hljs-comment">// We\'re adding 1 to the offset, because first</span>\n  <span class="hljs-comment">// quad word is used to store the heap object\'s type.</span>\n  <span class="hljs-keyword">return</span> [reg, <span class="hljs-number">8</span> * ((offset | <span class="hljs-number">0</span>) + <span class="hljs-number">1</span>) - <span class="hljs-number">1</span>];\n};\n</code></pre>\n<p>We can hook this methods into the jit.js context by passing them as a <code>helpers</code>\noption to the <code>jit.compile()</code> API method:</p>\n<pre><code class="language-javascript"><span class="hljs-keyword">var</span> helpers = {\n  <span class="hljs-attr">untagSmi</span>: untagSmi,\n  <span class="hljs-attr">checkSmi</span>: checkSmi,\n  <span class="hljs-attr">heapOffset</span>: heapOffset\n};\n\njit.compile(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n  <span class="hljs-comment">// We can use helpers here:</span>\n  <span class="hljs-keyword">this</span>.untagSmi(<span class="hljs-string">\'rax\'</span>);\n\n  <span class="hljs-keyword">this</span>.checkSmi(<span class="hljs-string">\'rbx\'</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n    <span class="hljs-comment">// Work with SMI</span>\n  }, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n    <span class="hljs-comment">// Work with pointer</span>\n  });\n\n  <span class="hljs-keyword">this</span>.mov(<span class="hljs-keyword">this</span>.heapOffset(<span class="hljs-string">\'rbx\'</span>, <span class="hljs-number">0</span>), <span class="hljs-number">1</span>);\n}, { <span class="hljs-attr">stubs</span>: stubs, <span class="hljs-attr">helpers</span>: helpers });\n</code></pre>\n<h2>Allocation</h2>\n<p>Now we should make our <code>Alloc</code> stub return tagged pointer. Also we will use the\nopportunity and improve it a bit by adding <code>tag</code> and <code>size</code> arguments to the\nstub (thus making possible generalized allocation with variable size and tag\nin the future):</p>\n<pre><code class="language-javascript">stubs.define(<span class="hljs-string">\'Alloc\'</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">size, tag</span>) </span>{\n  <span class="hljs-comment">// Save \'rbx\' and \'rcx\' registers</span>\n  <span class="hljs-keyword">this</span>.spill([<span class="hljs-string">\'rbx\'</span>, <span class="hljs-string">\'rcx\'</span>], <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n    <span class="hljs-comment">// Load `offset`</span>\n    <span class="hljs-comment">//</span>\n    <span class="hljs-comment">// <span class="hljs-doctag">NOTE:</span> We\'ll use pointer to `offset` variable,</span>\n    <span class="hljs-comment">// to be able to update</span>\n    <span class="hljs-comment">// it below</span>\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rax\'</span>, <span class="hljs-keyword">this</span>.ptr(offset));\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rax\'</span>, [<span class="hljs-string">\'rax\'</span>]);\n\n    <span class="hljs-comment">// Load end</span>\n    <span class="hljs-comment">//</span>\n    <span class="hljs-comment">// <span class="hljs-doctag">NOTE:</span> Same applies to end, though, we\'re</span>\n    <span class="hljs-comment">// not updating it right now</span>\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rbx\'</span>, <span class="hljs-keyword">this</span>.ptr(end));\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rbx\'</span>, [<span class="hljs-string">\'rbx\'</span>]);\n\n    <span class="hljs-comment">// Calculate new `offset`</span>\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rcx\'</span>, <span class="hljs-string">\'rax\'</span>);\n\n    <span class="hljs-comment">// Add tag size and body size</span>\n    <span class="hljs-keyword">this</span>.add(<span class="hljs-string">\'rcx\'</span>, <span class="hljs-number">8</span>);\n    <span class="hljs-keyword">this</span>.add(<span class="hljs-string">\'rcx\'</span>, size);\n\n    <span class="hljs-comment">// Check if we won\'t overflow our fixed size buffer</span>\n    <span class="hljs-keyword">this</span>.cmp(<span class="hljs-string">\'rcx\'</span>, <span class="hljs-string">\'rbx\'</span>);\n\n    <span class="hljs-comment">// this.j() performs conditional jump to the specified label.</span>\n    <span class="hljs-comment">// \'g\' stands for \'greater\'</span>\n    <span class="hljs-comment">// \'overflow\' is a label name, bound below</span>\n    <span class="hljs-keyword">this</span>.j(<span class="hljs-string">\'g\'</span>, <span class="hljs-string">\'overflow\'</span>);\n\n    <span class="hljs-comment">// Ok, we\'re good to go, update offset</span>\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rbx\'</span>, <span class="hljs-keyword">this</span>.ptr(offset));\n    <span class="hljs-keyword">this</span>.mov([<span class="hljs-string">\'rbx\'</span>], <span class="hljs-string">\'rcx\'</span>);\n\n    <span class="hljs-comment">// First 64bit pointer is reserved for \'tag\',</span>\n    <span class="hljs-comment">// second one is a `double` value</span>\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rcx\'</span>, tag);\n    <span class="hljs-keyword">this</span>.mov([<span class="hljs-string">\'rax\'</span>], <span class="hljs-string">\'rcx\'</span>);\n\n    <span class="hljs-comment">// !!!!!!!!!!!!!!!</span>\n    <span class="hljs-comment">// ! Tag pointer !</span>\n    <span class="hljs-comment">// !!!!!!!!!!!!!!!</span>\n    <span class="hljs-keyword">this</span>.or(<span class="hljs-string">\'rax\'</span>, <span class="hljs-number">1</span>);\n\n    <span class="hljs-comment">// Return \'rax\'</span>\n    <span class="hljs-keyword">this</span>.Return();\n\n    <span class="hljs-comment">// Overflowed :(</span>\n    <span class="hljs-keyword">this</span>.bind(<span class="hljs-string">\'overflow\'</span>)\n\n    <span class="hljs-comment">// Invoke javascript function!</span>\n    <span class="hljs-comment">// <span class="hljs-doctag">NOTE:</span> This is really funky stuff, but I\'m not</span>\n    <span class="hljs-comment">// going to dive deep into it right now</span>\n    <span class="hljs-keyword">this</span>.runtime(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n      <span class="hljs-built_in">console</span>.log(<span class="hljs-string">\'GC is needed, but not implemented\'</span>);\n    });\n\n    <span class="hljs-comment">// Crash</span>\n    <span class="hljs-keyword">this</span>.int3();\n\n    <span class="hljs-keyword">this</span>.Return();\n  });\n});\n</code></pre>\n<h2>Math stubs</h2>\n<p>Also, as we\'re going to do a bit more book-keeping in math operations to support\nboth SMIs and doubles, let\'s split it apart and put the code, handling doubles\ninto the stub:</p>\n<pre><code class="language-javascript"><span class="hljs-keyword">var</span> operators = [<span class="hljs-string">\'+\'</span>, <span class="hljs-string">\'-\'</span>, <span class="hljs-string">\'*\'</span>, <span class="hljs-string">\'/\'</span>];\n<span class="hljs-keyword">var</span> map = { <span class="hljs-string">\'+\'</span>: <span class="hljs-string">\'addsd\'</span>, <span class="hljs-string">\'-\'</span>: <span class="hljs-string">\'subsd\'</span>, <span class="hljs-string">\'*\'</span>: <span class="hljs-string">\'mulsd\'</span>,\n            <span class="hljs-string">\'/\'</span>: <span class="hljs-string">\'divsd\'</span> };\n\n<span class="hljs-comment">// Define `Binary+`, `Binary-`, `Binary*`, and `Binary/` stubs</span>\noperators.forEach(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">operator</span>) </span>{\n  stubs.define(<span class="hljs-string">\'Binary\'</span> + operator, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">left, right</span>) </span>{\n    <span class="hljs-comment">// Save \'rbx\' and \'rcx\'</span>\n    <span class="hljs-keyword">this</span>.spill([<span class="hljs-string">\'rbx\'</span>, <span class="hljs-string">\'rcx\'</span>], <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n      <span class="hljs-comment">// Load arguments to rax and rbx</span>\n      <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rax\'</span>, left);\n      <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rbx\'</span>, right);\n\n      <span class="hljs-comment">// Convert both numbers to doubles</span>\n      [[<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'xmm1\'</span>], [<span class="hljs-string">\'rbx\'</span>, <span class="hljs-string">\'xmm2\'</span>]].forEach(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">regs</span>) </span>{\n        <span class="hljs-keyword">var</span> nonSmi = <span class="hljs-keyword">this</span>.label();\n        <span class="hljs-keyword">var</span> done = <span class="hljs-keyword">this</span>.label();\n\n        <span class="hljs-keyword">this</span>.checkSmi(regs[<span class="hljs-number">0</span>]);\n        <span class="hljs-keyword">this</span>.j(<span class="hljs-string">\'nz\'</span>, nonSmi);\n\n        <span class="hljs-comment">// Convert integer to double</span>\n        <span class="hljs-keyword">this</span>.untagSmi(regs[<span class="hljs-number">0</span>]);\n        <span class="hljs-keyword">this</span>.cvtsi2sd(regs[<span class="hljs-number">1</span>], regs[<span class="hljs-number">0</span>]);\n\n        <span class="hljs-keyword">this</span>.j(done);\n        <span class="hljs-keyword">this</span>.bind(nonSmi);\n\n        <span class="hljs-keyword">this</span>.movq(regs[<span class="hljs-number">1</span>], <span class="hljs-keyword">this</span>.heapOffset(regs[<span class="hljs-number">0</span>], <span class="hljs-number">0</span>));\n        <span class="hljs-keyword">this</span>.bind(done);\n      }, <span class="hljs-keyword">this</span>);\n\n      <span class="hljs-keyword">var</span> instr = map[operator];\n\n      <span class="hljs-comment">// Execute binary operation</span>\n      <span class="hljs-keyword">if</span> (instr) {\n        <span class="hljs-keyword">this</span>[instr](<span class="hljs-string">\'xmm1\'</span>, <span class="hljs-string">\'xmm2\'</span>);\n      } <span class="hljs-keyword">else</span> {\n        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-built_in">Error</span>(<span class="hljs-string">\'Unsupported binary operator: \'</span> +\n                        operator);\n      }\n\n      <span class="hljs-comment">// Allocate new number, and put value in it</span>\n      <span class="hljs-comment">// <span class="hljs-doctag">NOTE:</span> Last two arguments are arguments to</span>\n      <span class="hljs-comment">// the stub (`size` and `tag`)</span>\n      <span class="hljs-keyword">this</span>.stub(<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'Alloc\'</span>, <span class="hljs-number">8</span>, <span class="hljs-number">1</span>);\n      <span class="hljs-keyword">this</span>.movq(<span class="hljs-keyword">this</span>.heapOffset(<span class="hljs-string">\'rax\'</span>, <span class="hljs-number">0</span>), <span class="hljs-string">\'xmm1\'</span>);\n    });\n\n    <span class="hljs-keyword">this</span>.Return();\n  });\n});\n</code></pre>\n<p>Note that this stub also converts all incoming numbers to doubles.</p>\n<h2>Compiler</h2>\n<p>And back to the compiler\'s code:</p>\n<pre><code class="language-javascript"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">visitProgram</span>(<span class="hljs-params">ast</span>) </span>{\n  assert.equal(ast.body.length,\n               <span class="hljs-number">1</span>,\n               <span class="hljs-string">\'Only one statement programs are supported\'</span>);\n  assert.equal(ast.body[<span class="hljs-number">0</span>].type, <span class="hljs-string">\'ExpressionStatement\'</span>);\n\n  <span class="hljs-comment">// We\'ve a pointer in \'rax\', convert it to integer</span>\n  visit.call(<span class="hljs-keyword">this</span>, ast.body[<span class="hljs-number">0</span>].expression);\n\n  <span class="hljs-comment">// Get floating point number out of heap number</span>\n  <span class="hljs-keyword">this</span>.checkSmi(<span class="hljs-string">\'rax\'</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n    <span class="hljs-comment">// Untag smi</span>\n    <span class="hljs-keyword">this</span>.untagSmi(<span class="hljs-string">\'rax\'</span>);\n  }, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n    <span class="hljs-keyword">this</span>.movq(<span class="hljs-string">\'xmm1\'</span>, <span class="hljs-keyword">this</span>.heapOffset(<span class="hljs-string">\'rax\'</span>, <span class="hljs-number">0</span>));\n\n    <span class="hljs-comment">// Round it towards zero</span>\n    <span class="hljs-keyword">this</span>.roundsd(<span class="hljs-string">\'zero\'</span>, <span class="hljs-string">\'xmm1\'</span>, <span class="hljs-string">\'xmm1\'</span>);\n\n    <span class="hljs-comment">// Convert double to integer</span>\n    <span class="hljs-keyword">this</span>.cvtsd2si(<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'xmm1\'</span>);\n  });\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">visitLiteral</span>(<span class="hljs-params">ast</span>) </span>{\n  assert.equal(<span class="hljs-keyword">typeof</span> ast.value, <span class="hljs-string">\'number\'</span>);\n\n  <span class="hljs-keyword">if</span> ((ast.value | <span class="hljs-number">0</span>) === ast.value) {\n    <span class="hljs-comment">// Small Integer (SMI), Tagged value</span>\n    <span class="hljs-comment">// (i.e. val * 2) with last bit set to</span>\n    <span class="hljs-comment">// zero</span>\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rax\'</span>, utils.tagSmi(ast.value));\n  } <span class="hljs-keyword">else</span> {\n    <span class="hljs-comment">// Allocate new heap number</span>\n    <span class="hljs-keyword">this</span>.stub(<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'Alloc\'</span>, <span class="hljs-number">8</span>, <span class="hljs-number">1</span>);\n\n    <span class="hljs-comment">// Save \'rbx\' register</span>\n    <span class="hljs-keyword">this</span>.spill(<span class="hljs-string">\'rbx\'</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n      <span class="hljs-keyword">this</span>.loadDouble(<span class="hljs-string">\'rbx\'</span>, ast.value);\n\n      <span class="hljs-comment">// <span class="hljs-doctag">NOTE:</span> Pointers have last bit set to 1</span>\n      <span class="hljs-comment">// That\'s why we need to use \'heapOffset\'</span>\n      <span class="hljs-comment">// routine to access it\'s memory</span>\n      <span class="hljs-keyword">this</span>.mov(<span class="hljs-keyword">this</span>.heapOffset(<span class="hljs-string">\'rax\'</span>, <span class="hljs-number">0</span>), <span class="hljs-string">\'rbx\'</span>);\n    });\n  }\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">visitBinary</span>(<span class="hljs-params">ast</span>) </span>{\n  <span class="hljs-comment">// Preserve \'rbx\' after leaving the AST node</span>\n  <span class="hljs-keyword">this</span>.spill(<span class="hljs-string">\'rbx\'</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n    <span class="hljs-comment">// Visit left side of expresion</span>\n    visit.call(<span class="hljs-keyword">this</span>, ast.right);\n\n    <span class="hljs-comment">// Move it to \'rbx\'</span>\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rbx\'</span>, <span class="hljs-string">\'rax\'</span>);\n\n    <span class="hljs-comment">// Visit right side of expression (the result is in \'rax\')</span>\n    visit.call(<span class="hljs-keyword">this</span>, ast.left);\n\n    <span class="hljs-comment">//</span>\n    <span class="hljs-comment">// So, to conclude, we\'ve left side in \'rax\' and right in \'rbx\'</span>\n    <span class="hljs-comment">//</span>\n\n    <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'/\'</span>) {\n      <span class="hljs-comment">// Call stub for division</span>\n      <span class="hljs-keyword">this</span>.stub(<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'Binary\'</span> + ast.operator, <span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'rbx\'</span>);\n    } <span class="hljs-keyword">else</span> {\n      <span class="hljs-keyword">this</span>.labelScope(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n        <span class="hljs-comment">// Check if both numbers are SMIs</span>\n        <span class="hljs-keyword">this</span>.checkSmi(<span class="hljs-string">\'rax\'</span>);\n        <span class="hljs-keyword">this</span>.j(<span class="hljs-string">\'nz\'</span>, <span class="hljs-string">\'call stub\'</span>);\n        <span class="hljs-keyword">this</span>.checkSmi(<span class="hljs-string">\'rbx\'</span>);\n        <span class="hljs-keyword">this</span>.j(<span class="hljs-string">\'nz\'</span>, <span class="hljs-string">\'call stub\'</span>);\n\n        <span class="hljs-comment">// Save rax in case of overflow</span>\n        <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rcx\'</span>, <span class="hljs-string">\'rax\'</span>);\n\n        <span class="hljs-comment">// <span class="hljs-doctag">NOTE:</span> both \'rax\' and \'rbx\' are tagged at this</span>\n        <span class="hljs-comment">// point.</span>\n        <span class="hljs-comment">// Tags don\'t need to be removed if we\'re doing</span>\n        <span class="hljs-comment">// addition or subtraction. However, in case of</span>\n        <span class="hljs-comment">// multiplication result would be 2x bigger if</span>\n        <span class="hljs-comment">// we won\'t untag one of the arguments.</span>\n        <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'+\'</span>) {\n          <span class="hljs-keyword">this</span>.add(<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'rbx\'</span>);\n        } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'-\'</span>) {\n          <span class="hljs-keyword">this</span>.sub(<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'rbx\'</span>);\n        } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'*\'</span>) {\n          <span class="hljs-keyword">this</span>.untagSmi(<span class="hljs-string">\'rax\'</span>);\n          <span class="hljs-keyword">this</span>.mul(<span class="hljs-string">\'rbx\'</span>);\n        }\n\n        <span class="hljs-comment">// On overflow restore \'rax\' from \'rcx\' and invoke stub</span>\n        <span class="hljs-keyword">this</span>.j(<span class="hljs-string">\'o\'</span>, <span class="hljs-string">\'restore\'</span>);\n\n        <span class="hljs-comment">// Otherwise return \'rax\'</span>\n        <span class="hljs-keyword">this</span>.j(<span class="hljs-string">\'done\'</span>);\n        <span class="hljs-keyword">this</span>.bind(<span class="hljs-string">\'restore\'</span>);\n\n        <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'rcx\'</span>);\n\n        <span class="hljs-keyword">this</span>.bind(<span class="hljs-string">\'call stub\'</span>);\n\n        <span class="hljs-comment">// Invoke stub and return heap number in \'rax\'</span>\n        <span class="hljs-keyword">this</span>.stub(<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'Binary\'</span> + ast.operator, <span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'rbx\'</span>);\n\n        <span class="hljs-keyword">this</span>.bind(<span class="hljs-string">\'done\'</span>);\n      });\n    }\n  });\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">visitUnary</span>(<span class="hljs-params">ast</span>) </span>{\n  <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'-\'</span>) {\n    <span class="hljs-comment">// Negate argument by emulating binary expression</span>\n    visit.call(<span class="hljs-keyword">this</span>, {\n      <span class="hljs-attr">type</span>: <span class="hljs-string">\'BinaryExpression\'</span>,\n      <span class="hljs-attr">operator</span>: <span class="hljs-string">\'*\'</span>,\n      <span class="hljs-attr">left</span>: ast.argument,\n      <span class="hljs-attr">right</span>: { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Literal\'</span>, <span class="hljs-attr">value</span>: <span class="hljs-number">-1</span> }\n    })\n  } <span class="hljs-keyword">else</span> {\n    <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-built_in">Error</span>(<span class="hljs-string">\'Unsupported unary operator: \'</span> + ast.operator);\n  }\n}\n</code></pre>\n<p>To conclude, we are now working with SMIs by default, inlining all operations\nfor the speed\'s sake, and falling back to the doubles in case of overflow or any\nother trouble, like trying to sum a double and a SMI!</p>\n<p>That\'s all for now, see you here next time! Here is the full compiler code from\nthis article: <a href="https://github.com/indutny/jit.js/tree/master/example/heap-smi-and-double">github</a>. Please try cloning, running and playing with it!\nHope you enjoyed this post.</p>\n'},{slug:"5.allocating-numbers",title:"Allocating numbers",date:"2013-11-06T00:00:00.000Z",html:'<h2>JIT</h2>\n<p>This is the second blog post in the series about JIT compiling.\n<a href="/4.how-to-start-jitting">The previous post</a> was an introduction into the Just-In-Time code\ngeneration and, in particular, <a href="https://github.com/indutny/jit.js">jit.js</a> usage. If you haven\'t read it yet -\nI recommend you to familiarize yourself with <a href="/4.how-to-start-jitting">it</a> first.</p>\n<h2>Objectives</h2>\n<p>Previously, we created a JIT compiler, supporting a very limited subset of\nJavaScript: integer numbers, math binary operators (<code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>), and\n<code>-</code> unary operator. This time, we will extend it by adding floating point\nnumber support, and, to make the process funnier and to spice things up,\nwe will allocate and store these numbers in the heap.</p>\n<p>Though, because we are doing things one step at a time, our heap won\'t have\nGarbage Collection, and will live inside fixed sized memory chunk (say &quot;yay&quot; to\nsimplicity!).</p>\n<h2>Stubs</h2>\n<p>Knowing what we aim to do, we can now set up internal structures for these\nfeatures. Essentially, what we\'ll need is a memory allocation procedure, that\ngenerates and returns memory addresses suitable for our goals.</p>\n<p>This allocation code could be generated for every AST node using series of\ninlined assembly instructions, which works great and, more importantly, is\nincredibly fast for concise operations. But due to the relatively big code\'s\nsize of this procedure, the resulting machine code output may become too big to\nbe fit entirely into the CPU\'s cache, causing potential performance problems to\nthe whole system.</p>\n<p>Generally, this is considered a bad practice. A better approach would be\nparameterizing such code blocks into shared procedures called <code>stubs</code> (I picked\nthat naming from <a href="https://github.com/v8/v8/blob/master/src/ia32/code-stubs-ia32.cc">v8\'s source</a> and, perhaps, it is how these things are\nnamed in other VMs too). For even better optimization these procedures\ncould be lazily compiled, i.e. we should not compile those ones that are not\nused by generated code. This technique is good for both compilation time and\nexecutable code size (and therefore CPU caches too).</p>\n<p>Fortunately, <a href="https://github.com/indutny/jit.js">jit.js</a> lets you generate <em>stubs</em> easily:</p>\n<pre><code class="language-javascript"><span class="hljs-keyword">var</span> stubs = jit.stubs();\n\nstubs.define(<span class="hljs-string">\'Allocate\'</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n  <span class="hljs-comment">// Our code here</span>\n  <span class="hljs-comment">// ....</span>\n\n  <span class="hljs-comment">// Returning back to caller</span>\n  <span class="hljs-keyword">this</span>.Return();\n});\n</code></pre>\n<p>Simple, isn\'t it? Now, to use it in our JIT compiler we\'ll need to pass it in\nan options argument:</p>\n<pre><code class="language-javascript">jit.compile(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n  <span class="hljs-comment">// Compiler code generation happens in this context</span>\n\n  <span class="hljs-comment">// Explanation:</span>\n  <span class="hljs-comment">// Read address of \'Allocate\' stub into \'rax\' register and</span>\n  <span class="hljs-comment">// call it.</span>\n  <span class="hljs-keyword">this</span>.stub(<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'Allocate\'</span>);\n\n  <span class="hljs-keyword">this</span>.Return();\n}, { <span class="hljs-attr">stubs</span>: stubs });\n</code></pre>\n<p>As mentioned above, only stubs that were used during compilation process will\nactually be generated and reused between all callers.</p>\n<h2>Heap</h2>\n<p>With this knowledge, we can proceed to the memory allocation phase. But first,\nlets take a short look at the structure and organization of the heap.</p>\n<p>The <em>heap</em> is the place where JavaScript (and many other) VMs create and store\nobjects (usually, ones that can\'t be fit into CPU registers). Some heap objects\nmay contain references to other objects (in other words, can reference them).\nAll live objects and their references create a directed graph, starting at\nso called <em>roots</em> (which are usually global variables and pointers on stack).</p>\n<p>Although, it is usually used in VMs with JIT compilation, Garbage Collection is\nnot required for the Heap. Indeed, many VMs and languages choose to use\nunmanaged memory instead (C/C++ as a banal example). In such cases you (as the\nlanguage user) will generally need to explicitly free unused resources to not\nrun out of the memory.</p>\n<p>But for obvious reasons, the JavaScript subset compiler that we\'re implementing,\nshould support both managed memory and Garbage Collection (which will be\nimplemented later).</p>\n<p>There are tons of books that may give you an advanced introduction into the\nheap allocation and garbage collection (my recommendation is\n<a href="http://www.amazon.com/The-Garbage-Collection-Handbook-Management/dp/1420082795/ref=sr_1_1?ie=UTF8&amp;qid=1383600127&amp;sr=8-1&amp;keywords=garbage+collection+handbook">The Garbage Collection Handbook</a>), and considerably many ways to allocate\nand collect memory in the heap.</p>\n<p>Usually, you will need to choose between the allocation speed and memory\nfragmentation. But, since we are not covering this very deeply, I would\nrecommend to stick with the method called &quot;bump allocation&quot; for now.</p>\n<h2>Bump allocation</h2>\n<p>Fixed-page bump allocation works in a following way.</p>\n<ol>\n<li>Take the memory chunk of fixed size (a <em>page</em>)</li>\n<li>Give away consequent slices of it as a return value of the allocation\nprocedure.</li>\n<li>When running low on memory, perform the Garbage Collection and free all\nunused space, by either compacting live objects or evacuating them to the\nnew memory chunk (replacing references to live objects in both cases).</li>\n</ol>\n<p>In terms of <a href="https://github.com/indutny/jit.js">jit.js</a> and stubs API, this procedure may look as following:</p>\n<pre><code class="language-javascript"><span class="hljs-comment">// Create fixed size memory chunk</span>\n<span class="hljs-keyword">var</span> page = <span class="hljs-keyword">new</span> Buffer(<span class="hljs-number">1024</span>);\n\n<span class="hljs-comment">// Set-up pointers to page start and page end</span>\n<span class="hljs-keyword">var</span> offset = jit.ptr(page);\n<span class="hljs-keyword">var</span> end = jit.ptr(page, page.length);\n\nstubs.define(<span class="hljs-string">\'Alloc\'</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n\n  <span class="hljs-comment">// Save \'rbx\' and \'rcx\' registers</span>\n  <span class="hljs-keyword">this</span>.spill([<span class="hljs-string">\'rbx\'</span>, <span class="hljs-string">\'rcx\'</span>], <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n    <span class="hljs-comment">// Load `offset`</span>\n    <span class="hljs-comment">//</span>\n    <span class="hljs-comment">// <span class="hljs-doctag">NOTE:</span> We\'ll use pointer to `offset` variable, to be able to update</span>\n    <span class="hljs-comment">// it below</span>\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rax\'</span>, <span class="hljs-keyword">this</span>.ptr(offset));\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rax\'</span>, [<span class="hljs-string">\'rax\'</span>]);\n\n    <span class="hljs-comment">// Load end</span>\n    <span class="hljs-comment">//</span>\n    <span class="hljs-comment">// <span class="hljs-doctag">NOTE:</span> Same applies to end, though, we\'re not updating it right now</span>\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rbx\'</span>, <span class="hljs-keyword">this</span>.ptr(end));\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rbx\'</span>, [<span class="hljs-string">\'rbx\'</span>]);\n\n    <span class="hljs-comment">// Calculate new `offset`</span>\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rcx\'</span>, <span class="hljs-string">\'rax\'</span>);\n\n    <span class="hljs-comment">// We\'ll assume that all allocations are 16 bytes = two 64bit pointers</span>\n    <span class="hljs-keyword">this</span>.add(<span class="hljs-string">\'rcx\'</span>, <span class="hljs-number">16</span>);\n\n    <span class="hljs-comment">// Check if we won\'t overflow our fixed size buffer</span>\n    <span class="hljs-keyword">this</span>.cmp(<span class="hljs-string">\'rcx\'</span>, <span class="hljs-string">\'rbx\'</span>);\n\n    <span class="hljs-comment">// this.j() performs conditional jump to the specified label.</span>\n    <span class="hljs-comment">// \'g\' stands for \'greater\'</span>\n    <span class="hljs-comment">// \'overflow\' is a label name, bound below</span>\n    <span class="hljs-keyword">this</span>.j(<span class="hljs-string">\'g\'</span>, <span class="hljs-string">\'overflow\'</span>);\n\n    <span class="hljs-comment">// Ok, we\'re good to go, update offset</span>\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rbx\'</span>, <span class="hljs-keyword">this</span>.ptr(offset));\n    <span class="hljs-keyword">this</span>.mov([<span class="hljs-string">\'rbx\'</span>], <span class="hljs-string">\'rcx\'</span>);\n\n    <span class="hljs-comment">// The first 64bit pointer is reserved for \'tag\',</span>\n    <span class="hljs-comment">// the second one is a `double` value</span>\n    <span class="hljs-keyword">this</span>.mov([<span class="hljs-string">\'rax\'</span>], <span class="hljs-number">1</span>);\n\n    <span class="hljs-comment">// Return \'rax\'</span>\n    <span class="hljs-keyword">this</span>.Return();\n\n    <span class="hljs-comment">// Overflowed :(</span>\n    <span class="hljs-keyword">this</span>.bind(<span class="hljs-string">\'overflow\'</span>)\n\n    <span class="hljs-comment">// Invoke javascript function!</span>\n    <span class="hljs-comment">// <span class="hljs-doctag">NOTE:</span> This is really funky stuff, but I\'m not going to dive deep</span>\n    <span class="hljs-comment">// into it right now</span>\n    <span class="hljs-keyword">this</span>.runtime(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n      <span class="hljs-built_in">console</span>.log(<span class="hljs-string">\'GC is needed, but not implemented\'</span>);\n    });\n\n    <span class="hljs-comment">// Crash</span>\n    <span class="hljs-keyword">this</span>.int3();\n\n    <span class="hljs-keyword">this</span>.Return();\n  });\n});\n</code></pre>\n<p>That\'s it! Not totally straightforward, but not really complicated either!</p>\n<p>This procedure will give away consequent slices of the <em>page</em>, and even tag\nthem! (I\'ll cover tagging in one of the next posts. Basically, they\'re used to\ndistinguish different kinds of heap objects).</p>\n<p>Few things to note here:</p>\n<ol>\n<li><code>jit.ptr(buf, offset)</code> returns a <code>Buffer</code>, containing a pointer to the given\n<code>buf</code> with <code>offset</code> added to it.</li>\n<li><code>this.spill()</code> is a routine for saving and restoring registers to/from the\nmemory (this process is usually called <em>spilling</em>). It takes list of the\nregisters and the closure. These registers will be saved before entering the\nclosure, and restored right after leaving it.\nNOTE: The restore code will be generated before each <code>this.Return()</code> too.</li>\n<li><code>this.mov([\'rbx\'], \'rcx\')</code> - stores <code>rcx</code> register into the memory location,\npointed by the value of <code>rbx</code> register.\nNOTE: you can also specify an offset here: <code>this.mov([\'rbx\', 8], \'rcx\')</code>.</li>\n<li>jit.js supports branching primitives: <code>this.cmp(a, b)</code>,\n<code>this.j(condition, labelName)</code>, <code>this.j(labelName)</code>, <code>this.bind(labelName)</code>.</li>\n</ol>\n<h1>Floating point</h1>\n<p>Now as we have a <em>presumably</em> working allocation procedure, let\'s recall what\nshould be stored inside of this heap chunks. In the allocation procedure, we\ncreate chunks with the 8 byte tag value, and the 8 byte contents. This is\nenough to store <code>double</code> (as C type) floating point numbers.</p>\n<p>There are plenty of assembly instructions to load/store/work with such numbers.\nBut note that to work with them - you\'ll need to store them in the different\nregister set: <code>xmm0</code>, <code>xmm1</code>, ... <code>xmm15</code>. Although, 64-bit floating numbers\ncould be stored in the general purpose registers: <code>rax</code>, <code>rbx</code>, ... Performing\nmath operations is possible only with a <code>xmm</code> register set. Here are some\ninstructions, that are present in <code>jit.js</code> and should be useful for our\ncompiler:</p>\n<ol>\n<li><code>movq(\'xmm\', \'gp\')</code> or <code>movq(\'gp\', \'xmm\')</code> to move 64bits from the general\npurpose register (or memory pointed by it) to xmm, or the other way around.</li>\n<li><code>movsd(\'xmm\', \'xmm\')</code> to move the value from one xmm to another.</li>\n<li><code>addsd</code>, <code>mulsd</code>, <code>subsd</code>, <code>divsd</code> - addition, multiplication, subtraction,\ndivision.</li>\n<li><code>cvtsi2sd(\'xmm\', \'gp\')</code>, <code>cvts2si(\'gp\', \'xmm\')</code> - converts integer into\ndouble, and double into integer, respectively.</li>\n<li><code>roundsd(\'mode\', \'xmm\', \'xmm\')</code> - round the <code>src</code> register using specified\n<code>mode</code> (which is one of: <code>nearest</code>, <code>down</code>, <code>up</code>, <code>zero</code>) and place the\nresult into the <code>dst</code> register.</li>\n</ol>\n<p>Using this sacred knowledge we can patch our existing code to make it work with\nthe floating point numbers (yeah, we will remove the integer support for now):</p>\n<pre><code class="language-javascript"><span class="hljs-comment">// Compile</span>\n<span class="hljs-keyword">var</span> fn = jit.compile(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n  <span class="hljs-comment">// This will generate default entry boilerplate</span>\n  <span class="hljs-keyword">this</span>.Proc(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n    visit.call(<span class="hljs-keyword">this</span>, ast);\n\n    <span class="hljs-comment">// The result should be in \'rax\' at this point</span>\n    <span class="hljs-comment">//</span>\n    <span class="hljs-comment">// This will generate default exit boilerplate</span>\n    <span class="hljs-keyword">this</span>.Return();\n  });\n}, { <span class="hljs-attr">stubs</span>: stubs });\n\n<span class="hljs-comment">// Execute</span>\n<span class="hljs-built_in">console</span>.log(fn());\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">visit</span>(<span class="hljs-params">ast</span>) </span>{\n  <span class="hljs-keyword">if</span> (ast.type === <span class="hljs-string">\'Program\'</span>)\n    visitProgram.call(<span class="hljs-keyword">this</span>, ast);\n  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ast.type === <span class="hljs-string">\'Literal\'</span>)\n    visitLiteral.call(<span class="hljs-keyword">this</span>, ast);\n  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ast.type === <span class="hljs-string">\'UnaryExpression\'</span>)\n    visitUnary.call(<span class="hljs-keyword">this</span>, ast);\n  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ast.type === <span class="hljs-string">\'BinaryExpression\'</span>)\n    visitBinary.call(<span class="hljs-keyword">this</span>, ast);\n  <span class="hljs-keyword">else</span>\n    <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-built_in">Error</span>(<span class="hljs-string">\'Unknown ast node: \'</span> + ast.type);\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">visitProgram</span>(<span class="hljs-params">ast</span>) </span>{\n  assert.equal(ast.body.length,\n               <span class="hljs-number">1</span>,\n               <span class="hljs-string">\'Only one statement programs are supported\'</span>);\n  assert.equal(ast.body[<span class="hljs-number">0</span>].type, <span class="hljs-string">\'ExpressionStatement\'</span>);\n\n  <span class="hljs-comment">// We\'ve a pointer in \'rax\', convert it to integer</span>\n  visit.call(<span class="hljs-keyword">this</span>, ast.body[<span class="hljs-number">0</span>].expression);\n\n  <span class="hljs-comment">// Get floating point number out of heap number</span>\n  <span class="hljs-keyword">this</span>.movq(<span class="hljs-string">\'xmm1\'</span>, [<span class="hljs-string">\'rax\'</span>, <span class="hljs-number">8</span>]);\n\n  <span class="hljs-comment">// Round it towards zero</span>\n  <span class="hljs-keyword">this</span>.roundsd(<span class="hljs-string">\'zero\'</span>, <span class="hljs-string">\'xmm1\'</span>, <span class="hljs-string">\'xmm1\'</span>);\n\n  <span class="hljs-comment">// Convert double to integer</span>\n  <span class="hljs-keyword">this</span>.cvtsd2si(<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'xmm1\'</span>);\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">visitLiteral</span>(<span class="hljs-params">ast</span>) </span>{\n  assert.equal(<span class="hljs-keyword">typeof</span> ast.value, <span class="hljs-string">\'number\'</span>);\n\n  <span class="hljs-comment">// Allocate new heap number</span>\n  <span class="hljs-keyword">this</span>.stub(<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'Alloc\'</span>);\n\n  <span class="hljs-comment">// Save \'rbx\' register</span>\n  <span class="hljs-keyword">this</span>.spill(<span class="hljs-string">\'rbx\'</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n    <span class="hljs-keyword">this</span>.loadDouble(<span class="hljs-string">\'rbx\'</span>, ast.value);\n    <span class="hljs-keyword">this</span>.mov([<span class="hljs-string">\'rax\'</span>, <span class="hljs-number">8</span>], <span class="hljs-string">\'rbx\'</span>);\n  });\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">visitBinary</span>(<span class="hljs-params">ast</span>) </span>{\n  <span class="hljs-comment">// Preserve \'rbx\' after leaving the AST node</span>\n  <span class="hljs-keyword">this</span>.spill(<span class="hljs-string">\'rbx\'</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n    <span class="hljs-comment">// Visit right side of expresion</span>\n    visit.call(<span class="hljs-keyword">this</span>, ast.right);\n\n    <span class="hljs-comment">// Move it to \'rbx\'</span>\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rbx\'</span>, <span class="hljs-string">\'rax\'</span>);\n\n    <span class="hljs-comment">// Visit left side of expression (the result is in \'rax\')</span>\n    visit.call(<span class="hljs-keyword">this</span>, ast.left);\n\n    <span class="hljs-comment">//</span>\n    <span class="hljs-comment">// So, to conclude, we\'ve left side in \'rax\' and right in \'rbx\'</span>\n    <span class="hljs-comment">//</span>\n\n    <span class="hljs-comment">// Let\'s load their double values</span>\n    <span class="hljs-keyword">this</span>.movq(<span class="hljs-string">\'xmm1\'</span>, [<span class="hljs-string">\'rax\'</span>, <span class="hljs-number">8</span>]);\n    <span class="hljs-keyword">this</span>.movq(<span class="hljs-string">\'xmm2\'</span>, [<span class="hljs-string">\'rbx\'</span>, <span class="hljs-number">8</span>]);\n\n    <span class="hljs-comment">// Execute binary operation</span>\n    <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'+\'</span>) {\n      <span class="hljs-keyword">this</span>.addsd(<span class="hljs-string">\'xmm1\'</span>, <span class="hljs-string">\'xmm2\'</span>);\n    } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'-\'</span>) {\n      <span class="hljs-keyword">this</span>.subsd(<span class="hljs-string">\'xmm1\'</span>, <span class="hljs-string">\'xmm2\'</span>);\n    } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'*\'</span>) {\n      <span class="hljs-keyword">this</span>.mulsd(<span class="hljs-string">\'xmm1\'</span>, <span class="hljs-string">\'xmm2\'</span>);\n    } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'/\'</span>) {\n      <span class="hljs-keyword">this</span>.divsd(<span class="hljs-string">\'xmm1\'</span>, <span class="hljs-string">\'xmm2\'</span>);\n    } <span class="hljs-keyword">else</span> {\n      <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-built_in">Error</span>(<span class="hljs-string">\'Unsupported binary operator: \'</span> + ast.operator);\n    }\n\n    <span class="hljs-comment">// Allocate new number, and put value in it</span>\n    <span class="hljs-keyword">this</span>.stub(<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'Alloc\'</span>);\n    <span class="hljs-keyword">this</span>.movq([<span class="hljs-string">\'rax\'</span>, <span class="hljs-number">8</span>], <span class="hljs-string">\'xmm1\'</span>);\n  });\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">visitUnary</span>(<span class="hljs-params">ast</span>) </span>{\n  <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'-\'</span>) {\n    <span class="hljs-comment">// Negate argument by emulating binary expression</span>\n    visit.call(<span class="hljs-keyword">this</span>, {\n      <span class="hljs-attr">type</span>: <span class="hljs-string">\'BinaryExpression\'</span>,\n      <span class="hljs-attr">operator</span>: <span class="hljs-string">\'*\'</span>,\n      <span class="hljs-attr">left</span>: ast.argument,\n      <span class="hljs-attr">right</span>: { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Literal\'</span>, <span class="hljs-attr">value</span>: <span class="hljs-number">-1</span> }\n    })\n  } <span class="hljs-keyword">else</span> {\n    <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-built_in">Error</span>(<span class="hljs-string">\'Unsupported unary operator: \'</span> + ast.operator);\n  }\n}\n</code></pre>\n<h2>To be continued</h2>\n<p>So, that\'s all I have to say to you for now. On a more social theme, you may\nwant subscribe to my <a href="https://twitter.com/indutny">twitter</a> or watch my <a href="https://github.com/indutny/blog">blog on github</a>. Don\'t miss\nthe next post!</p>\n'},{slug:"4.how-to-start-jitting",title:"How to start JIT-ting",date:"2013-11-01T00:00:00.000Z",html:'<h2>Premise</h2>\n<p>Most developers heard about JIT compilers and how they can make slow interpreted\nlanguages run at a speed, comparable to native code. However, not many people\nunderstand how exactly this JIT thing works, and even less people could\nwrite their own compilers.</p>\n<p>I think having at least, basic knowledge of compiler internals may greatly\nimprove understanding of the code that is running on that software.</p>\n<p>In this article, we\'ll visit some peaks of JIT-island, and probably even\nimplement a compiler ourselves!</p>\n<h2>What we\'ll start with</h2>\n<p>Knowing some compiler basics, we can assume that every compiler is\ntransforming input in some format (usually, a source code) into the output in\nanother or same format (usually, a machine code). JIT compilers are not an\nexception.</p>\n<p>What really makes them exceptional, is the fact that they\'re running not ahead\nof time (like gcc, clang and others), but Just-In-Time (i.e. right before\nexecuting compiler\'s output).</p>\n<p>To start developing our own JIT compiler we\'ll need to select the input language\nfor it. Considering <a href="http://adambard.com/blog/top-github-languages-for-2013-so-far/">TOP GITHUB LANGUAGES FOR 2013 (SO FAR)</a>, JavaScript\nseems like a good candidate for implementing some limited subset of\nit with simplified semantics. Even more, we\'ll implement JIT compiler in the\nJavaScript itself. You can call it META-META!</p>\n<h2>AST</h2>\n<p>Our compiler will accept JavaScript source code as its input, and produce (and\nimmediately execute) machine code for the very popular X64 platform. But, while\nits pretty comfortable for humans to work with a textual representation,\ncompiler developers are usually tending to create multiple Intermediate\nRepresentations (IR) before generating the final machine code.</p>\n<p>Since we\'re writing simplified compiler, having only one IR should be enough for\nus, and I\'ll choose Abstract Syntax Tree (AST) representation for this purposes.</p>\n<p>Getting AST out of JavaScript code is really easy nowadays, and we can choose\nany (of dozens) library we like: <a href="https://github.com/ariya/esprima">esprima</a>, <a href="https://github.com/ariya/esprima">uglify-js</a>, etc. Just to be\non one page with me, I recommend you to choose <a href="https://github.com/ariya/esprima">esprima</a>. It has a nice and\nwell defined <a href="https://developer.mozilla.org/en-US/docs/SpiderMonkey/Parser_API">output format</a>.</p>\n<p>For example, this code: <code>obj.method(42)</code> will produce the following AST (using\n<code>esprima.parse(&quot;...&quot;)</code>):</p>\n<pre><code class="language-javascript">{ <span class="hljs-attr">type</span>: <span class="hljs-string">\'Program\'</span>,\n  <span class="hljs-attr">body</span>:\n   [ { <span class="hljs-attr">type</span>: <span class="hljs-string">\'ExpressionStatement\'</span>,\n       <span class="hljs-attr">expression</span>:\n        { <span class="hljs-attr">type</span>: <span class="hljs-string">\'CallExpression\'</span>,\n          <span class="hljs-attr">callee</span>:\n           { <span class="hljs-attr">type</span>: <span class="hljs-string">\'MemberExpression\'</span>,\n             <span class="hljs-attr">computed</span>: <span class="hljs-literal">false</span>,\n             <span class="hljs-attr">object</span>: { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Identifier\'</span>, <span class="hljs-attr">name</span>: <span class="hljs-string">\'obj\'</span> },\n             <span class="hljs-attr">property</span>: { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Identifier\'</span>, <span class="hljs-attr">name</span>: <span class="hljs-string">\'method\'</span> } },\n          <span class="hljs-attr">arguments</span>: [ { <span class="hljs-attr">type</span>: <span class="hljs-string">\'Literal\'</span>, <span class="hljs-attr">value</span>: <span class="hljs-number">42</span> } ] } } ] }\n</code></pre>\n<h2>Machine code</h2>\n<p>Let\'s summarize: we have JavaScript source (<em>check</em>), its AST (<em>check</em>), and we\nwant to get machine code for it.</p>\n<p>If you\'re already familiar with assembly language then you can skip this\nchapter, as it contains only basic introductionary material on this topic.\nHowever, if you\'re new to it, reading next chapter may be hard without learning\nsome basics first. So please stay here, it won\'t take too long!</p>\n<p>Assembly language is the nearest textual representation of the binary code that\nyour CPU(s) understand and is(are) able to run. Considering that processors are\nexecuting code by reading and running instructions one-by-one, it may seem\nlogical to you that almost every line in assembly program represent an\ninstruction:</p>\n<pre><code class="language-asm">mov rax, 1    ; Put 1 into the register named `rax`\nmov rbx, 2    ; Put 2 into the register named `rbx`\nadd rax, rbx  ; Calculate sum of `rax` and `rbx` and put it into `rax`\n</code></pre>\n<p>This program\'s output (assuming you\'ll get it from <code>rax</code> register) is 3. And,\nas you\'ve probably already figured out, it puts some data in some CPU slots\n(<a href="http://en.wikipedia.org/wiki/Processor_register">registers</a>) and asks the CPU to calculate the sum of them.</p>\n<p>Usually processors have enough registers to store results of intermediate\noperations, but in some situations you may want to store/load data (and work\nwith it) from the computer\'s memory:</p>\n<pre><code class="language-asm">mov rax, 1\nmov [rbp-8], rbx  ; Save rbx register into a stack slot\nmov rbx, 2\nadd rax, rbx\nmov rbx, [rbp-8]  ; Restore rbx register from a stack slot\n</code></pre>\n<p>Registers have names, memory slots have addresses. These addresses are usually\nwritten using <code>[...]</code> syntax. For example, <code>[rbp-8]</code> means: take the value of\nthe <code>rbp</code> register, subtract <code>8</code>, and access a memory slot using the resulting\nvalue as the address.</p>\n<p>You can see that we\'re using <code>rbp</code> register here. <code>rbp</code> usually contains\naddress at which on-stack variables storage (i.e. variables that are stored in\ncurrent procedure\'s <a href="http://en.wikipedia.org/wiki/Stack_(abstract_data_type)">stack</a>) starts; <code>8</code> is a size of <code>rbx</code> register (and any\nother register, prefixed with <code>r</code>), and since the <a href="http://en.wikipedia.org/wiki/Stack_(abstract_data_type)">stack</a> is growing upwards,\nwe need to subtract it from <code>rbp</code> to get a free address slot for our purposes.</p>\n<p>There are many more nuances of programming at such a low level, and\nunfortunately I\'m not going to cover all of them here. Also, please be aware\nthat I gave you a very shallow description, and what actually happens here may\nsometimes be much more complex.</p>\n<p>Knowing things mentioned above should be enough to proceed to the code\ngeneration.</p>\n<h2>Code generation</h2>\n<p>Implementing the entire JavaScript is a rather complicated practice, so we\'ll\nimplement only a simplified arithmetics engine for now. (Which should be as fun\nas getting to the whole thing later!)</p>\n<p>The best and the easiest way to do it, is to traverse the AST using\n<a href="http://en.wikipedia.org/wiki/Depth-first_search">Depth First Search</a>, generating machine code for each node. You might wonder\nhow could you generate machine code in a memory-safe language like JavaScript.\nThat\'s where I\'m going to introduce you to <a href="https://github.com/indutny/jit.js">jit.js</a>.</p>\n<p>It is a node.js module (and C++ addon, actually) capable of generating and\nexecution of machine code, using assembly-like JavaScript syntax:</p>\n<pre><code class="language-javascript"><span class="hljs-keyword">var</span> jit = <span class="hljs-built_in">require</span>(<span class="hljs-string">\'jit.js\'</span>);\n\n<span class="hljs-keyword">var</span> fn = jit.compile(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n  <span class="hljs-keyword">this</span>.Proc(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rax\'</span>, <span class="hljs-number">42</span>);\n    <span class="hljs-keyword">this</span>.Return();\n  });\n});\n<span class="hljs-built_in">console</span>.log(fn());  <span class="hljs-comment">// 42</span>\n</code></pre>\n<h2>Let\'s write it</h2>\n<p>Thus only one thing left now, a module to traverse the AST tree, generated by\n<a href="https://github.com/ariya/esprima">esprima</a>. Thankfully, considering its structure and our minimalistic\ncompiler design it should be pretty easy.</p>\n<p>We\'re going to support:</p>\n<ol>\n<li>Number literals (<code>{ type: \'Literal\', value: 123 }</code>)</li>\n<li>Binary expression, with operators: <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>%</code>\n(<code>{ type: \'BinaryExpression\', operator: \'+\', left: ... , right: .... }</code>)</li>\n<li>Unary expression, with the <code>-</code> operator\n(<code>{ type: \'UnaryExpression\', operator: \'-\', argument: ... }</code>)</li>\n</ol>\n<p>All these operations are performed on integers, so don\'t expect it to work\nproperly with values like <code>0.5</code>, <code>0.66666</code>, etc.</p>\n<p>While processing expression, we\'ll be visiting each supported AST node of it,\ngenerating code that returns it\'s result in the <code>rax</code> register. Sounds easy,\nright? The only rule here is that we should keep all other registers clean\nafter leaving the AST node. Which, in other words, means that we should save all\nregisters that are used and restore them after they\'re not needed anymore.\nFortunately, CPUs have two magic instructions <code>push</code> and <code>pop</code> that can help us\nwith that task.</p>\n<p>Here is the resulting code with descriptive comments:</p>\n<pre><code class="language-javascript"><span class="hljs-keyword">var</span> jit = <span class="hljs-built_in">require</span>(<span class="hljs-string">\'jit.js\'</span>),\n    esprima = <span class="hljs-built_in">require</span>(<span class="hljs-string">\'esprima\'</span>),\n    assert = <span class="hljs-built_in">require</span>(<span class="hljs-string">\'assert\'</span>);\n\n<span class="hljs-keyword">var</span> ast = esprima.parse(process.argv[<span class="hljs-number">2</span>]);\n\n<span class="hljs-comment">// Compile</span>\n<span class="hljs-keyword">var</span> fn = jit.compile(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n  <span class="hljs-comment">// This will generate default entry boilerplate</span>\n  <span class="hljs-keyword">this</span>.Proc(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>{\n    visit.call(<span class="hljs-keyword">this</span>, ast);\n\n    <span class="hljs-comment">// The result should be in \'rax\' at this point</span>\n\n    <span class="hljs-comment">// This will generate default exit boilerplate</span>\n    <span class="hljs-keyword">this</span>.Return();\n  });\n});\n\n<span class="hljs-comment">// Execute</span>\n<span class="hljs-built_in">console</span>.log(fn());\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">visit</span>(<span class="hljs-params">ast</span>) </span>{\n  <span class="hljs-keyword">if</span> (ast.type === <span class="hljs-string">\'Program\'</span>)\n    visitProgram.call(<span class="hljs-keyword">this</span>, ast);\n  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ast.type === <span class="hljs-string">\'Literal\'</span>)\n    visitLiteral.call(<span class="hljs-keyword">this</span>, ast);\n  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ast.type === <span class="hljs-string">\'UnaryExpression\'</span>)\n    visitUnary.call(<span class="hljs-keyword">this</span>, ast);\n  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ast.type === <span class="hljs-string">\'BinaryExpression\'</span>)\n    visitBinary.call(<span class="hljs-keyword">this</span>, ast);\n  <span class="hljs-keyword">else</span>\n    <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-built_in">Error</span>(<span class="hljs-string">\'Unknown ast node: \'</span> + ast.type);\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">visitProgram</span>(<span class="hljs-params">ast</span>) </span>{\n  assert.equal(ast.body.length,\n               <span class="hljs-number">1</span>,\n               <span class="hljs-string">\'Only one statement programs are supported\'</span>);\n  assert.equal(ast.body[<span class="hljs-number">0</span>].type, <span class="hljs-string">\'ExpressionStatement\'</span>);\n  visit.call(<span class="hljs-keyword">this</span>, ast.body[<span class="hljs-number">0</span>].expression);\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">visitLiteral</span>(<span class="hljs-params">ast</span>) </span>{\n  assert.equal(<span class="hljs-keyword">typeof</span> ast.value, <span class="hljs-string">\'number\'</span>);\n  assert.equal(ast.value | <span class="hljs-number">0</span>,\n               ast.value,\n               <span class="hljs-string">\'Only integer numbers are supported\'</span>);\n\n  <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rax\'</span>, ast.value);\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">visitBinary</span>(<span class="hljs-params">ast</span>) </span>{\n  <span class="hljs-comment">// Preserve \'rbx\' after leaving the AST node</span>\n  <span class="hljs-keyword">this</span>.push(<span class="hljs-string">\'rbx\'</span>);\n\n  <span class="hljs-comment">// Visit right side of expresion</span>\n  visit.call(<span class="hljs-keyword">this</span>, ast.right);\n\n  <span class="hljs-comment">// Move it to \'rbx\'</span>\n  <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rbx\'</span>, <span class="hljs-string">\'rax\'</span>);\n\n  <span class="hljs-comment">// Visit left side of expression (the result is in \'rax\')</span>\n  visit.call(<span class="hljs-keyword">this</span>, ast.left);\n\n  <span class="hljs-comment">//</span>\n  <span class="hljs-comment">// So, to conclude, we\'ve left side in \'rax\' and right in \'rbx\'</span>\n  <span class="hljs-comment">//</span>\n\n  <span class="hljs-comment">// Execute binary operation</span>\n  <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'+\'</span>) {\n    <span class="hljs-keyword">this</span>.add(<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'rbx\'</span>);\n  } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'-\'</span>) {\n    <span class="hljs-keyword">this</span>.sub(<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'rbx\'</span>);\n  } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'*\'</span>) {\n    <span class="hljs-comment">// Signed multiplication</span>\n    <span class="hljs-comment">// rax = rax * rbx</span>\n    <span class="hljs-keyword">this</span>.imul(<span class="hljs-string">\'rbx\'</span>);\n  } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'/\'</span>) {\n    <span class="hljs-comment">// Preserve \'rdx\'</span>\n    <span class="hljs-keyword">this</span>.push(<span class="hljs-string">\'rdx\'</span>);\n\n    <span class="hljs-comment">// idiv is dividing rdx:rax by rbx, therefore we need to clear rdx</span>\n    <span class="hljs-comment">// before running it</span>\n    <span class="hljs-keyword">this</span>.xor(<span class="hljs-string">\'rdx\'</span>, <span class="hljs-string">\'rdx\'</span>);\n\n    <span class="hljs-comment">// Signed division, rax = rax / rbx</span>\n    <span class="hljs-keyword">this</span>.idiv(<span class="hljs-string">\'rbx\'</span>);\n\n    <span class="hljs-comment">// Restore \'rdx\'</span>\n    <span class="hljs-keyword">this</span>.pop(<span class="hljs-string">\'rdx\'</span>);\n  } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'%\'</span>) {\n    <span class="hljs-comment">// Preserve \'rdx\'</span>\n    <span class="hljs-keyword">this</span>.push(<span class="hljs-string">\'rdx\'</span>);\n\n    <span class="hljs-comment">// Prepare to execute idiv</span>\n    <span class="hljs-keyword">this</span>.xor(<span class="hljs-string">\'rdx\'</span>, <span class="hljs-string">\'rdx\'</span>);\n    <span class="hljs-keyword">this</span>.idiv(<span class="hljs-string">\'rbx\'</span>);\n\n    <span class="hljs-comment">// idiv puts remainder in \'rdx\'</span>\n    <span class="hljs-keyword">this</span>.mov(<span class="hljs-string">\'rax\'</span>, <span class="hljs-string">\'rdx\'</span>);\n\n    <span class="hljs-comment">// Restore \'rdx\'</span>\n    <span class="hljs-keyword">this</span>.pop(<span class="hljs-string">\'rdx\'</span>);\n  } <span class="hljs-keyword">else</span> {\n    <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-built_in">Error</span>(<span class="hljs-string">\'Unsupported binary operator: \'</span> + ast.operator);\n  }\n\n  <span class="hljs-comment">// Restore \'rbx\'</span>\n  <span class="hljs-keyword">this</span>.pop(<span class="hljs-string">\'rbx\'</span>);\n\n  <span class="hljs-comment">// The result is in \'rax\'</span>\n}\n\n<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">visitUnary</span>(<span class="hljs-params">ast</span>) </span>{\n  <span class="hljs-comment">// Visit argument and put result into \'rax\'</span>\n  visit.call(<span class="hljs-keyword">this</span>, ast.argument);\n\n  <span class="hljs-keyword">if</span> (ast.operator === <span class="hljs-string">\'-\'</span>) {\n    <span class="hljs-comment">// Negate argument</span>\n    <span class="hljs-keyword">this</span>.neg(<span class="hljs-string">\'rax\'</span>);\n  } <span class="hljs-keyword">else</span> {\n    <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-built_in">Error</span>(<span class="hljs-string">\'Unsupported unary operator: \'</span> + ast.operator);\n  }\n}\n</code></pre>\n<p>You can try it by cloning it from <a href="https://github.com/indutny/jit.js/tree/master/example/basic">github</a>, running <code>npm install</code> in it\'s\nfolder and then voila!</p>\n<pre><code class="language-bash">$ node ./main.js <span class="hljs-string">\'1 + 2 * 3\'</span>\n7\n</code></pre>\n<p>Thanks for reading up to this point! I\'ll talk about floating point operations\nand the heap in the next blog post!</p>\n'},{slug:"3.dtrace-ustack-helper",title:"DTrace and the little ustack helper that could",date:"2013-01-11T00:00:00.000Z",html:"<a target=__blank href=\"/f/tlsnappy-x64.svg\">\n  ![Flamegraph](/images/flamegraph.png)\n</a>\n<p><a href=\"http://blog.nodejs.org/2012/04/25/profiling-node-js/\">Flamegraphs</a> are awesome if you need to profile your node.js application.\nThey provide a nice looking visual view of where your application is spending\nits time. Although they're <a href=\"http://blog.nodejs.org/2012/04/25/profiling-node-js/\">well</a> <a href=\"http://dtrace.org/blogs/dap/2012/01/05/where-does-your-node-program-spend-its-time/\">documented</a>, no one has ever said a\nword on how they work internally, but everyone mentions\n&quot;ustack helper&quot; which, right now, works only on SmartOS.</p>\n<h1>Call stack</h1>\n<p>To understand profiling, one must understand what a callstack is. During its\nlifetime every application is using <a href=\"http://en.wikipedia.org/wiki/Stack_(abstract_data_type)\">stack</a>, which is a chunk of memory which can\nbe changed by using <code>push</code>, <code>pop</code>, <code>call</code> and other CPU instructions, or\nby accessing it directly.</p>\n<p>The <code>push</code> and <code>pop</code> instructions simply expand/shrink stack storing/loading\ndata on top of it. The <code>call</code> instruction is a little bit more interesting:</p>\n<p><em>(Quote from\n<a href=\"http://download.intel.com/products/processor/manual/325462.pdf\">Intel 64 and IA-32 Architectures Software Developers Manual</a>)</em></p>\n<pre><code>...the processor pushes the value of the EIP register (which contains the\noffset of the instruction following the CALL instruction) on the stack (for\nuse later as a return-instruction pointer). The processor then branches to\nthe address in the current code segment specified by the target operand.\n</code></pre>\n<p>So coupled with the <code>ret</code> instruction <code>call</code> allows you to jump into some\nfunction and return back to the place where it was called. (Despite it's\nsimplicity, I still find it amazing.)</p>\n<p>That's how calling functions really work internally, but stack can be also used\nto store local (on-stack) function's data. This is achieved using stack frames.\nThis is how functions' assembly code do usually look:</p>\n<p><em>(I'll use <a href=\"http://en.wikipedia.org/wiki/X86_assembly_language#Syntax\">AT&amp;T assembly syntax</a>)</em></p>\n<pre><code>push ebp ; Save previous frame pointer\nmov  esp, ebp ; Set new frame pointer\nsub  $0x60, esp ; Allocate space on stack\n\n; Function's body.\nmov  $0x10, -0x8(%ebp) ; set on-stack variable\n\nmov  ebp, esp ; Shrink stack to it's initial value\npop  ebp ; Restore previous frame pointer\nret  0 ; Return to caller\n</code></pre>\n<p>If represented graphically stack generally looks like this:</p>\n<p><img src=\"/images/callstack.png\" alt=\"Callstack\"></p>\n<p>The main pros of using structure above are:</p>\n<ul>\n<li>Easiness of restoring stack back to its initial position</li>\n<li>Fast and simple access to on-stack variables</li>\n</ul>\n<h1>Stack trace</h1>\n<p>Suppose your application has thrown an exception or crashed with a segmentation\nfault. To find the cause of the problem one may start by looking at the stack\ntrace where the crash has happened:</p>\n<pre><code>#0  0x00007fff84356d16 in kevent ()\n#1  0x00000001000557b7 in kqueue_poll ()\n#2  0x000000010004c77a in uv__run ()\n#3  0x000000010004c92a in uv_run ()\n#4  0x0000000100015319 in node::Start ()\n#5  0x000000010000dd24 in start ()\n</code></pre>\n<p>Here, on the left, you can see addresses of functions' code. Debugger gets them\nby taking current <code>eip</code> and <code>ebp</code> registers (which stands for current\ninstruction address and current stack frame address), walking stack frames and\ncollecting return addresses from it. On the right side, you can see functions'\nreal names. <a href=\"http://www.gnu.org/software/gdb/\">gdb</a> automatically loads this information for you by searching\nfor debugging symbols corresponding to addresses it has collected.</p>\n<h1>Flamegraph</h1>\n<p>In order to create flamegraph, one will need to periodically collect\napplication's stack traces and join them (the process is called\n<a href=\"http://en.wikipedia.org/wiki/Profiling_(computer_programming)#Statistical_profilers\">statistical profiling</a>),  making boxes with functions that were called more\noften - wider, and putting box on the top of another box only if their functions\nappear above each other in the stack trace.</p>\n<h1>V8's stack frames</h1>\n<p>When collecting stack traces of C/C++ application, dtrace will use static\ndebugging information using binary's symbols table. But when it comes to dynamic\nlanguages, getting such information turns out to be more complicated:\nfunctions are compiled lazily, often recompiled with applied optimizations, old\ncode may be evicted by GC... in other words, application is evolving during its\nexecution.</p>\n<p>Thankfully, V8 provides this information, but instead of debugging symbols\nit stores it in stack frames. Here is an example of v8's stack frame structure:</p>\n<p><img src=\"/images/v8-callstack.png\" alt=\"V8 Callstack\"></p>\n<p>So knowing this structure we can identify frames by checking marker/function\nvalue and getting function names from V8's heap (it's too big topic to cover\nhere, believe me).</p>\n<p>That's exactly the job of ustack helper, it takes frame address and should figure\nout and return function's name, or just fail. So everytime you call <code>jstack()</code>\nfunction in DTrace probe, ustack helper will be called for every unidentified\nframe.</p>\n<h1>ustack helper example</h1>\n<p><em>NOTE: some knowledge of D language is required to fully understand code below</em></p>\n<pre><code>dtrace:helper:ustack:\n{\n  /* frame pointer */\n  this-&gt;fp = arg1;\n\n  /* Last statement - result */\n  &quot;whoa! you've identified me&quot;;\n}\n</code></pre>\n<p>If you replace contents of <code>src/v8ustack.d</code> in node.js sources, recompile it\n(on SmartOS), run <code>bash benchmark/http-flamegraph.sh</code>, and open <code>stacks.src</code>,\nwhich should contain following stack traces:</p>\n<pre><code>node`_ZN2v88internal7Context14native_contextEv\nnode`_ZN4node10StreamWrap15WriteStringImplILNS_13...\nnode`_ZN4node10StreamWrap15WriteUtf8StringERKN2v89ArgumentsE+0x9\nwhoa! you've identified me\nwhoa! you've identified me\nwhoa! you've identified me\n</code></pre>\n<p>As you can see, DTrace has identified some C++ functions and for all other\naddresses has called our ustack helper.</p>\n<p>Let's read some data from V8's stack frame:</p>\n<pre><code>#define FP_MARKER (-2 * 8)\n#define FT_ENTRY (1 &lt;&lt; 32)\n\n/* Init */\ndtrace:helper:ustack:\n{\n  this-&gt;fp = arg1;\n  this-&gt;done = 0;\n  this-&gt;marker = (uint64_t) 0;\n}\n\n/* Get marker */\ndtrace:helper:ustack:\n{\n  this-&gt;marker = *(uint64_t*) copyin(this-&gt;fp + FP_MARKER,\n                                     sizeof(uint64_t));\n}\n\n/* Match entry marker */\ndtrace:helper:ustack:\n/this-&gt;marker == FT_ENTRY/\n{\n  this-&gt;done = 1;\n  &quot;entry&quot;;\n}\n\n/* Match everything else */\ndtrace:helper:ustack:\n/!this-&gt;done/\n{\n  &quot;everything else&quot;;\n}\n</code></pre>\n<p>Run it again, and if you're lucky enough you'll find this in <code>stacks.src</code>:</p>\n<pre><code>everything else\neverything else\nentry\nnode`_ZN2v88internalL6InvokeEbNS0...\n</code></pre>\n<p>Important things about ustack helper:</p>\n<ul>\n<li>It's running within kernel (though, in it's own context, so it can't crash\nit). The most important consequences of it is that user-land addresses can't\nbe accessed directly, but only by using <code>copyin()</code> function.</li>\n<li>Usage of control flow statements (if/foreach/while) in DTrace scripts is\nprohibited, since all probes should terminate in a reasonable time. Otherwise\ninfinite loop in kernel space will cause your system to halt.</li>\n</ul>\n<h1>Debugging ustack helper</h1>\n<p>During development of 64bit platform support for node.js ustack helper, I found\nthat it's pretty hard to debug ustack helper. The only method to do this is\ninsertion of probes which are returning some debugging information, and\nobserving this information later in stack traces.</p>\n<p>Additionally, it's worth noting that failed <code>copyin()</code> or any bad memory access\nwon't produce any informative output, but you'll see raw address in stack trace\n(i.e. 0x0000000012345678) rather than your pretty real function's name.</p>\n<h1>Epilogue</h1>\n<p>You can look at/play with node's <a href=\"https://github.com/joyent/node/blob/master/src/v8ustack.d\">ustack helper</a>, big kudos to\n<a href=\"https://github.com/davepacheco\">Dave Pacheco</a> for developing it!</p>\n<p>And you should check out Bryan Cantrill's and Dave Pacheco's presentation that\nexplains many things that wasn't covered in this post:\n<a href=\"http://www.slideshare.net/bcantrill/goto2012\">Dynamic Languages in Production: Progress and Open Challenges</a> and\n<a href=\"http://www.livestream.com/dataweek/video?clipId=pla_59016422-9a89-45be-ac86-64bc4c45fe99&amp;utm_source=lslibrary&amp;utm_medium=ui-thumb\">video</a>.</p>\n<p>Huge thanks to <a href=\"http://voxer.com/\">Voxer</a> for funding my investigation and work on porting\nDTrace ustack helper to 64bit platform! Guys, I love you. You're awesome!</p>\n"},{slug:"2.candor-returns",title:"Candor returns",date:"2012-11-21T00:00:00.000Z",html:"<p>Before I start diving into the deep sea of compiler internals, I would like to\nfamiliarize you with the <a href=\"https://github.com/indutny/candor\">Candor</a> programming language and its Virtual\nMachine.</p>\n<p>This is the thing I was working on last 10 months, and one of the most wonderful\nand complex things I've been working on since the start of my software\ndevelopment career.</p>\n<p>Candor is an Ecmascript-inspired language, but while the newer versions of the\nEcmascript standard are adding new functionality and syntax features, my\nlanguage aims to make the syntax as simple as possible.</p>\n<h3>No exceptions</h3>\n<p>Caller can always be sure that function will return after the call. You should\neither invoke a callback with an error argument, return negative number on\nerror, or do anything else to let caller know about errors that has happened.</p>\n<h3>No undefined and null</h3>\n<p>There is the only one value and type that represents undefined value - <code>nil</code>.\nThus, less checks and a more understandable behaviour of your application.</p>\n<h3>No implicit global variables</h3>\n<p>Every global variable access should be done explicitly, by loading/storing\nproperties of the <code>global</code> object. To my mind, it's the most simplest and\npowerful way to prevent global leaks.</p>\n<h3>No default runtime</h3>\n<p>Candor has no default APIs that are doing 'high-level' things with objects and\narrays. These routines should be implemented by embedder (like <a href=\"https://github.com/indutny/candor.io\">candor.io</a>).</p>\n<p>Removing runtime from VM is good in terms of support, less dependencies - less\nthings to care about, and leaving things out of the core keeps it compact.</p>\n<h3>No prototype chains</h3>\n<p>Objects are just magic-less hash-maps without special properties like\n<code>toString</code> or <code>__proto__</code>. Additionally you can have both numeric and string\nkeys in objects (in other words, <code>a[0]</code> and <code>a['0']</code> are not the same thing).</p>\n<p>Also there're no <code>length</code> property of array, it's replaced by <code>sizeof</code> keyword.\nExample: <code>sizeof [1,2,3] == 3</code> or even <code>sizeof &quot;string&quot;</code>.</p>\n<h3>No complicated type coercion</h3>\n<p>Objects, arrays and nil are always converted either to empty string or to zero,\ndepending on type of another argument. For example, this lets you increment\nuninitialized variables without getting any errors or unexpected behaviour:\n<code>nil + 1 == 1</code>.</p>\n<h3>Dart-like function syntax</h3>\n<p>No <code>function</code> keyword, yay! Just write:</p>\n<pre><code>function_name(arguments) {\n  //body\n}\n</code></pre>\n<h2>Syntax</h2>\n<p>You can learn more about syntax and play with it on <a href=\"http://candor-lang.org/\">the official website</a>.</p>\n<h2>Compiler</h2>\n<p>Since the <a href=\"https://github.com/indutny/candor/commit/f3b1ebf3a839e32fcafa14b21af3\">start of this year</a> I have been working on delivering very\nprimitive JIT compiler and VM for Candor. The first version was generating\npretty ugly machine code, which was ineffective and massive.</p>\n<p>It was using the following algorithm:</p>\n<ol>\n<li>Visit AST node.</li>\n<li>Generate all it's children, and place their results into <code>rax</code>, <code>rbx</code>, <code>rcx</code>\n(depending on child's index). (Just in case - <a href=\"http://en.wikipedia.org/wiki/X86-64\">x86-64</a>)</li>\n<li>Generate code that calculates the result of operation and return value in\n<code>rax</code>.</li>\n</ol>\n<p>Pros - fast compilation, easy to understand algorithm. Cons - hard way to deal\nwith different CPU architectures (i.e. it needed more than 6 registers), dumb\ngenerated machine code.</p>\n<p>Thanks to <a href=\"https://code.google.com/p/v8/\">v8</a> and <a href=\"http://www.dartlang.org/\">Dart</a> hacker <a href=\"http://mrale.ph/\">Vyacheslav Egorov</a> and\n<a href=\"http://wingolog.org/\">Andy Wingo's blog</a>, I've figured out that <a href=\"https://github.com/indutny/candor/wiki/Compiler-papers\">there're much better ways</a> to\ndo JIT code generation, but it was too complex for me to understand at that\ntime. And despite I've created new branch <code>feature-ssa</code> and written tons of\ncode, I've never got something truly working.</p>\n<p>I got stuck at implementing registry allocator, mostly because of wrong design\ndecisions that I made before, and continuing development of this branch in this\nform was impossible.</p>\n<p>That's why I took a long break (for almost 6 months) and worked on other\nprojects, until I realized how this thing should be implemented.</p>\n<h2>Candor returns</h2>\n<p>After this pause I've considered many things and finally did it. Even more,\nCandor now has two compilers: non-optimizing and optimizing. The non-optimizing\nis used where it needs to compile a lot of source as fast as possible, and the\noptimizing compiler is used for small functions that might be quickly optimized.</p>\n<p>Main things that helped me to got to this state:</p>\n<ol>\n<li>Understanding how <a href=\"http://en.wikipedia.org/wiki/Control_flow_graph\">CFG</a> and <a href=\"http://en.wikipedia.org/wiki/Static_single_assignment_form\">SSA</a> should be really handled and\nrepresented. CFG is a way to represent tree of input source code (AST) in a\nlinear form, by placing instructions in blocks and connecting them with the\ncontrol-flow edges like: goto and branch (which is used in <code>if</code> and <code>while</code>\nstatements). What I was missing is that the instruction and it's value should\nbe the same object, otherwise it's very problematic to exploit\n<a href=\"http://en.wikipedia.org/wiki/Use-define_chain\">def-use chains</a>, which are very useful for getting type information and\nperforming dead code elimination.</li>\n<li>I was detecting variable conflicts in the blocks with two incoming\nedges in a over-complicated way. I was using lists of active variables and\nperforming very complex analysis to propagate them to blocks that needed\nthem. Apparently, it's very cool and simple to do it in a way v8 does it. By\ncreating environment for each basic block in CFG, placing variables into it\nand copying it as-it-is when adding successor to the block.</li>\n<li>I didn't understand that low-level intermediate representation should\noperate on <code>uses</code> which a parts of variable's liveness intervals... Previous\nversion was doing simplified linear-scan register allocation without holes in\nvariable's liveness intervals, which isn't resulting in good allocation.</li>\n</ol>\n<p>The main difference between optimizing and non-optimizing compiler is that the\nformer is trying to place everything in registers, while the latter operates\nonly on the stack slots (i.e. doing memory access on every variable load and\nstore).</p>\n<p>By having a register allocator that's capable of allocating registers in very\ngeneric terms, it was really straightforward to add support for a 32bit code\ngeneration. And now Candor is officially running on two platforms: ia32 and x64.</p>\n<h2>Plans</h2>\n<p>Now that there are two brand new compilers, I'm going to work on adaptive\noptimization/deoptimization for it. Candor should be capable of optimizing\nhot functions on the fly and inlining small functions into their callers. Also,\nit's quite practical to generate code that's very fast in common cases, and\nfalls back to unoptimized code in all other cases.</p>\n<p>ARM support is also the part of my future plans for Candor, and I'll start\nworking on it as soon as I'll receive my Raspberry PI.</p>\n<h2>More info</h2>\n<p>If you want to ask questions and/or learn more about Candor you can subscribe to\nour <a href=\"https://groups.google.com/forum/?fromgroups&amp;hl=en#!forum/candorlang\">google group</a> or join the #candor IRC channel on freenode.</p>\n"},{slug:"1.to-lock-or-not-to-lock",title:"To lock, or not to lock",date:"2012-10-11T00:00:00.000Z",html:'<h1>TL;DR</h1>\n<p>As I\'ve promised you in my <a href="http://blog.indutny.com/0.benchmarking-tls">previous post</a>, I made <a href="https://github.com/indutny/tlsnappy">TLSnappy</a> balance and\nhandle requests a little bit better.</p>\n<h1>Data flow</h1>\n<p>For leveraging all available CPUs TLSnappy runs multiple threads that are each\npicking and processing tasks from their dispatch queues, one by one. Tasks are\ncreated from node\'s event-loop in following cases:</p>\n<ul>\n<li>Data comes from client and should be decrypted</li>\n<li>Data from server should be encrypted</li>\n</ul>\n<p>So, as you can see, each thread is receiving data from it\'s inputs (either\n<code>encrypted</code> or <code>clear</code>) and/or emitting data to it\'s outputs. This pattern\napparently requires a lot of data transfer <code>to</code> and <code>from</code> worker threads and\nrequires storing (buffering) that data in some temporary storage before\nprocessing it.</p>\n<p>To my mind, best structure to fit this needs is <a href="http://en.wikipedia.org/wiki/Circular_buffer">Circular (Ring) buffer</a>.\nBecause it\'s fast, can be grown if more than it\'s current capacity needs to be\nheld.</p>\n<p>The <a href="https://github.com/indutny/tlsnappy/blob/old-ring/src/ring.h">Naive version</a> of it was good enough to try out things, but it wasn\'t\nsupposed to be run in a multi-threaded concurrent environment - all access to\nthis buffer can take place only in a <a href="http://en.wikipedia.org/wiki/Critical_section">critical section</a>. This means that at\nany time only one thread may access the ring\'s methods or properties. You might\nthink that this doesn\'t make difference, but, according to <a href="http://en.wikipedia.org/wiki/Amdahl\'s_law">Amdahl\'s law</a>,\nreducing time spent in non-parallelizable (sequential) parts of application is\nmuch more critical for overall performance than speeding up parallel parts.</p>\n<h1>Lock-less ring buffer</h1>\n<p>Removing locks seemed to be essential for achieving better performance, however\na special structure needs to be used in order to make a ring buffer work across\nmultiple CPUs. Here is the structure I chose for it:</p>\n<p><img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/ring.png" alt="Ring buffer"></p>\n<p>Ring consists of pages that\'re forming circular linked list, each page has two\noffsets: reader (<code>roffset</code>) and writer (<code>woffset</code>). And there\'re two special\npages (which could be the same one actually): reader head (<code>rhead</code>) and writer\nhead (<code>whead</code>).</p>\n<p>Initially the ring contains only one page which is <code>rhead</code> and <code>whead</code> at the\nsame time. When the producer wants to put data in - it goes to the <code>whead</code>,\ncopies data into the page, increments <code>woffset</code> and if the page is full - it\ncreate a new page, or reuses an old one that doesn\'t contain any un-read data.\nConsumer takes <code>rhead</code> reads up to <code>woffset - roffset</code> bytes from it, increments\n<code>roffset</code> and moves to the next page if <code>roffset</code> is equal to the size of the\npage.</p>\n<p>So here are benchmarks:</p>\n<p>Without lock-less ring:</p>\n<pre><code>Transactions:                 200000 hits\nAvailability:                 100.00 %\nElapsed time:                  47.90 secs\nData transferred:             585.37 MB\nResponse time:                  0.02 secs\nTransaction rate:            4175.37 trans/sec\nThroughput:                    12.22 MB/sec\nConcurrency:                   98.79\nSuccessful transactions:      200000\nFailed transactions:               0\nLongest transaction:            0.09\nShortest transaction:           0.00\n</code></pre>\n<p>With lock-less ring:</p>\n<pre><code>Transactions:                 200000 hits\nAvailability:                 100.00 %\nElapsed time:                  47.37 secs\nData transferred:             585.37 MB\nResponse time:                  0.02 secs\nTransaction rate:            4222.08 trans/sec\nThroughput:                    12.36 MB/sec\nConcurrency:                   98.83\nSuccessful transactions:      200000\nFailed transactions:               0\nLongest transaction:            0.12\nShortest transaction:           0.00\n</code></pre>\n<p>As you can see, performance hasn\'t greatly improved and is actually almost\nbeyond statistical error (which means that results are nearly the same). However\nthese are results for small 3kb page, lets try sending some big 100kb buffers.</p>\n<p>Without lock-less ring:</p>\n<pre><code>Transactions:                 100000 hits\nAvailability:                 100.00 %\nElapsed time:                  64.06 secs\nData transferred:            9536.74 MB\nResponse time:                  0.06 secs\nTransaction rate:            1561.04 trans/sec\nThroughput:                   148.87 MB/sec\nConcurrency:                   98.59\nSuccessful transactions:      100000\nFailed transactions:               0\nLongest transaction:            1.93\nShortest transaction:           0.00\n</code></pre>\n<p>With lock-less ring:</p>\n<pre><code>Transactions:                 100000 hits\nAvailability:                 100.00 %\nElapsed time:                  58.73 secs\nData transferred:            9536.74 MB\nResponse time:                  0.06 secs\nTransaction rate:            1702.71 trans/sec\nThroughput:                   162.38 MB/sec\nConcurrency:                   98.98\nSuccessful transactions:      100000\nFailed transactions:               0\nLongest transaction:            0.19\nShortest transaction:           0.00\n</code></pre>\n<p>Wow! That\'s much better - about 9% performance improvement.</p>\n<h1>Instruments</h1>\n<p>Still TLSnappy\'s performance wasn\'t even close to what nginx is capable of\n(~5100 requests per second). Thus it was necessary to continue investigation and\nthis is where <a href="https://developer.apple.com/library/mac/#documentation/DeveloperTools/Conceptual/InstrumentsUserGuide/Introduction/Introduction.html">Instruments.app</a> comes into play, which is basically an UI for some\nvery useful dtrace scripts. I\'ve run the <code>CPU Sampler</code> utility and this is what\nthe call tree looked like:\n<img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/original-node.png" alt="Original node"></p>\n<p>Obviously it spends almost 30% of time in synchronization between threads,\nparticularly in <code>CRYPTO_add_lock</code> function:\n<img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/old-crypto-add-lock.png" alt="Old CRYPTO_add_lock"></p>\n<p>After modifying the code to use atomic operations, which are supported by almost\nevery CPU nowadays):\n<img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/new-crypto-add-lock.png" alt="New CRYPTO_add_lock"></p>\n<p>Call tree locked like this:\n<img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/patched-node.png" alt="Patched node"></p>\n<h1>Results</h1>\n<p>I\'ve opened <a href="https://github.com/joyent/node/pull/4105">pull request for node.js</a> and sent the same patches to the\nopenssl-dev mailing list. With patched node and latest tlsnappy these are the\nbenchmark results:</p>\n<p><img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-rps-2.png" alt="Requests per second">\n<img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-load-2.png" alt="Average load"></p>\n<p>And that\'s without patches:</p>\n<p><img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-rps-siege.png" alt="Requests per second">\n<img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-load-siege.png" alt="Average load"></p>\n<p>A little comment about curve names here:</p>\n<ul>\n<li><code>default</code> - one tlsnappy process with 16 threads</li>\n<li><code>hybrid</code> - 4 tlsnappy processes with 4 threads each</li>\n<li><code>cluster</code> - 16 tlsnappy processes with 1 thread each</li>\n<li><code>http</code> - 16 node.js processes in cluster</li>\n</ul>\n<p>The work is unfinished yet, but now I know that OpenSSL doesn\'t really behave\nwell when used in multithreaded application.</p>\n'},{slug:"0.benchmarking-tls",title:"Benchmarking TLS, TLSnappy and NGINX",date:"2012-10-02T00:00:00.000Z",html:'<h1>TL;DR</h1>\n<p>I\'ve created <a href="https://github.com/indutny/tlsnappy">TLSnappy</a> module which is going to be faster than internal TLS\nmodule in node.js. So far it\'s slower on some benchmarks, but it\'ll definitely\nbe much snappier soon.</p>\n<h1>Preface</h1>\n<p>Many people were complaining about <a href="http://nodejs.org/api/tls.html">tls</a> performance in node.js, which (as\nthey said) was significantly worse than in many other popular web servers,\nbalancers and terminators (i.e. nginx, haproxy..).</p>\n<p>Several things were done to address this issue, including:</p>\n<ul>\n<li>Disabling OpenSSL compression in node:\nhttp://journal.paul.querna.org/articles/2011/04/05/openssl-memory-use/ and\nhttps://github.com/joyent/node/commit/e83c695</li>\n<li><a href="https://github.com/joyent/node/commit/e80cac62">Bundling a newer version of OpenSSL</a></li>\n<li><a href="https://github.com/joyent/node/compare/7651228...e0e9f0c">Enabling inlined assembly</a></li>\n<li><a href="https://github.com/joyent/node/commit/7651228">Using slab allocator to reduce memory allocation overhead</a></li>\n</ul>\n<p>After all that stuff got in, rps (requests per second) rate was significantly\nimproved, but many users were still unhappy with overall TLS performance.</p>\n<h1>TLSnappy</h1>\n<p>This time, instead of patching and tweaking <a href="http://nodejs.org/api/tls.html">tls</a> I decided that it may be\nworth trying to rewrite it from scratch as a third-party node.js addon. This\nrecently became <a href="https://github.com/TooTallNate/node-gyp/wiki/Linking-to-OpenSSL">possible</a>, thanks to <a href="https://github.com/TooTallNate">Nathan Rajlich</a> and his awesome\nnode.js native addon build tool <a href="https://github.com/TooTallNate/node-gyp">node-gyp</a>.</p>\n<p>I didn\'t want to offer a module that\'s functionally equivalent to TLS, but\nwanted to fix some issues (as I\'ve perceived them) and improve few things:</p>\n<ul>\n<li>Encryption/decryption should happen asynchronously (i.e. in other thread).\nThis could potentially speed up initial ssl handshake, and let the event loop\nperform more operations while encryption/decryption is happening in the\nbackground.</li>\n<li>The builtin TLS module passes, slices and copies buffers in <a href="https://github.com/indutny/tlsnappy">javascript</a>.\nAll binary data operations should happen in C++.</li>\n</ul>\n<p>All this was implemented in <a href="https://github.com/indutny/tlsnappy">TLSnappy</a> module.</p>\n<p>There were a lot of availability and stability issues (and surely much more that\nI\'m yet unaware of). But tlsnappy seem to be quite a bit more performant than\nthe built-in tls module. Especially... when taking in account that <code>tlsnappy</code> is\nby default using all available cores to encrypt/decrypt requests, while <code>tls</code>\nmodule needs to be run in <a href="http://nodejs.org/api/cluster.html">cluster</a> to balance load between all cores.</p>\n<h1>Benchmarking</h1>\n<p>And I\'ve confirmed that when I was benchmaring it with Apache Benchmark (ab) on\nmy Macbook Pro and on dedicated Xeon server. Here a results from the latter one:</p>\n<p><img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-rps.png" alt="Xeon 16 threads (rps) - Apache Benchmark">\n<img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-ms.png" alt="Xeon 16 threads (ms) - Apache Benchmark"></p>\n<p>A little comment about curve names here:</p>\n<ul>\n<li><code>default</code> - one tlsnappy process with 16 threads</li>\n<li><code>hybrid</code> - 4 tlsnappy processes with 4 threads each</li>\n<li><code>cluster</code> - 16 tlsnappy processes with 1 thread each</li>\n<li><code>http</code> - 16 node.js processes in cluster</li>\n</ul>\n<p>As you can see tlsnappy is faster than tls server in almost every case, except\n<code>cluster</code> mode (which just wasn\'t saturating CPU enough). Everything looked\ngreat and shiny, until <a href="https://github.com/mranney">Matt Ranney</a> has pointed out that <code>ab</code> results of\nhttps benchmarks are not really trustful:</p>\n<blockquote class="twitter-tweet tw-align-center"><p>@<a href="https://twitter.com/ryah">ryah</a> @<a href="https://twitter.com/indutny">indutny</a> I was also mislead by "ab" with https benchmarks. I\'m not sure what tool to use instead though.</p>&mdash; Matt Ranney (@mranney) <a href="https://twitter.com/mranney/status/252137849468633088" data-datetime="2012-09-29T20:08:42+00:00">September 29, 2012</a></blockquote>\n<p>I\'ve installed siege, created node.js <a href="https://github.com/indutny/tlsnappy/blob/master/benchmark/script.js">script</a> and let it run for some time:</p>\n<p><img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-rps-siege.png" alt="Xeon 16 threads (rps) - Siege"></p>\n<p>Results are much better now (nginx was doing 5000 rps with siege and 2500 rps\nwith ab), but now tlsnappy seems to be slower than node.js\' default tls server.</p>\n<p>I started investigation and decided to track not only rps rate, but a CPU load\ntoo:</p>\n<p><img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-load-siege.png" alt="Xeon 16 threads (load) - Siege"></p>\n<h1>Afterword</h1>\n<p>Right now, as you can see on the chart above, tlsnappy isn\'t saturating all CPUs\nwell. I suspect this is a major reason of its relative slowness in comparison\nto both nginx and https module. I\'m working on making it balance and handle\nrequests better, and will sum up results of this investigation in the next blog\npost.</p>\n<p>For those of you, who are interested in more details -\n<a href="https://docs.google.com/spreadsheet/ccc?key=0AhEDnA4M4EKGdDIwb3VYZTd1alA5T1pTVnlQWl9wanc">here is benchmarks\' data</a></p>\n',scripts:["https://platform.twitter.com/widgets.js"]}]},158:function(s,n,e){"use strict";e.d(n,"a",function(){return t});e(89);var a="Jan:Feb:Mar:Apr:May:Jun:Jul:Aug:Sep:Oct:Nov:Dec".split(":");function t(s){var n=new Date(s);return"".concat(n.getDay()," ").concat(a[n.getMonth()]," ").concat(n.getFullYear())}}}]);
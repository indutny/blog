# Benchmarking TLS, TLSnappy and NGINX

Preface
=======

Many people were complaining about [tls][0] performance in node.js, which (as
they told) was significantly worse than in many other popular web servers,
balancers and terminators (i.e. nginx, haproxy..).

Several actions was performed to fix this issue including:

 * Disabling OpenSSL compression in node:
   http://journal.paul.querna.org/articles/2011/04/05/openssl-memory-use/ and
   https://github.com/joyent/node/commit/e83c695
 * Bundling fresh version of OpenSSL:
   https://github.com/joyent/node/commit/e80cac62
 * Enabling inlined assembly:
   https://github.com/joyent/node/compare/7651228...e0e9f0c
 * Using slab allocator to reduce memory allocation overhead:
   https://github.com/joyent/node/commit/7651228

After all that stuff got in, rps (request per second) rate was significantly
improved, but many users was still unhappy with overall module speed.

TLSnappy
========

This time, instead of patching and tweaking [tls][0] I decided that it may be
worth trying rewriting it from scratch as a third-party node.js addon. This
recently became [possible][1], thanks to [Nathan Rajlich][2] and his awesome
node.js native addon build tool [node-gyp][3], which is embedded in and used by
default by npm.

But instead of having exact copy of tls in a third-party module, I wanted to
fix some issues (as I've perceived them):

 * Encryption/decryption should happen in a non-blocking mode (i.e. in other
   thread). This should potentially speed up initial ssl handshake, and let
   event loop perform more operations while encryption/decryption is happening
   in background.
 * All input and output data processing should happen in C++ land. Node.js is
   passing, slicing and copying buffers in [javascript part][4] of tls module.

All this was implemented in [TLSnappy][4] module.

There was a lot of availability and stability issues (and surely much more than
I'm yet unaware of). But performance seems to be quite better than `tls`' one.
Especially, when taking in account that `tlsnappy` is by default using all
available cores to encrypt/decrypt requests, while `tls` module needs to be run
in [cluster][5] to balance load between all cores.

Benchmarking
============

And I've confirmed that when I was benchmaring it with Apache Benchmark (ab) on
my Macbook Pro and on dedicated Xeon server. Here a results from the latter one:

![Xeon 16 threads (rps) - Apache Benchmark][6]
![Xeon 16 threads (ms) - Apache Benchmark][7]

A little comment about curve names here:

 * `default` - one tlsnappy process with 16 threads
 * `hybrid` - 4 tlsnappy processes with 4 threads each
 * `cluster` - 16 tlsnappy processes with 1 thread each
 * `http` - 16 node.js processes in cluster

As you can see tlsnappy is faster than tls server in almost every case, except
`cluster` mode (which just wasn't saturating CPU enough). Everything looked
great and shiny, until [Matt Ranney][8] has pointed out that `ab` results of
https benchmarks are not really trustful:

<blockquote class="twitter-tweet tw-align-center"><p>@<a href="https://twitter.com/ryah">ryah</a> @<a href="https://twitter.com/indutny">indutny</a> I was also mislead by "ab" with https benchmarks. I'm not sure what tool to use instead though.</p>&mdash; Matt Ranney (@mranney) <a href="https://twitter.com/mranney/status/252137849468633088" data-datetime="2012-09-29T20:08:42+00:00">September 29, 2012</a></blockquote>
<script src="//platform.twitter.com/widgets.js" charset="utf-8" async></script>

I've installed siege, created node.js [script][9] and let it run for some time:

![Xeon 16 threads (rps) - Siege][10]

Results are much better now (nginx was doing 5000 rps with siege and 2500 rps
with ab), but now tlsnappy seems to be slower than node.js' default tls server.

I started investigation and decided to track not only rps rate, but a CPU load
too:

![Xeon 16 threads (load) - Siege][11]

Foreword
========

Right now, as you can see on the char above, tlsnappy isn't saturating all CPUs
well. I suspect this is a major reason of it's relative slowness in comparison
to both nginx and https module. I'm working on making it balance and handle
requests better, and will write results of this investigation in the next blog
post.

For those of you, who is interested in more details - [here is benchmarks data][12]

[0]: http://nodejs.org/api/tls.html
[1]: https://github.com/TooTallNate/node-gyp/wiki/Linking-to-OpenSSL
[2]: https://github.com/TooTallNate
[3]: https://github.com/TooTallNate/node-gyp
[4]: https://github.com/indutny/tlsnappy
[5]: http://nodejs.org/api/cluster.html
[6]: https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-rps.png
[7]: https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-ms.png
[8]: https://github.com/mranney
[9]: https://github.com/indutny/tlsnappy/blob/master/benchmark/script.js
[10]: https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-rps-siege.png
[11]: https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-load-siege.png
[12]: https://docs.google.com/spreadsheet/ccc?key=0AhEDnA4M4EKGdDIwb3VYZTd1alA5T1pTVnlQWl9wanc

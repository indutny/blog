---
title: Benchmarking TLS, TLSnappy and NGINX
date: 2012-10-02
permalink: /0.benchmarking-tls/
tags: [TLS, performance]
---

TL;DR
=====

I've created [TLSnappy][4] module which is going to be faster than internal TLS
module in node.js. So far it's slower on some benchmarks, but it'll definitely
be much snappier soon.

Preface
=======

Many people were complaining about [tls][0] performance in node.js, which (as
they said) was significantly worse than in many other popular web servers,
balancers and terminators (i.e. nginx, haproxy..).

Several things were done to address this issue, including:

 * Disabling OpenSSL compression in node, see [Paul Querna's article](http://journal.paul.querna.org/articles/2011/04/05/openssl-memory-use/) and [Node.js commit](https://github.com/joyent/node/commit/e83c695)
 * [Bundling a newer version of OpenSSL][13]
 * [Enabling inlined assembly][14]
 * [Using slab allocator to reduce memory allocation overhead][15]

After all that stuff got in, rps (requests per second) rate was significantly
improved, but many users were still unhappy with overall TLS performance.

TLSnappy
========

This time, instead of patching and tweaking [tls][0] I decided that it may be
worth trying to rewrite it from scratch as a third-party node.js addon. This
recently became [possible][1], thanks to [Nathan Rajlich][2] and his awesome
node.js native addon build tool [node-gyp][3].

I didn't want to offer a module that's functionally equivalent to TLS, but
wanted to fix some issues (as I've perceived them) and improve few things:

 * Encryption/decryption should happen asynchronously (i.e. in other thread).
   This could potentially speed up initial ssl handshake, and let the event loop
   perform more operations while encryption/decryption is happening in the
   background.
 * The builtin TLS module passes, slices and copies buffers in [javascript][4].
   All binary data operations should happen in C++.

All this was implemented in [TLSnappy][4] module.

There were a lot of availability and stability issues (and surely much more that
I'm yet unaware of). But tlsnappy seem to be quite a bit more performant than
the built-in tls module. Especially... when taking in account that `tlsnappy` is
by default using all available cores to encrypt/decrypt requests, while `tls`
module needs to be run in [cluster][5] to balance load between all cores.

Benchmarking
============

And I've confirmed that when I was benchmaring it with Apache Benchmark (ab) on
my Macbook Pro and on dedicated Xeon server. Here a results from the latter one:

{% image "./tlsnappy-rps.png", "Xeon 16 threads (rps) - Apache Benchmark" %}
{% image "./tlsnappy-ms.png", "Xeon 16 threads (ms) - Apache Benchmark" %}

A little comment about curve names here:

 * `default` - one tlsnappy process with 16 threads
 * `hybrid` - 4 tlsnappy processes with 4 threads each
 * `cluster` - 16 tlsnappy processes with 1 thread each
 * `http` - 16 node.js processes in cluster

As you can see tlsnappy is faster than tls server in almost every case, except
`cluster` mode (which just wasn't saturating CPU enough). Everything looked
great and shiny, until [Matt Ranney][8] has pointed out that `ab` results of
https benchmarks are not really trustful:

<blockquote class="twitter-tweet tw-align-center"><p>@<a href="https://twitter.com/ryah">ryah</a> @<a href="https://twitter.com/indutny">indutny</a> I was also mislead by "ab" with https benchmarks. I'm not sure what tool to use instead though.</p>&mdash; Matt Ranney (@mranney) <a href="https://twitter.com/mranney/status/252137849468633088" data-datetime="2012-09-29T20:08:42+00:00">September 29, 2012</a></blockquote>

I've installed siege, created node.js [script][9] and let it run for some time:

{% image "./tlsnappy-rps-siege.png", "Xeon 16 threads (rps) - Siege " %}

Results are much better now (nginx was doing 5000 rps with siege and 2500 rps
with ab), but now tlsnappy seems to be slower than node.js' default tls server.

I started investigation and decided to track not only rps rate, but a CPU load
too:

{% image "./tlsnappy-load-siege.png", "Xeon 16 threads (load) - Siege " %}

Afterword
=========

Right now, as you can see on the chart above, tlsnappy isn't saturating all CPUs
well. I suspect this is a major reason of its relative slowness in comparison
to both nginx and https module. I'm working on making it balance and handle
requests better, and will sum up results of this investigation in the next blog
post.

For those of you, who are interested in more details -
[here is benchmarks' data][12]

[0]: http://nodejs.org/api/tls.html
[1]: https://github.com/TooTallNate/node-gyp/wiki/Linking-to-OpenSSL
[2]: https://github.com/TooTallNate
[3]: https://github.com/TooTallNate/node-gyp
[4]: https://github.com/indutny/tlsnappy
[5]: http://nodejs.org/api/cluster.html
[8]: https://github.com/mranney
[9]: https://github.com/indutny/tlsnappy/blob/master/benchmark/script.js
[12]: https://docs.google.com/spreadsheet/ccc?key=0AhEDnA4M4EKGdDIwb3VYZTd1alA5T1pTVnlQWl9wanc
[13]: https://github.com/joyent/node/commit/e80cac62
[14]: https://github.com/joyent/node/compare/7651228...e0e9f0c
[15]: https://github.com/joyent/node/commit/7651228
